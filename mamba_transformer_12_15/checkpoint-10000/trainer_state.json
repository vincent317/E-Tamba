{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.9653441451877595,
  "eval_steps": 1000,
  "global_step": 10000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0,
      "grad_norm": 0.823432445526123,
      "learning_rate": 4.978762428805869e-05,
      "loss": 10.1354,
      "step": 50
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.5347459316253662,
      "learning_rate": 4.954628825176176e-05,
      "loss": 7.9134,
      "step": 100
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.062615156173706,
      "learning_rate": 4.930495221546482e-05,
      "loss": 7.8656,
      "step": 150
    },
    {
      "epoch": 0.02,
      "grad_norm": 10.729616165161133,
      "learning_rate": 4.906361617916788e-05,
      "loss": 6.8872,
      "step": 200
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.9013864398002625,
      "learning_rate": 4.882228014287094e-05,
      "loss": 6.4754,
      "step": 250
    },
    {
      "epoch": 0.03,
      "grad_norm": 1.4274927377700806,
      "learning_rate": 4.858094410657399e-05,
      "loss": 6.2861,
      "step": 300
    },
    {
      "epoch": 0.03,
      "grad_norm": 1.6280817985534668,
      "learning_rate": 4.833960807027705e-05,
      "loss": 6.1411,
      "step": 350
    },
    {
      "epoch": 0.04,
      "grad_norm": 1.6601113080978394,
      "learning_rate": 4.809827203398012e-05,
      "loss": 6.0092,
      "step": 400
    },
    {
      "epoch": 0.04,
      "grad_norm": 1.656697154045105,
      "learning_rate": 4.785693599768318e-05,
      "loss": 5.9267,
      "step": 450
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.9851356744766235,
      "learning_rate": 4.761559996138624e-05,
      "loss": 5.8431,
      "step": 500
    },
    {
      "epoch": 0.05,
      "grad_norm": 1.2732365131378174,
      "learning_rate": 4.7374263925089293e-05,
      "loss": 5.8137,
      "step": 550
    },
    {
      "epoch": 0.06,
      "grad_norm": 1.869531512260437,
      "learning_rate": 4.7132927888792354e-05,
      "loss": 5.7815,
      "step": 600
    },
    {
      "epoch": 0.06,
      "grad_norm": 2.335833787918091,
      "learning_rate": 4.6891591852495414e-05,
      "loss": 5.7115,
      "step": 650
    },
    {
      "epoch": 0.07,
      "grad_norm": 1.0388880968093872,
      "learning_rate": 4.665025581619848e-05,
      "loss": 5.6292,
      "step": 700
    },
    {
      "epoch": 0.07,
      "grad_norm": 1.1441072225570679,
      "learning_rate": 4.640891977990154e-05,
      "loss": 5.5959,
      "step": 750
    },
    {
      "epoch": 0.08,
      "grad_norm": 2.961862325668335,
      "learning_rate": 4.6167583743604595e-05,
      "loss": 5.5591,
      "step": 800
    },
    {
      "epoch": 0.08,
      "grad_norm": 2.2593162059783936,
      "learning_rate": 4.5926247707307655e-05,
      "loss": 5.5551,
      "step": 850
    },
    {
      "epoch": 0.09,
      "grad_norm": 1.2952903509140015,
      "learning_rate": 4.5684911671010716e-05,
      "loss": 5.5109,
      "step": 900
    },
    {
      "epoch": 0.09,
      "grad_norm": 1.1842141151428223,
      "learning_rate": 4.5443575634713776e-05,
      "loss": 5.4684,
      "step": 950
    },
    {
      "epoch": 0.1,
      "grad_norm": 2.0833659172058105,
      "learning_rate": 4.520223959841684e-05,
      "loss": 5.469,
      "step": 1000
    },
    {
      "epoch": 0.1,
      "eval_loss": 5.428962707519531,
      "eval_runtime": 390.8219,
      "eval_samples_per_second": 160.001,
      "eval_steps_per_second": 2.502,
      "step": 1000
    },
    {
      "epoch": 0.1,
      "grad_norm": 2.035473585128784,
      "learning_rate": 4.49609035621199e-05,
      "loss": 5.4225,
      "step": 1050
    },
    {
      "epoch": 0.11,
      "grad_norm": 2.467158317565918,
      "learning_rate": 4.471956752582296e-05,
      "loss": 5.405,
      "step": 1100
    },
    {
      "epoch": 0.11,
      "grad_norm": 2.0674445629119873,
      "learning_rate": 4.447823148952602e-05,
      "loss": 5.3773,
      "step": 1150
    },
    {
      "epoch": 0.12,
      "grad_norm": 2.373114585876465,
      "learning_rate": 4.423689545322908e-05,
      "loss": 5.3474,
      "step": 1200
    },
    {
      "epoch": 0.12,
      "grad_norm": 1.6647899150848389,
      "learning_rate": 4.399555941693214e-05,
      "loss": 5.3113,
      "step": 1250
    },
    {
      "epoch": 0.13,
      "grad_norm": 1.6021857261657715,
      "learning_rate": 4.37542233806352e-05,
      "loss": 5.3153,
      "step": 1300
    },
    {
      "epoch": 0.13,
      "grad_norm": 1.2614679336547852,
      "learning_rate": 4.351288734433826e-05,
      "loss": 5.2971,
      "step": 1350
    },
    {
      "epoch": 0.14,
      "grad_norm": 1.17757248878479,
      "learning_rate": 4.327155130804132e-05,
      "loss": 5.2507,
      "step": 1400
    },
    {
      "epoch": 0.14,
      "grad_norm": 1.5515658855438232,
      "learning_rate": 4.303021527174438e-05,
      "loss": 5.2401,
      "step": 1450
    },
    {
      "epoch": 0.14,
      "grad_norm": 1.9634132385253906,
      "learning_rate": 4.278887923544744e-05,
      "loss": 5.24,
      "step": 1500
    },
    {
      "epoch": 0.15,
      "grad_norm": 2.0243892669677734,
      "learning_rate": 4.25475431991505e-05,
      "loss": 5.2334,
      "step": 1550
    },
    {
      "epoch": 0.15,
      "grad_norm": 1.661182165145874,
      "learning_rate": 4.230620716285356e-05,
      "loss": 5.2225,
      "step": 1600
    },
    {
      "epoch": 0.16,
      "grad_norm": 2.532989740371704,
      "learning_rate": 4.206487112655662e-05,
      "loss": 5.1826,
      "step": 1650
    },
    {
      "epoch": 0.16,
      "grad_norm": 2.443333864212036,
      "learning_rate": 4.182353509025968e-05,
      "loss": 5.1642,
      "step": 1700
    },
    {
      "epoch": 0.17,
      "grad_norm": 1.6694014072418213,
      "learning_rate": 4.158219905396274e-05,
      "loss": 5.1753,
      "step": 1750
    },
    {
      "epoch": 0.17,
      "grad_norm": 2.1462488174438477,
      "learning_rate": 4.13408630176658e-05,
      "loss": 5.1426,
      "step": 1800
    },
    {
      "epoch": 0.18,
      "grad_norm": 2.4016778469085693,
      "learning_rate": 4.1099526981368855e-05,
      "loss": 5.1298,
      "step": 1850
    },
    {
      "epoch": 0.18,
      "grad_norm": 1.8336302042007446,
      "learning_rate": 4.085819094507192e-05,
      "loss": 5.1269,
      "step": 1900
    },
    {
      "epoch": 0.19,
      "grad_norm": 1.4773811101913452,
      "learning_rate": 4.061685490877498e-05,
      "loss": 5.1285,
      "step": 1950
    },
    {
      "epoch": 0.19,
      "grad_norm": 1.9585425853729248,
      "learning_rate": 4.037551887247804e-05,
      "loss": 5.109,
      "step": 2000
    },
    {
      "epoch": 0.19,
      "eval_loss": 5.089993476867676,
      "eval_runtime": 390.872,
      "eval_samples_per_second": 159.981,
      "eval_steps_per_second": 2.502,
      "step": 2000
    },
    {
      "epoch": 0.2,
      "grad_norm": 1.8375892639160156,
      "learning_rate": 4.01341828361811e-05,
      "loss": 5.1021,
      "step": 2050
    },
    {
      "epoch": 0.2,
      "grad_norm": 3.5429444313049316,
      "learning_rate": 3.989284679988416e-05,
      "loss": 5.0621,
      "step": 2100
    },
    {
      "epoch": 0.21,
      "grad_norm": 1.6415536403656006,
      "learning_rate": 3.965151076358722e-05,
      "loss": 5.0725,
      "step": 2150
    },
    {
      "epoch": 0.21,
      "grad_norm": 1.665309190750122,
      "learning_rate": 3.9410174727290284e-05,
      "loss": 5.0472,
      "step": 2200
    },
    {
      "epoch": 0.22,
      "grad_norm": 1.7117923498153687,
      "learning_rate": 3.9168838690993345e-05,
      "loss": 5.0477,
      "step": 2250
    },
    {
      "epoch": 0.22,
      "grad_norm": 2.136540651321411,
      "learning_rate": 3.89275026546964e-05,
      "loss": 5.0501,
      "step": 2300
    },
    {
      "epoch": 0.23,
      "grad_norm": 3.545893430709839,
      "learning_rate": 3.868616661839946e-05,
      "loss": 5.0012,
      "step": 2350
    },
    {
      "epoch": 0.23,
      "grad_norm": 1.961560606956482,
      "learning_rate": 3.844483058210252e-05,
      "loss": 5.0379,
      "step": 2400
    },
    {
      "epoch": 0.24,
      "grad_norm": 4.51071310043335,
      "learning_rate": 3.820349454580558e-05,
      "loss": 5.0286,
      "step": 2450
    },
    {
      "epoch": 0.24,
      "grad_norm": 2.660379409790039,
      "learning_rate": 3.7962158509508647e-05,
      "loss": 5.0019,
      "step": 2500
    },
    {
      "epoch": 0.25,
      "grad_norm": 2.5368001461029053,
      "learning_rate": 3.77208224732117e-05,
      "loss": 4.9537,
      "step": 2550
    },
    {
      "epoch": 0.25,
      "grad_norm": 1.6601139307022095,
      "learning_rate": 3.747948643691476e-05,
      "loss": 4.9717,
      "step": 2600
    },
    {
      "epoch": 0.26,
      "grad_norm": 2.1053977012634277,
      "learning_rate": 3.723815040061782e-05,
      "loss": 4.9785,
      "step": 2650
    },
    {
      "epoch": 0.26,
      "grad_norm": 2.1456222534179688,
      "learning_rate": 3.699681436432088e-05,
      "loss": 4.9484,
      "step": 2700
    },
    {
      "epoch": 0.27,
      "grad_norm": 2.2360620498657227,
      "learning_rate": 3.675547832802394e-05,
      "loss": 4.983,
      "step": 2750
    },
    {
      "epoch": 0.27,
      "grad_norm": 2.4447338581085205,
      "learning_rate": 3.6514142291727e-05,
      "loss": 4.9384,
      "step": 2800
    },
    {
      "epoch": 0.28,
      "grad_norm": 2.204437732696533,
      "learning_rate": 3.627280625543006e-05,
      "loss": 4.9441,
      "step": 2850
    },
    {
      "epoch": 0.28,
      "grad_norm": 2.011445999145508,
      "learning_rate": 3.603147021913312e-05,
      "loss": 4.9201,
      "step": 2900
    },
    {
      "epoch": 0.28,
      "grad_norm": 2.8652260303497314,
      "learning_rate": 3.579013418283618e-05,
      "loss": 4.9128,
      "step": 2950
    },
    {
      "epoch": 0.29,
      "grad_norm": 2.0007762908935547,
      "learning_rate": 3.554879814653924e-05,
      "loss": 4.9256,
      "step": 3000
    },
    {
      "epoch": 0.29,
      "eval_loss": 4.906777858734131,
      "eval_runtime": 391.1543,
      "eval_samples_per_second": 159.865,
      "eval_steps_per_second": 2.5,
      "step": 3000
    },
    {
      "epoch": 0.29,
      "grad_norm": 1.4503604173660278,
      "learning_rate": 3.5307462110242303e-05,
      "loss": 4.8857,
      "step": 3050
    },
    {
      "epoch": 0.3,
      "grad_norm": 2.306293487548828,
      "learning_rate": 3.5066126073945364e-05,
      "loss": 4.8917,
      "step": 3100
    },
    {
      "epoch": 0.3,
      "grad_norm": 1.9790308475494385,
      "learning_rate": 3.4824790037648424e-05,
      "loss": 4.8821,
      "step": 3150
    },
    {
      "epoch": 0.31,
      "grad_norm": 2.0391502380371094,
      "learning_rate": 3.4583454001351484e-05,
      "loss": 4.882,
      "step": 3200
    },
    {
      "epoch": 0.31,
      "grad_norm": 1.755759358406067,
      "learning_rate": 3.4342117965054545e-05,
      "loss": 4.8885,
      "step": 3250
    },
    {
      "epoch": 0.32,
      "grad_norm": 1.326018214225769,
      "learning_rate": 3.4100781928757605e-05,
      "loss": 4.8765,
      "step": 3300
    },
    {
      "epoch": 0.32,
      "grad_norm": 3.4575374126434326,
      "learning_rate": 3.385944589246066e-05,
      "loss": 4.8302,
      "step": 3350
    },
    {
      "epoch": 0.33,
      "grad_norm": 3.7555906772613525,
      "learning_rate": 3.3618109856163726e-05,
      "loss": 4.8614,
      "step": 3400
    },
    {
      "epoch": 0.33,
      "grad_norm": 1.2058850526809692,
      "learning_rate": 3.3376773819866786e-05,
      "loss": 4.8512,
      "step": 3450
    },
    {
      "epoch": 0.34,
      "grad_norm": 1.600963830947876,
      "learning_rate": 3.3135437783569846e-05,
      "loss": 4.8278,
      "step": 3500
    },
    {
      "epoch": 0.34,
      "grad_norm": 2.186601161956787,
      "learning_rate": 3.289410174727291e-05,
      "loss": 4.8162,
      "step": 3550
    },
    {
      "epoch": 0.35,
      "grad_norm": 2.028148651123047,
      "learning_rate": 3.265276571097596e-05,
      "loss": 4.8093,
      "step": 3600
    },
    {
      "epoch": 0.35,
      "grad_norm": 1.8680585622787476,
      "learning_rate": 3.241142967467902e-05,
      "loss": 4.8457,
      "step": 3650
    },
    {
      "epoch": 0.36,
      "grad_norm": 2.528939962387085,
      "learning_rate": 3.217009363838209e-05,
      "loss": 4.82,
      "step": 3700
    },
    {
      "epoch": 0.36,
      "grad_norm": 3.398200273513794,
      "learning_rate": 3.192875760208515e-05,
      "loss": 4.8211,
      "step": 3750
    },
    {
      "epoch": 0.37,
      "grad_norm": 1.9487873315811157,
      "learning_rate": 3.168742156578821e-05,
      "loss": 4.8109,
      "step": 3800
    },
    {
      "epoch": 0.37,
      "grad_norm": 2.149264097213745,
      "learning_rate": 3.144608552949126e-05,
      "loss": 4.8097,
      "step": 3850
    },
    {
      "epoch": 0.38,
      "grad_norm": 1.5911574363708496,
      "learning_rate": 3.120474949319432e-05,
      "loss": 4.7927,
      "step": 3900
    },
    {
      "epoch": 0.38,
      "grad_norm": 1.3407843112945557,
      "learning_rate": 3.096341345689738e-05,
      "loss": 4.8173,
      "step": 3950
    },
    {
      "epoch": 0.39,
      "grad_norm": 2.3371312618255615,
      "learning_rate": 3.072207742060045e-05,
      "loss": 4.7936,
      "step": 4000
    },
    {
      "epoch": 0.39,
      "eval_loss": 4.795432090759277,
      "eval_runtime": 391.0919,
      "eval_samples_per_second": 159.891,
      "eval_steps_per_second": 2.501,
      "step": 4000
    },
    {
      "epoch": 0.39,
      "grad_norm": 2.4239749908447266,
      "learning_rate": 3.0480741384303507e-05,
      "loss": 4.7851,
      "step": 4050
    },
    {
      "epoch": 0.4,
      "grad_norm": 1.8951692581176758,
      "learning_rate": 3.0239405348006567e-05,
      "loss": 4.7856,
      "step": 4100
    },
    {
      "epoch": 0.4,
      "grad_norm": 2.0463273525238037,
      "learning_rate": 2.9998069311709624e-05,
      "loss": 4.777,
      "step": 4150
    },
    {
      "epoch": 0.41,
      "grad_norm": 1.5413366556167603,
      "learning_rate": 2.9756733275412684e-05,
      "loss": 4.7709,
      "step": 4200
    },
    {
      "epoch": 0.41,
      "grad_norm": 1.8159756660461426,
      "learning_rate": 2.9515397239115745e-05,
      "loss": 4.7792,
      "step": 4250
    },
    {
      "epoch": 0.42,
      "grad_norm": 2.3354074954986572,
      "learning_rate": 2.927406120281881e-05,
      "loss": 4.777,
      "step": 4300
    },
    {
      "epoch": 0.42,
      "grad_norm": 2.2329764366149902,
      "learning_rate": 2.903272516652187e-05,
      "loss": 4.7868,
      "step": 4350
    },
    {
      "epoch": 0.42,
      "grad_norm": 2.0843729972839355,
      "learning_rate": 2.8791389130224926e-05,
      "loss": 4.7561,
      "step": 4400
    },
    {
      "epoch": 0.43,
      "grad_norm": 2.231208324432373,
      "learning_rate": 2.8550053093927986e-05,
      "loss": 4.7629,
      "step": 4450
    },
    {
      "epoch": 0.43,
      "grad_norm": 2.3801331520080566,
      "learning_rate": 2.8308717057631046e-05,
      "loss": 4.7481,
      "step": 4500
    },
    {
      "epoch": 0.44,
      "grad_norm": 2.0140020847320557,
      "learning_rate": 2.8067381021334103e-05,
      "loss": 4.7568,
      "step": 4550
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.6526293754577637,
      "learning_rate": 2.782604498503717e-05,
      "loss": 4.7608,
      "step": 4600
    },
    {
      "epoch": 0.45,
      "grad_norm": 2.0324714183807373,
      "learning_rate": 2.7584708948740227e-05,
      "loss": 4.7409,
      "step": 4650
    },
    {
      "epoch": 0.45,
      "grad_norm": 2.2981746196746826,
      "learning_rate": 2.7343372912443288e-05,
      "loss": 4.7486,
      "step": 4700
    },
    {
      "epoch": 0.46,
      "grad_norm": 2.951017141342163,
      "learning_rate": 2.7102036876146348e-05,
      "loss": 4.7194,
      "step": 4750
    },
    {
      "epoch": 0.46,
      "grad_norm": 1.5791761875152588,
      "learning_rate": 2.6860700839849405e-05,
      "loss": 4.7247,
      "step": 4800
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.5944311618804932,
      "learning_rate": 2.6619364803552465e-05,
      "loss": 4.7294,
      "step": 4850
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.6511133909225464,
      "learning_rate": 2.637802876725553e-05,
      "loss": 4.7307,
      "step": 4900
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.8739252090454102,
      "learning_rate": 2.613669273095859e-05,
      "loss": 4.7301,
      "step": 4950
    },
    {
      "epoch": 0.48,
      "grad_norm": 2.471421957015991,
      "learning_rate": 2.589535669466165e-05,
      "loss": 4.7192,
      "step": 5000
    },
    {
      "epoch": 0.48,
      "eval_loss": 4.725518703460693,
      "eval_runtime": 389.5264,
      "eval_samples_per_second": 160.533,
      "eval_steps_per_second": 2.511,
      "step": 5000
    },
    {
      "epoch": 0.49,
      "grad_norm": 2.461144208908081,
      "learning_rate": 2.5654020658364707e-05,
      "loss": 4.7249,
      "step": 5050
    },
    {
      "epoch": 0.49,
      "grad_norm": 2.5357837677001953,
      "learning_rate": 2.5412684622067767e-05,
      "loss": 4.7247,
      "step": 5100
    },
    {
      "epoch": 0.5,
      "grad_norm": 2.3492965698242188,
      "learning_rate": 2.5171348585770827e-05,
      "loss": 4.7332,
      "step": 5150
    },
    {
      "epoch": 0.5,
      "grad_norm": 2.201955795288086,
      "learning_rate": 2.4930012549473888e-05,
      "loss": 4.7063,
      "step": 5200
    },
    {
      "epoch": 0.51,
      "grad_norm": 1.7861882448196411,
      "learning_rate": 2.4688676513176948e-05,
      "loss": 4.7147,
      "step": 5250
    },
    {
      "epoch": 0.51,
      "grad_norm": 1.995993733406067,
      "learning_rate": 2.444734047688001e-05,
      "loss": 4.7155,
      "step": 5300
    },
    {
      "epoch": 0.52,
      "grad_norm": 2.458087921142578,
      "learning_rate": 2.420600444058307e-05,
      "loss": 4.7127,
      "step": 5350
    },
    {
      "epoch": 0.52,
      "grad_norm": 1.8038725852966309,
      "learning_rate": 2.396466840428613e-05,
      "loss": 4.695,
      "step": 5400
    },
    {
      "epoch": 0.53,
      "grad_norm": 1.7122173309326172,
      "learning_rate": 2.372333236798919e-05,
      "loss": 4.7166,
      "step": 5450
    },
    {
      "epoch": 0.53,
      "grad_norm": 2.915121555328369,
      "learning_rate": 2.348199633169225e-05,
      "loss": 4.6978,
      "step": 5500
    },
    {
      "epoch": 0.54,
      "grad_norm": 1.4485961198806763,
      "learning_rate": 2.324066029539531e-05,
      "loss": 4.704,
      "step": 5550
    },
    {
      "epoch": 0.54,
      "grad_norm": 2.308647871017456,
      "learning_rate": 2.299932425909837e-05,
      "loss": 4.6814,
      "step": 5600
    },
    {
      "epoch": 0.55,
      "grad_norm": 1.7238328456878662,
      "learning_rate": 2.275798822280143e-05,
      "loss": 4.6865,
      "step": 5650
    },
    {
      "epoch": 0.55,
      "grad_norm": 1.8059861660003662,
      "learning_rate": 2.2516652186504488e-05,
      "loss": 4.6932,
      "step": 5700
    },
    {
      "epoch": 0.56,
      "grad_norm": 2.0375816822052,
      "learning_rate": 2.227531615020755e-05,
      "loss": 4.6905,
      "step": 5750
    },
    {
      "epoch": 0.56,
      "grad_norm": 1.7443708181381226,
      "learning_rate": 2.2033980113910612e-05,
      "loss": 4.6638,
      "step": 5800
    },
    {
      "epoch": 0.56,
      "grad_norm": 2.3281242847442627,
      "learning_rate": 2.179264407761367e-05,
      "loss": 4.6711,
      "step": 5850
    },
    {
      "epoch": 0.57,
      "grad_norm": 1.7117031812667847,
      "learning_rate": 2.1551308041316732e-05,
      "loss": 4.6768,
      "step": 5900
    },
    {
      "epoch": 0.57,
      "grad_norm": 2.4154622554779053,
      "learning_rate": 2.130997200501979e-05,
      "loss": 4.6779,
      "step": 5950
    },
    {
      "epoch": 0.58,
      "grad_norm": 1.7409700155258179,
      "learning_rate": 2.106863596872285e-05,
      "loss": 4.6674,
      "step": 6000
    },
    {
      "epoch": 0.58,
      "eval_loss": 4.672342300415039,
      "eval_runtime": 389.7713,
      "eval_samples_per_second": 160.433,
      "eval_steps_per_second": 2.509,
      "step": 6000
    },
    {
      "epoch": 0.58,
      "grad_norm": 1.8952521085739136,
      "learning_rate": 2.082729993242591e-05,
      "loss": 4.6672,
      "step": 6050
    },
    {
      "epoch": 0.59,
      "grad_norm": 1.9229673147201538,
      "learning_rate": 2.058596389612897e-05,
      "loss": 4.6657,
      "step": 6100
    },
    {
      "epoch": 0.59,
      "grad_norm": 1.6165590286254883,
      "learning_rate": 2.034462785983203e-05,
      "loss": 4.6553,
      "step": 6150
    },
    {
      "epoch": 0.6,
      "grad_norm": 2.616081953048706,
      "learning_rate": 2.010329182353509e-05,
      "loss": 4.6851,
      "step": 6200
    },
    {
      "epoch": 0.6,
      "grad_norm": 2.7832562923431396,
      "learning_rate": 1.986195578723815e-05,
      "loss": 4.645,
      "step": 6250
    },
    {
      "epoch": 0.61,
      "grad_norm": 1.8077982664108276,
      "learning_rate": 1.962061975094121e-05,
      "loss": 4.6508,
      "step": 6300
    },
    {
      "epoch": 0.61,
      "grad_norm": 2.6406850814819336,
      "learning_rate": 1.9379283714644272e-05,
      "loss": 4.6537,
      "step": 6350
    },
    {
      "epoch": 0.62,
      "grad_norm": 2.762362480163574,
      "learning_rate": 1.9137947678347332e-05,
      "loss": 4.6514,
      "step": 6400
    },
    {
      "epoch": 0.62,
      "grad_norm": 2.4023027420043945,
      "learning_rate": 1.889661164205039e-05,
      "loss": 4.6715,
      "step": 6450
    },
    {
      "epoch": 0.63,
      "grad_norm": 2.401165246963501,
      "learning_rate": 1.8655275605753453e-05,
      "loss": 4.6268,
      "step": 6500
    },
    {
      "epoch": 0.63,
      "grad_norm": 2.6430349349975586,
      "learning_rate": 1.8413939569456513e-05,
      "loss": 4.6413,
      "step": 6550
    },
    {
      "epoch": 0.64,
      "grad_norm": 1.6765092611312866,
      "learning_rate": 1.817260353315957e-05,
      "loss": 4.6519,
      "step": 6600
    },
    {
      "epoch": 0.64,
      "grad_norm": 2.8983302116394043,
      "learning_rate": 1.7931267496862634e-05,
      "loss": 4.6375,
      "step": 6650
    },
    {
      "epoch": 0.65,
      "grad_norm": 2.218233346939087,
      "learning_rate": 1.768993146056569e-05,
      "loss": 4.6602,
      "step": 6700
    },
    {
      "epoch": 0.65,
      "grad_norm": 2.416003704071045,
      "learning_rate": 1.744859542426875e-05,
      "loss": 4.6562,
      "step": 6750
    },
    {
      "epoch": 0.66,
      "grad_norm": 2.1377274990081787,
      "learning_rate": 1.7207259387971815e-05,
      "loss": 4.6399,
      "step": 6800
    },
    {
      "epoch": 0.66,
      "grad_norm": 2.274496078491211,
      "learning_rate": 1.6965923351674872e-05,
      "loss": 4.6448,
      "step": 6850
    },
    {
      "epoch": 0.67,
      "grad_norm": 1.7127264738082886,
      "learning_rate": 1.6724587315377932e-05,
      "loss": 4.65,
      "step": 6900
    },
    {
      "epoch": 0.67,
      "grad_norm": 2.6648058891296387,
      "learning_rate": 1.6483251279080993e-05,
      "loss": 4.6463,
      "step": 6950
    },
    {
      "epoch": 0.68,
      "grad_norm": 3.421499252319336,
      "learning_rate": 1.6241915242784053e-05,
      "loss": 4.6493,
      "step": 7000
    },
    {
      "epoch": 0.68,
      "eval_loss": 4.637113094329834,
      "eval_runtime": 390.3609,
      "eval_samples_per_second": 160.19,
      "eval_steps_per_second": 2.505,
      "step": 7000
    },
    {
      "epoch": 0.68,
      "grad_norm": 2.1961586475372314,
      "learning_rate": 1.6000579206487113e-05,
      "loss": 4.6328,
      "step": 7050
    },
    {
      "epoch": 0.69,
      "grad_norm": 2.1489076614379883,
      "learning_rate": 1.5759243170190174e-05,
      "loss": 4.6427,
      "step": 7100
    },
    {
      "epoch": 0.69,
      "grad_norm": 1.6598464250564575,
      "learning_rate": 1.5517907133893234e-05,
      "loss": 4.6081,
      "step": 7150
    },
    {
      "epoch": 0.7,
      "grad_norm": 3.7071683406829834,
      "learning_rate": 1.5276571097596294e-05,
      "loss": 4.6092,
      "step": 7200
    },
    {
      "epoch": 0.7,
      "grad_norm": 3.6793789863586426,
      "learning_rate": 1.5035235061299355e-05,
      "loss": 4.6281,
      "step": 7250
    },
    {
      "epoch": 0.7,
      "grad_norm": 2.5631256103515625,
      "learning_rate": 1.4793899025002413e-05,
      "loss": 4.6168,
      "step": 7300
    },
    {
      "epoch": 0.71,
      "grad_norm": 1.644603967666626,
      "learning_rate": 1.4552562988705474e-05,
      "loss": 4.6132,
      "step": 7350
    },
    {
      "epoch": 0.71,
      "grad_norm": 2.367464780807495,
      "learning_rate": 1.4311226952408536e-05,
      "loss": 4.6178,
      "step": 7400
    },
    {
      "epoch": 0.72,
      "grad_norm": 1.6489429473876953,
      "learning_rate": 1.4069890916111594e-05,
      "loss": 4.6291,
      "step": 7450
    },
    {
      "epoch": 0.72,
      "grad_norm": 2.5491204261779785,
      "learning_rate": 1.3828554879814653e-05,
      "loss": 4.604,
      "step": 7500
    },
    {
      "epoch": 0.73,
      "grad_norm": 2.025829553604126,
      "learning_rate": 1.3587218843517715e-05,
      "loss": 4.6139,
      "step": 7550
    },
    {
      "epoch": 0.73,
      "grad_norm": 1.8924505710601807,
      "learning_rate": 1.3345882807220775e-05,
      "loss": 4.6254,
      "step": 7600
    },
    {
      "epoch": 0.74,
      "grad_norm": 2.005809783935547,
      "learning_rate": 1.3104546770923834e-05,
      "loss": 4.6231,
      "step": 7650
    },
    {
      "epoch": 0.74,
      "grad_norm": 1.6035338640213013,
      "learning_rate": 1.2863210734626896e-05,
      "loss": 4.6115,
      "step": 7700
    },
    {
      "epoch": 0.75,
      "grad_norm": 1.7871103286743164,
      "learning_rate": 1.2621874698329955e-05,
      "loss": 4.6219,
      "step": 7750
    },
    {
      "epoch": 0.75,
      "grad_norm": 1.9751055240631104,
      "learning_rate": 1.2380538662033015e-05,
      "loss": 4.61,
      "step": 7800
    },
    {
      "epoch": 0.76,
      "grad_norm": 2.315668821334839,
      "learning_rate": 1.2139202625736075e-05,
      "loss": 4.6023,
      "step": 7850
    },
    {
      "epoch": 0.76,
      "grad_norm": 1.5760248899459839,
      "learning_rate": 1.1897866589439136e-05,
      "loss": 4.6137,
      "step": 7900
    },
    {
      "epoch": 0.77,
      "grad_norm": 1.7436636686325073,
      "learning_rate": 1.1656530553142196e-05,
      "loss": 4.6251,
      "step": 7950
    },
    {
      "epoch": 0.77,
      "grad_norm": 1.8873209953308105,
      "learning_rate": 1.1415194516845255e-05,
      "loss": 4.603,
      "step": 8000
    },
    {
      "epoch": 0.77,
      "eval_loss": 4.61085844039917,
      "eval_runtime": 390.2488,
      "eval_samples_per_second": 160.236,
      "eval_steps_per_second": 2.506,
      "step": 8000
    },
    {
      "epoch": 0.78,
      "grad_norm": 1.3575526475906372,
      "learning_rate": 1.1173858480548317e-05,
      "loss": 4.6146,
      "step": 8050
    },
    {
      "epoch": 0.78,
      "grad_norm": 1.552125334739685,
      "learning_rate": 1.0932522444251377e-05,
      "loss": 4.5967,
      "step": 8100
    },
    {
      "epoch": 0.79,
      "grad_norm": 1.9629712104797363,
      "learning_rate": 1.0691186407954436e-05,
      "loss": 4.6252,
      "step": 8150
    },
    {
      "epoch": 0.79,
      "grad_norm": 1.8006943464279175,
      "learning_rate": 1.0449850371657496e-05,
      "loss": 4.6102,
      "step": 8200
    },
    {
      "epoch": 0.8,
      "grad_norm": 1.623297929763794,
      "learning_rate": 1.0208514335360556e-05,
      "loss": 4.6115,
      "step": 8250
    },
    {
      "epoch": 0.8,
      "grad_norm": 1.5186964273452759,
      "learning_rate": 9.967178299063617e-06,
      "loss": 4.6083,
      "step": 8300
    },
    {
      "epoch": 0.81,
      "grad_norm": 1.579399585723877,
      "learning_rate": 9.725842262766677e-06,
      "loss": 4.6156,
      "step": 8350
    },
    {
      "epoch": 0.81,
      "grad_norm": 2.3760528564453125,
      "learning_rate": 9.484506226469737e-06,
      "loss": 4.6064,
      "step": 8400
    },
    {
      "epoch": 0.82,
      "grad_norm": 1.7166615724563599,
      "learning_rate": 9.243170190172796e-06,
      "loss": 4.6023,
      "step": 8450
    },
    {
      "epoch": 0.82,
      "grad_norm": 1.7026691436767578,
      "learning_rate": 9.001834153875858e-06,
      "loss": 4.6087,
      "step": 8500
    },
    {
      "epoch": 0.83,
      "grad_norm": 1.7091957330703735,
      "learning_rate": 8.760498117578918e-06,
      "loss": 4.5865,
      "step": 8550
    },
    {
      "epoch": 0.83,
      "grad_norm": 1.7539598941802979,
      "learning_rate": 8.519162081281977e-06,
      "loss": 4.5975,
      "step": 8600
    },
    {
      "epoch": 0.84,
      "grad_norm": 1.7009996175765991,
      "learning_rate": 8.277826044985037e-06,
      "loss": 4.5955,
      "step": 8650
    },
    {
      "epoch": 0.84,
      "grad_norm": 1.3922252655029297,
      "learning_rate": 8.036490008688098e-06,
      "loss": 4.5885,
      "step": 8700
    },
    {
      "epoch": 0.84,
      "grad_norm": 1.5575711727142334,
      "learning_rate": 7.795153972391158e-06,
      "loss": 4.5956,
      "step": 8750
    },
    {
      "epoch": 0.85,
      "grad_norm": 2.105097770690918,
      "learning_rate": 7.553817936094218e-06,
      "loss": 4.6022,
      "step": 8800
    },
    {
      "epoch": 0.85,
      "grad_norm": 1.443579077720642,
      "learning_rate": 7.312481899797279e-06,
      "loss": 4.5971,
      "step": 8850
    },
    {
      "epoch": 0.86,
      "grad_norm": 1.6904555559158325,
      "learning_rate": 7.071145863500338e-06,
      "loss": 4.602,
      "step": 8900
    },
    {
      "epoch": 0.86,
      "grad_norm": 1.6709128618240356,
      "learning_rate": 6.8298098272033984e-06,
      "loss": 4.601,
      "step": 8950
    },
    {
      "epoch": 0.87,
      "grad_norm": 1.939206600189209,
      "learning_rate": 6.588473790906459e-06,
      "loss": 4.6016,
      "step": 9000
    },
    {
      "epoch": 0.87,
      "eval_loss": 4.5946044921875,
      "eval_runtime": 390.7927,
      "eval_samples_per_second": 160.013,
      "eval_steps_per_second": 2.503,
      "step": 9000
    },
    {
      "epoch": 0.87,
      "grad_norm": 1.4038548469543457,
      "learning_rate": 6.347137754609518e-06,
      "loss": 4.5891,
      "step": 9050
    },
    {
      "epoch": 0.88,
      "grad_norm": 2.320909261703491,
      "learning_rate": 6.105801718312579e-06,
      "loss": 4.5803,
      "step": 9100
    },
    {
      "epoch": 0.88,
      "grad_norm": 2.5142433643341064,
      "learning_rate": 5.864465682015639e-06,
      "loss": 4.5872,
      "step": 9150
    },
    {
      "epoch": 0.89,
      "grad_norm": 1.7421056032180786,
      "learning_rate": 5.623129645718699e-06,
      "loss": 4.6004,
      "step": 9200
    },
    {
      "epoch": 0.89,
      "grad_norm": 1.540666103363037,
      "learning_rate": 5.381793609421759e-06,
      "loss": 4.6077,
      "step": 9250
    },
    {
      "epoch": 0.9,
      "grad_norm": 1.754433274269104,
      "learning_rate": 5.140457573124819e-06,
      "loss": 4.6101,
      "step": 9300
    },
    {
      "epoch": 0.9,
      "grad_norm": 1.9836310148239136,
      "learning_rate": 4.8991215368278794e-06,
      "loss": 4.578,
      "step": 9350
    },
    {
      "epoch": 0.91,
      "grad_norm": 1.645308256149292,
      "learning_rate": 4.65778550053094e-06,
      "loss": 4.5755,
      "step": 9400
    },
    {
      "epoch": 0.91,
      "grad_norm": 1.8888880014419556,
      "learning_rate": 4.416449464233999e-06,
      "loss": 4.5806,
      "step": 9450
    },
    {
      "epoch": 0.92,
      "grad_norm": 1.6127095222473145,
      "learning_rate": 4.1751134279370604e-06,
      "loss": 4.5878,
      "step": 9500
    },
    {
      "epoch": 0.92,
      "grad_norm": 1.7448158264160156,
      "learning_rate": 3.93377739164012e-06,
      "loss": 4.5933,
      "step": 9550
    },
    {
      "epoch": 0.93,
      "grad_norm": 1.988232970237732,
      "learning_rate": 3.69244135534318e-06,
      "loss": 4.5749,
      "step": 9600
    },
    {
      "epoch": 0.93,
      "grad_norm": 1.3677701950073242,
      "learning_rate": 3.4511053190462406e-06,
      "loss": 4.5928,
      "step": 9650
    },
    {
      "epoch": 0.94,
      "grad_norm": 1.485508680343628,
      "learning_rate": 3.2097692827493005e-06,
      "loss": 4.5885,
      "step": 9700
    },
    {
      "epoch": 0.94,
      "grad_norm": 1.4559518098831177,
      "learning_rate": 2.9684332464523604e-06,
      "loss": 4.5863,
      "step": 9750
    },
    {
      "epoch": 0.95,
      "grad_norm": 1.6585900783538818,
      "learning_rate": 2.7270972101554203e-06,
      "loss": 4.5763,
      "step": 9800
    },
    {
      "epoch": 0.95,
      "grad_norm": 1.3562431335449219,
      "learning_rate": 2.4857611738584807e-06,
      "loss": 4.5673,
      "step": 9850
    },
    {
      "epoch": 0.96,
      "grad_norm": 2.229231595993042,
      "learning_rate": 2.2444251375615406e-06,
      "loss": 4.5722,
      "step": 9900
    },
    {
      "epoch": 0.96,
      "grad_norm": 1.4842349290847778,
      "learning_rate": 2.003089101264601e-06,
      "loss": 4.5604,
      "step": 9950
    },
    {
      "epoch": 0.97,
      "grad_norm": 1.3477336168289185,
      "learning_rate": 1.761753064967661e-06,
      "loss": 4.5684,
      "step": 10000
    },
    {
      "epoch": 0.97,
      "eval_loss": 4.584888458251953,
      "eval_runtime": 390.0637,
      "eval_samples_per_second": 160.312,
      "eval_steps_per_second": 2.507,
      "step": 10000
    }
  ],
  "logging_steps": 50,
  "max_steps": 10359,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 2000,
  "total_flos": 8.141383139328e+16,
  "train_batch_size": 48,
  "trial_name": null,
  "trial_params": null
}
