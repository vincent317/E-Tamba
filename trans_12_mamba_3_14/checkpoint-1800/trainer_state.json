{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.9841779721833032,
  "eval_steps": 900,
  "global_step": 1800,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0054676554010183506,
      "grad_norm": 5.132281303405762,
      "learning_rate": 0.0001,
      "loss": 6.751,
      "step": 10
    },
    {
      "epoch": 0.010935310802036701,
      "grad_norm": 2.472959041595459,
      "learning_rate": 0.0001,
      "loss": 4.4537,
      "step": 20
    },
    {
      "epoch": 0.016402966203055053,
      "grad_norm": 2.822592258453369,
      "learning_rate": 0.0001,
      "loss": 4.1339,
      "step": 30
    },
    {
      "epoch": 0.021870621604073402,
      "grad_norm": 1.8891185522079468,
      "learning_rate": 0.0001,
      "loss": 4.0237,
      "step": 40
    },
    {
      "epoch": 0.027338277005091755,
      "grad_norm": 2.0143380165100098,
      "learning_rate": 0.0001,
      "loss": 3.9949,
      "step": 50
    },
    {
      "epoch": 0.03280593240611011,
      "grad_norm": 1.612397313117981,
      "learning_rate": 0.0001,
      "loss": 3.9223,
      "step": 60
    },
    {
      "epoch": 0.03827358780712846,
      "grad_norm": 1.656925916671753,
      "learning_rate": 0.0001,
      "loss": 3.8389,
      "step": 70
    },
    {
      "epoch": 0.043741243208146804,
      "grad_norm": 1.6736817359924316,
      "learning_rate": 0.0001,
      "loss": 3.8018,
      "step": 80
    },
    {
      "epoch": 0.04920889860916516,
      "grad_norm": 1.6560380458831787,
      "learning_rate": 0.0001,
      "loss": 3.8273,
      "step": 90
    },
    {
      "epoch": 0.05467655401018351,
      "grad_norm": 1.7402106523513794,
      "learning_rate": 0.0001,
      "loss": 3.7874,
      "step": 100
    },
    {
      "epoch": 0.06014420941120186,
      "grad_norm": 1.488500714302063,
      "learning_rate": 0.0001,
      "loss": 3.7478,
      "step": 110
    },
    {
      "epoch": 0.06561186481222021,
      "grad_norm": 1.5264443159103394,
      "learning_rate": 0.0001,
      "loss": 3.7311,
      "step": 120
    },
    {
      "epoch": 0.07107952021323856,
      "grad_norm": 1.4902325868606567,
      "learning_rate": 0.0001,
      "loss": 3.6899,
      "step": 130
    },
    {
      "epoch": 0.07654717561425692,
      "grad_norm": 1.5021576881408691,
      "learning_rate": 0.0001,
      "loss": 3.7288,
      "step": 140
    },
    {
      "epoch": 0.08201483101527526,
      "grad_norm": 1.5663137435913086,
      "learning_rate": 0.0001,
      "loss": 3.7042,
      "step": 150
    },
    {
      "epoch": 0.08748248641629361,
      "grad_norm": 1.4985665082931519,
      "learning_rate": 0.0001,
      "loss": 3.6757,
      "step": 160
    },
    {
      "epoch": 0.09295014181731197,
      "grad_norm": 1.83270263671875,
      "learning_rate": 0.0001,
      "loss": 3.7153,
      "step": 170
    },
    {
      "epoch": 0.09841779721833031,
      "grad_norm": 1.510211706161499,
      "learning_rate": 0.0001,
      "loss": 3.6914,
      "step": 180
    },
    {
      "epoch": 0.10388545261934866,
      "grad_norm": 1.4605191946029663,
      "learning_rate": 0.0001,
      "loss": 3.6938,
      "step": 190
    },
    {
      "epoch": 0.10935310802036702,
      "grad_norm": 1.5263104438781738,
      "learning_rate": 0.0001,
      "loss": 3.6939,
      "step": 200
    },
    {
      "epoch": 0.11482076342138536,
      "grad_norm": 1.362489938735962,
      "learning_rate": 0.0001,
      "loss": 3.6994,
      "step": 210
    },
    {
      "epoch": 0.12028841882240372,
      "grad_norm": 1.4122778177261353,
      "learning_rate": 0.0001,
      "loss": 3.6657,
      "step": 220
    },
    {
      "epoch": 0.12575607422342208,
      "grad_norm": 1.582255482673645,
      "learning_rate": 0.0001,
      "loss": 3.6504,
      "step": 230
    },
    {
      "epoch": 0.13122372962444043,
      "grad_norm": 1.397373080253601,
      "learning_rate": 0.0001,
      "loss": 3.6511,
      "step": 240
    },
    {
      "epoch": 0.13669138502545877,
      "grad_norm": 1.480452060699463,
      "learning_rate": 0.0001,
      "loss": 3.7029,
      "step": 250
    },
    {
      "epoch": 0.14215904042647712,
      "grad_norm": 1.4156376123428345,
      "learning_rate": 0.0001,
      "loss": 3.6183,
      "step": 260
    },
    {
      "epoch": 0.14762669582749546,
      "grad_norm": 1.3244590759277344,
      "learning_rate": 0.0001,
      "loss": 3.6394,
      "step": 270
    },
    {
      "epoch": 0.15309435122851384,
      "grad_norm": 1.384212613105774,
      "learning_rate": 0.0001,
      "loss": 3.6126,
      "step": 280
    },
    {
      "epoch": 0.15856200662953218,
      "grad_norm": 1.4705413579940796,
      "learning_rate": 0.0001,
      "loss": 3.6159,
      "step": 290
    },
    {
      "epoch": 0.16402966203055053,
      "grad_norm": 1.7135179042816162,
      "learning_rate": 0.0001,
      "loss": 3.6701,
      "step": 300
    },
    {
      "epoch": 0.16949731743156887,
      "grad_norm": 1.446548581123352,
      "learning_rate": 0.0001,
      "loss": 3.6043,
      "step": 310
    },
    {
      "epoch": 0.17496497283258722,
      "grad_norm": 1.331034779548645,
      "learning_rate": 0.0001,
      "loss": 3.64,
      "step": 320
    },
    {
      "epoch": 0.1804326282336056,
      "grad_norm": 1.4361119270324707,
      "learning_rate": 0.0001,
      "loss": 3.5809,
      "step": 330
    },
    {
      "epoch": 0.18590028363462394,
      "grad_norm": 1.285718560218811,
      "learning_rate": 0.0001,
      "loss": 3.5738,
      "step": 340
    },
    {
      "epoch": 0.19136793903564228,
      "grad_norm": 1.301375389099121,
      "learning_rate": 0.0001,
      "loss": 3.599,
      "step": 350
    },
    {
      "epoch": 0.19683559443666063,
      "grad_norm": 1.4009181261062622,
      "learning_rate": 0.0001,
      "loss": 3.5879,
      "step": 360
    },
    {
      "epoch": 0.20230324983767897,
      "grad_norm": 1.3251330852508545,
      "learning_rate": 0.0001,
      "loss": 3.5944,
      "step": 370
    },
    {
      "epoch": 0.20777090523869732,
      "grad_norm": 1.3589898347854614,
      "learning_rate": 0.0001,
      "loss": 3.6388,
      "step": 380
    },
    {
      "epoch": 0.2132385606397157,
      "grad_norm": 1.442259430885315,
      "learning_rate": 0.0001,
      "loss": 3.5651,
      "step": 390
    },
    {
      "epoch": 0.21870621604073404,
      "grad_norm": 1.2522436380386353,
      "learning_rate": 0.0001,
      "loss": 3.5882,
      "step": 400
    },
    {
      "epoch": 0.22417387144175238,
      "grad_norm": 1.2926222085952759,
      "learning_rate": 0.0001,
      "loss": 3.5913,
      "step": 410
    },
    {
      "epoch": 0.22964152684277073,
      "grad_norm": 1.4573163986206055,
      "learning_rate": 0.0001,
      "loss": 3.569,
      "step": 420
    },
    {
      "epoch": 0.23510918224378907,
      "grad_norm": 1.3636000156402588,
      "learning_rate": 0.0001,
      "loss": 3.5836,
      "step": 430
    },
    {
      "epoch": 0.24057683764480745,
      "grad_norm": 1.2545222043991089,
      "learning_rate": 0.0001,
      "loss": 3.5446,
      "step": 440
    },
    {
      "epoch": 0.2460444930458258,
      "grad_norm": 1.2453532218933105,
      "learning_rate": 0.0001,
      "loss": 3.5634,
      "step": 450
    },
    {
      "epoch": 0.25151214844684416,
      "grad_norm": 1.2033443450927734,
      "learning_rate": 0.0001,
      "loss": 3.5984,
      "step": 460
    },
    {
      "epoch": 0.2569798038478625,
      "grad_norm": 1.4560679197311401,
      "learning_rate": 0.0001,
      "loss": 3.6136,
      "step": 470
    },
    {
      "epoch": 0.26244745924888085,
      "grad_norm": 1.9214560985565186,
      "learning_rate": 0.0001,
      "loss": 3.5415,
      "step": 480
    },
    {
      "epoch": 0.2679151146498992,
      "grad_norm": 1.4065382480621338,
      "learning_rate": 0.0001,
      "loss": 3.5679,
      "step": 490
    },
    {
      "epoch": 0.27338277005091755,
      "grad_norm": 1.3558012247085571,
      "learning_rate": 0.0001,
      "loss": 3.6094,
      "step": 500
    },
    {
      "epoch": 0.2788504254519359,
      "grad_norm": 1.2911077737808228,
      "learning_rate": 0.0001,
      "loss": 3.552,
      "step": 510
    },
    {
      "epoch": 0.28431808085295424,
      "grad_norm": 1.283264398574829,
      "learning_rate": 0.0001,
      "loss": 3.5348,
      "step": 520
    },
    {
      "epoch": 0.2897857362539726,
      "grad_norm": 1.9068974256515503,
      "learning_rate": 0.0001,
      "loss": 3.5089,
      "step": 530
    },
    {
      "epoch": 0.2952533916549909,
      "grad_norm": 1.3631443977355957,
      "learning_rate": 0.0001,
      "loss": 3.4933,
      "step": 540
    },
    {
      "epoch": 0.30072104705600927,
      "grad_norm": 1.3448842763900757,
      "learning_rate": 0.0001,
      "loss": 3.5438,
      "step": 550
    },
    {
      "epoch": 0.3061887024570277,
      "grad_norm": 1.3367855548858643,
      "learning_rate": 0.0001,
      "loss": 3.5544,
      "step": 560
    },
    {
      "epoch": 0.311656357858046,
      "grad_norm": 1.2406728267669678,
      "learning_rate": 0.0001,
      "loss": 3.5284,
      "step": 570
    },
    {
      "epoch": 0.31712401325906436,
      "grad_norm": 1.2142161130905151,
      "learning_rate": 0.0001,
      "loss": 3.5459,
      "step": 580
    },
    {
      "epoch": 0.3225916686600827,
      "grad_norm": 1.3100335597991943,
      "learning_rate": 0.0001,
      "loss": 3.535,
      "step": 590
    },
    {
      "epoch": 0.32805932406110105,
      "grad_norm": 1.3041877746582031,
      "learning_rate": 0.0001,
      "loss": 3.5725,
      "step": 600
    },
    {
      "epoch": 0.3335269794621194,
      "grad_norm": 1.387598991394043,
      "learning_rate": 0.0001,
      "loss": 3.5582,
      "step": 610
    },
    {
      "epoch": 0.33899463486313774,
      "grad_norm": 1.3897607326507568,
      "learning_rate": 0.0001,
      "loss": 3.5633,
      "step": 620
    },
    {
      "epoch": 0.3444622902641561,
      "grad_norm": 1.192849040031433,
      "learning_rate": 0.0001,
      "loss": 3.5268,
      "step": 630
    },
    {
      "epoch": 0.34992994566517444,
      "grad_norm": 1.3239500522613525,
      "learning_rate": 0.0001,
      "loss": 3.5519,
      "step": 640
    },
    {
      "epoch": 0.3553976010661928,
      "grad_norm": 1.2438017129898071,
      "learning_rate": 0.0001,
      "loss": 3.5703,
      "step": 650
    },
    {
      "epoch": 0.3608652564672112,
      "grad_norm": 1.1709678173065186,
      "learning_rate": 0.0001,
      "loss": 3.5287,
      "step": 660
    },
    {
      "epoch": 0.3663329118682295,
      "grad_norm": 1.331854224205017,
      "learning_rate": 0.0001,
      "loss": 3.5251,
      "step": 670
    },
    {
      "epoch": 0.3718005672692479,
      "grad_norm": 2.1273610591888428,
      "learning_rate": 0.0001,
      "loss": 3.5089,
      "step": 680
    },
    {
      "epoch": 0.3772682226702662,
      "grad_norm": 1.3352487087249756,
      "learning_rate": 0.0001,
      "loss": 3.5181,
      "step": 690
    },
    {
      "epoch": 0.38273587807128456,
      "grad_norm": 1.2943617105484009,
      "learning_rate": 0.0001,
      "loss": 3.5673,
      "step": 700
    },
    {
      "epoch": 0.3882035334723029,
      "grad_norm": 1.419596791267395,
      "learning_rate": 0.0001,
      "loss": 3.5433,
      "step": 710
    },
    {
      "epoch": 0.39367118887332125,
      "grad_norm": 1.4740294218063354,
      "learning_rate": 0.0001,
      "loss": 3.5511,
      "step": 720
    },
    {
      "epoch": 0.3991388442743396,
      "grad_norm": 1.3491724729537964,
      "learning_rate": 0.0001,
      "loss": 3.4953,
      "step": 730
    },
    {
      "epoch": 0.40460649967535794,
      "grad_norm": 1.3608801364898682,
      "learning_rate": 0.0001,
      "loss": 3.5123,
      "step": 740
    },
    {
      "epoch": 0.4100741550763763,
      "grad_norm": 1.1103992462158203,
      "learning_rate": 0.0001,
      "loss": 3.5491,
      "step": 750
    },
    {
      "epoch": 0.41554181047739464,
      "grad_norm": 1.3049986362457275,
      "learning_rate": 0.0001,
      "loss": 3.5304,
      "step": 760
    },
    {
      "epoch": 0.42100946587841304,
      "grad_norm": 1.314786672592163,
      "learning_rate": 0.0001,
      "loss": 3.5247,
      "step": 770
    },
    {
      "epoch": 0.4264771212794314,
      "grad_norm": 1.2964929342269897,
      "learning_rate": 0.0001,
      "loss": 3.5001,
      "step": 780
    },
    {
      "epoch": 0.4319447766804497,
      "grad_norm": 1.2835575342178345,
      "learning_rate": 0.0001,
      "loss": 3.5211,
      "step": 790
    },
    {
      "epoch": 0.43741243208146807,
      "grad_norm": 1.1925679445266724,
      "learning_rate": 0.0001,
      "loss": 3.4887,
      "step": 800
    },
    {
      "epoch": 0.4428800874824864,
      "grad_norm": 1.3329418897628784,
      "learning_rate": 0.0001,
      "loss": 3.5436,
      "step": 810
    },
    {
      "epoch": 0.44834774288350476,
      "grad_norm": 1.2326335906982422,
      "learning_rate": 0.0001,
      "loss": 3.501,
      "step": 820
    },
    {
      "epoch": 0.4538153982845231,
      "grad_norm": 1.3481501340866089,
      "learning_rate": 0.0001,
      "loss": 3.5354,
      "step": 830
    },
    {
      "epoch": 0.45928305368554145,
      "grad_norm": 1.5197936296463013,
      "learning_rate": 0.0001,
      "loss": 3.567,
      "step": 840
    },
    {
      "epoch": 0.4647507090865598,
      "grad_norm": 1.3030314445495605,
      "learning_rate": 0.0001,
      "loss": 3.5447,
      "step": 850
    },
    {
      "epoch": 0.47021836448757814,
      "grad_norm": 1.1651054620742798,
      "learning_rate": 0.0001,
      "loss": 3.5097,
      "step": 860
    },
    {
      "epoch": 0.47568601988859655,
      "grad_norm": 1.1733566522598267,
      "learning_rate": 0.0001,
      "loss": 3.527,
      "step": 870
    },
    {
      "epoch": 0.4811536752896149,
      "grad_norm": 1.2036515474319458,
      "learning_rate": 0.0001,
      "loss": 3.4898,
      "step": 880
    },
    {
      "epoch": 0.48662133069063324,
      "grad_norm": 1.3825393915176392,
      "learning_rate": 0.0001,
      "loss": 3.4894,
      "step": 890
    },
    {
      "epoch": 0.4920889860916516,
      "grad_norm": 1.335553526878357,
      "learning_rate": 0.0001,
      "loss": 3.4826,
      "step": 900
    },
    {
      "epoch": 0.4920889860916516,
      "eval_loss": 3.49804425239563,
      "eval_runtime": 236.8379,
      "eval_samples_per_second": 48.974,
      "eval_steps_per_second": 12.245,
      "step": 900
    },
    {
      "epoch": 0.4975566414926699,
      "grad_norm": 1.3196134567260742,
      "learning_rate": 0.0001,
      "loss": 3.5086,
      "step": 910
    },
    {
      "epoch": 0.5030242968936883,
      "grad_norm": 1.3023546934127808,
      "learning_rate": 0.0001,
      "loss": 3.5098,
      "step": 920
    },
    {
      "epoch": 0.5084919522947067,
      "grad_norm": 1.3006588220596313,
      "learning_rate": 0.0001,
      "loss": 3.5454,
      "step": 930
    },
    {
      "epoch": 0.513959607695725,
      "grad_norm": 1.598020315170288,
      "learning_rate": 0.0001,
      "loss": 3.5487,
      "step": 940
    },
    {
      "epoch": 0.5194272630967434,
      "grad_norm": 1.2143197059631348,
      "learning_rate": 0.0001,
      "loss": 3.4812,
      "step": 950
    },
    {
      "epoch": 0.5248949184977617,
      "grad_norm": 1.2002195119857788,
      "learning_rate": 0.0001,
      "loss": 3.5144,
      "step": 960
    },
    {
      "epoch": 0.53036257389878,
      "grad_norm": 1.2837754487991333,
      "learning_rate": 0.0001,
      "loss": 3.503,
      "step": 970
    },
    {
      "epoch": 0.5358302292997984,
      "grad_norm": 1.3304804563522339,
      "learning_rate": 0.0001,
      "loss": 3.4946,
      "step": 980
    },
    {
      "epoch": 0.5412978847008167,
      "grad_norm": 1.167749285697937,
      "learning_rate": 0.0001,
      "loss": 3.4629,
      "step": 990
    },
    {
      "epoch": 0.5467655401018351,
      "grad_norm": 1.4000765085220337,
      "learning_rate": 0.0001,
      "loss": 3.5128,
      "step": 1000
    },
    {
      "epoch": 0.5522331955028534,
      "grad_norm": 1.2783151865005493,
      "learning_rate": 0.0001,
      "loss": 3.51,
      "step": 1010
    },
    {
      "epoch": 0.5577008509038718,
      "grad_norm": 1.296910047531128,
      "learning_rate": 0.0001,
      "loss": 3.5171,
      "step": 1020
    },
    {
      "epoch": 0.5631685063048901,
      "grad_norm": 1.3074989318847656,
      "learning_rate": 0.0001,
      "loss": 3.4982,
      "step": 1030
    },
    {
      "epoch": 0.5686361617059085,
      "grad_norm": 1.122219443321228,
      "learning_rate": 0.0001,
      "loss": 3.5028,
      "step": 1040
    },
    {
      "epoch": 0.5741038171069268,
      "grad_norm": 1.4738245010375977,
      "learning_rate": 0.0001,
      "loss": 3.5107,
      "step": 1050
    },
    {
      "epoch": 0.5795714725079452,
      "grad_norm": 2.216632843017578,
      "learning_rate": 0.0001,
      "loss": 3.4254,
      "step": 1060
    },
    {
      "epoch": 0.5850391279089635,
      "grad_norm": 1.2183163166046143,
      "learning_rate": 0.0001,
      "loss": 3.4675,
      "step": 1070
    },
    {
      "epoch": 0.5905067833099819,
      "grad_norm": 1.1152350902557373,
      "learning_rate": 0.0001,
      "loss": 3.4847,
      "step": 1080
    },
    {
      "epoch": 0.5959744387110002,
      "grad_norm": 1.240967869758606,
      "learning_rate": 0.0001,
      "loss": 3.47,
      "step": 1090
    },
    {
      "epoch": 0.6014420941120185,
      "grad_norm": 1.1892855167388916,
      "learning_rate": 0.0001,
      "loss": 3.4652,
      "step": 1100
    },
    {
      "epoch": 0.6069097495130369,
      "grad_norm": 1.1612942218780518,
      "learning_rate": 0.0001,
      "loss": 3.5019,
      "step": 1110
    },
    {
      "epoch": 0.6123774049140553,
      "grad_norm": 1.1524642705917358,
      "learning_rate": 0.0001,
      "loss": 3.5076,
      "step": 1120
    },
    {
      "epoch": 0.6178450603150737,
      "grad_norm": 1.1702306270599365,
      "learning_rate": 0.0001,
      "loss": 3.4544,
      "step": 1130
    },
    {
      "epoch": 0.623312715716092,
      "grad_norm": 1.1886019706726074,
      "learning_rate": 0.0001,
      "loss": 3.5335,
      "step": 1140
    },
    {
      "epoch": 0.6287803711171104,
      "grad_norm": 1.2905160188674927,
      "learning_rate": 0.0001,
      "loss": 3.4954,
      "step": 1150
    },
    {
      "epoch": 0.6342480265181287,
      "grad_norm": 1.198183536529541,
      "learning_rate": 0.0001,
      "loss": 3.4933,
      "step": 1160
    },
    {
      "epoch": 0.6397156819191471,
      "grad_norm": 1.1519486904144287,
      "learning_rate": 0.0001,
      "loss": 3.4612,
      "step": 1170
    },
    {
      "epoch": 0.6451833373201654,
      "grad_norm": 1.1257187128067017,
      "learning_rate": 0.0001,
      "loss": 3.4223,
      "step": 1180
    },
    {
      "epoch": 0.6506509927211838,
      "grad_norm": 1.3404150009155273,
      "learning_rate": 0.0001,
      "loss": 3.5417,
      "step": 1190
    },
    {
      "epoch": 0.6561186481222021,
      "grad_norm": 1.1305599212646484,
      "learning_rate": 0.0001,
      "loss": 3.4474,
      "step": 1200
    },
    {
      "epoch": 0.6615863035232205,
      "grad_norm": 1.205016851425171,
      "learning_rate": 0.0001,
      "loss": 3.5002,
      "step": 1210
    },
    {
      "epoch": 0.6670539589242388,
      "grad_norm": 1.1369143724441528,
      "learning_rate": 0.0001,
      "loss": 3.4676,
      "step": 1220
    },
    {
      "epoch": 0.6725216143252571,
      "grad_norm": 1.1360223293304443,
      "learning_rate": 0.0001,
      "loss": 3.4243,
      "step": 1230
    },
    {
      "epoch": 0.6779892697262755,
      "grad_norm": 1.1882450580596924,
      "learning_rate": 0.0001,
      "loss": 3.4437,
      "step": 1240
    },
    {
      "epoch": 0.6834569251272938,
      "grad_norm": 1.1063848733901978,
      "learning_rate": 0.0001,
      "loss": 3.4621,
      "step": 1250
    },
    {
      "epoch": 0.6889245805283122,
      "grad_norm": 1.1738636493682861,
      "learning_rate": 0.0001,
      "loss": 3.4445,
      "step": 1260
    },
    {
      "epoch": 0.6943922359293305,
      "grad_norm": 1.091110110282898,
      "learning_rate": 0.0001,
      "loss": 3.4509,
      "step": 1270
    },
    {
      "epoch": 0.6998598913303489,
      "grad_norm": 1.1803592443466187,
      "learning_rate": 0.0001,
      "loss": 3.3919,
      "step": 1280
    },
    {
      "epoch": 0.7053275467313672,
      "grad_norm": 1.242100477218628,
      "learning_rate": 0.0001,
      "loss": 3.4571,
      "step": 1290
    },
    {
      "epoch": 0.7107952021323856,
      "grad_norm": 1.1125462055206299,
      "learning_rate": 0.0001,
      "loss": 3.4487,
      "step": 1300
    },
    {
      "epoch": 0.7162628575334039,
      "grad_norm": 1.1819366216659546,
      "learning_rate": 0.0001,
      "loss": 3.4175,
      "step": 1310
    },
    {
      "epoch": 0.7217305129344224,
      "grad_norm": 1.1949609518051147,
      "learning_rate": 0.0001,
      "loss": 3.4483,
      "step": 1320
    },
    {
      "epoch": 0.7271981683354407,
      "grad_norm": 1.1352641582489014,
      "learning_rate": 0.0001,
      "loss": 3.4035,
      "step": 1330
    },
    {
      "epoch": 0.732665823736459,
      "grad_norm": 1.1778836250305176,
      "learning_rate": 0.0001,
      "loss": 3.4716,
      "step": 1340
    },
    {
      "epoch": 0.7381334791374774,
      "grad_norm": 1.127791404724121,
      "learning_rate": 0.0001,
      "loss": 3.4587,
      "step": 1350
    },
    {
      "epoch": 0.7436011345384957,
      "grad_norm": 1.0923744440078735,
      "learning_rate": 0.0001,
      "loss": 3.4266,
      "step": 1360
    },
    {
      "epoch": 0.7490687899395141,
      "grad_norm": 1.071972370147705,
      "learning_rate": 0.0001,
      "loss": 3.4345,
      "step": 1370
    },
    {
      "epoch": 0.7545364453405324,
      "grad_norm": 1.1406863927841187,
      "learning_rate": 0.0001,
      "loss": 3.4218,
      "step": 1380
    },
    {
      "epoch": 0.7600041007415508,
      "grad_norm": 1.2516624927520752,
      "learning_rate": 0.0001,
      "loss": 3.409,
      "step": 1390
    },
    {
      "epoch": 0.7654717561425691,
      "grad_norm": 1.151599645614624,
      "learning_rate": 0.0001,
      "loss": 3.4452,
      "step": 1400
    },
    {
      "epoch": 0.7709394115435875,
      "grad_norm": 1.168190360069275,
      "learning_rate": 0.0001,
      "loss": 3.406,
      "step": 1410
    },
    {
      "epoch": 0.7764070669446058,
      "grad_norm": 1.1974512338638306,
      "learning_rate": 0.0001,
      "loss": 3.4303,
      "step": 1420
    },
    {
      "epoch": 0.7818747223456242,
      "grad_norm": 1.040841817855835,
      "learning_rate": 0.0001,
      "loss": 3.4807,
      "step": 1430
    },
    {
      "epoch": 0.7873423777466425,
      "grad_norm": 1.2193949222564697,
      "learning_rate": 0.0001,
      "loss": 3.4615,
      "step": 1440
    },
    {
      "epoch": 0.7928100331476609,
      "grad_norm": 1.2105457782745361,
      "learning_rate": 0.0001,
      "loss": 3.3908,
      "step": 1450
    },
    {
      "epoch": 0.7982776885486792,
      "grad_norm": 1.1837568283081055,
      "learning_rate": 0.0001,
      "loss": 3.3833,
      "step": 1460
    },
    {
      "epoch": 0.8037453439496975,
      "grad_norm": 1.0845741033554077,
      "learning_rate": 0.0001,
      "loss": 3.4166,
      "step": 1470
    },
    {
      "epoch": 0.8092129993507159,
      "grad_norm": 1.2007958889007568,
      "learning_rate": 0.0001,
      "loss": 3.4117,
      "step": 1480
    },
    {
      "epoch": 0.8146806547517342,
      "grad_norm": 1.0335347652435303,
      "learning_rate": 0.0001,
      "loss": 3.3771,
      "step": 1490
    },
    {
      "epoch": 0.8201483101527526,
      "grad_norm": 1.0929251909255981,
      "learning_rate": 0.0001,
      "loss": 3.3951,
      "step": 1500
    },
    {
      "epoch": 0.8256159655537709,
      "grad_norm": 1.0979098081588745,
      "learning_rate": 0.0001,
      "loss": 3.3681,
      "step": 1510
    },
    {
      "epoch": 0.8310836209547893,
      "grad_norm": 1.1277481317520142,
      "learning_rate": 0.0001,
      "loss": 3.3709,
      "step": 1520
    },
    {
      "epoch": 0.8365512763558077,
      "grad_norm": 1.2343684434890747,
      "learning_rate": 0.0001,
      "loss": 3.3958,
      "step": 1530
    },
    {
      "epoch": 0.8420189317568261,
      "grad_norm": 1.1643351316452026,
      "learning_rate": 0.0001,
      "loss": 3.367,
      "step": 1540
    },
    {
      "epoch": 0.8474865871578444,
      "grad_norm": 1.3626302480697632,
      "learning_rate": 0.0001,
      "loss": 3.3935,
      "step": 1550
    },
    {
      "epoch": 0.8529542425588628,
      "grad_norm": 1.1525287628173828,
      "learning_rate": 0.0001,
      "loss": 3.4133,
      "step": 1560
    },
    {
      "epoch": 0.8584218979598811,
      "grad_norm": 1.1710230112075806,
      "learning_rate": 0.0001,
      "loss": 3.3899,
      "step": 1570
    },
    {
      "epoch": 0.8638895533608995,
      "grad_norm": 1.1121751070022583,
      "learning_rate": 0.0001,
      "loss": 3.4096,
      "step": 1580
    },
    {
      "epoch": 0.8693572087619178,
      "grad_norm": 1.154395580291748,
      "learning_rate": 0.0001,
      "loss": 3.3964,
      "step": 1590
    },
    {
      "epoch": 0.8748248641629361,
      "grad_norm": 1.2158981561660767,
      "learning_rate": 0.0001,
      "loss": 3.4301,
      "step": 1600
    },
    {
      "epoch": 0.8802925195639545,
      "grad_norm": 1.2219127416610718,
      "learning_rate": 0.0001,
      "loss": 3.4003,
      "step": 1610
    },
    {
      "epoch": 0.8857601749649728,
      "grad_norm": 1.1717907190322876,
      "learning_rate": 0.0001,
      "loss": 3.3716,
      "step": 1620
    },
    {
      "epoch": 0.8912278303659912,
      "grad_norm": 1.386429786682129,
      "learning_rate": 0.0001,
      "loss": 3.3774,
      "step": 1630
    },
    {
      "epoch": 0.8966954857670095,
      "grad_norm": 1.1774688959121704,
      "learning_rate": 0.0001,
      "loss": 3.3848,
      "step": 1640
    },
    {
      "epoch": 0.9021631411680279,
      "grad_norm": 1.1356289386749268,
      "learning_rate": 0.0001,
      "loss": 3.3982,
      "step": 1650
    },
    {
      "epoch": 0.9076307965690462,
      "grad_norm": 1.0615222454071045,
      "learning_rate": 0.0001,
      "loss": 3.3914,
      "step": 1660
    },
    {
      "epoch": 0.9130984519700646,
      "grad_norm": 1.2380143404006958,
      "learning_rate": 0.0001,
      "loss": 3.4029,
      "step": 1670
    },
    {
      "epoch": 0.9185661073710829,
      "grad_norm": 1.1310811042785645,
      "learning_rate": 0.0001,
      "loss": 3.3847,
      "step": 1680
    },
    {
      "epoch": 0.9240337627721013,
      "grad_norm": 1.0323221683502197,
      "learning_rate": 0.0001,
      "loss": 3.3645,
      "step": 1690
    },
    {
      "epoch": 0.9295014181731196,
      "grad_norm": 1.1547839641571045,
      "learning_rate": 0.0001,
      "loss": 3.4001,
      "step": 1700
    },
    {
      "epoch": 0.9349690735741379,
      "grad_norm": 1.05658757686615,
      "learning_rate": 0.0001,
      "loss": 3.372,
      "step": 1710
    },
    {
      "epoch": 0.9404367289751563,
      "grad_norm": 1.2620874643325806,
      "learning_rate": 0.0001,
      "loss": 3.3036,
      "step": 1720
    },
    {
      "epoch": 0.9459043843761747,
      "grad_norm": 1.199520468711853,
      "learning_rate": 0.0001,
      "loss": 3.3651,
      "step": 1730
    },
    {
      "epoch": 0.9513720397771931,
      "grad_norm": 1.2588963508605957,
      "learning_rate": 0.0001,
      "loss": 3.3746,
      "step": 1740
    },
    {
      "epoch": 0.9568396951782114,
      "grad_norm": 1.222519874572754,
      "learning_rate": 0.0001,
      "loss": 3.4214,
      "step": 1750
    },
    {
      "epoch": 0.9623073505792298,
      "grad_norm": 1.013093113899231,
      "learning_rate": 0.0001,
      "loss": 3.3859,
      "step": 1760
    },
    {
      "epoch": 0.9677750059802481,
      "grad_norm": 1.143571138381958,
      "learning_rate": 0.0001,
      "loss": 3.3524,
      "step": 1770
    },
    {
      "epoch": 0.9732426613812665,
      "grad_norm": 1.2757664918899536,
      "learning_rate": 0.0001,
      "loss": 3.378,
      "step": 1780
    },
    {
      "epoch": 0.9787103167822848,
      "grad_norm": 1.2165273427963257,
      "learning_rate": 0.0001,
      "loss": 3.3957,
      "step": 1790
    },
    {
      "epoch": 0.9841779721833032,
      "grad_norm": 1.1547424793243408,
      "learning_rate": 0.0001,
      "loss": 3.3903,
      "step": 1800
    },
    {
      "epoch": 0.9841779721833032,
      "eval_loss": 3.374220609664917,
      "eval_runtime": 236.8919,
      "eval_samples_per_second": 48.963,
      "eval_steps_per_second": 12.242,
      "step": 1800
    }
  ],
  "logging_steps": 10,
  "max_steps": 1828,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 1800,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 5.862564590576763e+17,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
