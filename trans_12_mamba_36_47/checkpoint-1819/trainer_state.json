{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.9997595410669506,
  "eval_steps": 1000,
  "global_step": 1819,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.005496204183985435,
      "grad_norm": 4.211594104766846,
      "learning_rate": 0.0001,
      "loss": 6.1054,
      "step": 10
    },
    {
      "epoch": 0.01099240836797087,
      "grad_norm": 3.4237864017486572,
      "learning_rate": 0.0001,
      "loss": 4.3366,
      "step": 20
    },
    {
      "epoch": 0.016488612551956307,
      "grad_norm": 2.5637569427490234,
      "learning_rate": 0.0001,
      "loss": 4.1782,
      "step": 30
    },
    {
      "epoch": 0.02198481673594174,
      "grad_norm": 2.1007890701293945,
      "learning_rate": 0.0001,
      "loss": 4.0499,
      "step": 40
    },
    {
      "epoch": 0.027481020919927174,
      "grad_norm": 1.9369207620620728,
      "learning_rate": 0.0001,
      "loss": 4.0017,
      "step": 50
    },
    {
      "epoch": 0.032977225103912614,
      "grad_norm": 1.7477043867111206,
      "learning_rate": 0.0001,
      "loss": 3.9661,
      "step": 60
    },
    {
      "epoch": 0.03847342928789804,
      "grad_norm": 1.724100947380066,
      "learning_rate": 0.0001,
      "loss": 3.904,
      "step": 70
    },
    {
      "epoch": 0.04396963347188348,
      "grad_norm": 1.6222184896469116,
      "learning_rate": 0.0001,
      "loss": 3.7878,
      "step": 80
    },
    {
      "epoch": 0.04946583765586891,
      "grad_norm": 1.7678521871566772,
      "learning_rate": 0.0001,
      "loss": 3.8289,
      "step": 90
    },
    {
      "epoch": 0.05496204183985435,
      "grad_norm": 1.6924889087677002,
      "learning_rate": 0.0001,
      "loss": 3.8363,
      "step": 100
    },
    {
      "epoch": 0.060458246023839785,
      "grad_norm": 1.5378233194351196,
      "learning_rate": 0.0001,
      "loss": 3.7995,
      "step": 110
    },
    {
      "epoch": 0.06595445020782523,
      "grad_norm": 1.346677541732788,
      "learning_rate": 0.0001,
      "loss": 3.7491,
      "step": 120
    },
    {
      "epoch": 0.07145065439181066,
      "grad_norm": 1.5532268285751343,
      "learning_rate": 0.0001,
      "loss": 3.7593,
      "step": 130
    },
    {
      "epoch": 0.07694685857579608,
      "grad_norm": 1.6559734344482422,
      "learning_rate": 0.0001,
      "loss": 3.7227,
      "step": 140
    },
    {
      "epoch": 0.08244306275978153,
      "grad_norm": 1.5712019205093384,
      "learning_rate": 0.0001,
      "loss": 3.726,
      "step": 150
    },
    {
      "epoch": 0.08793926694376696,
      "grad_norm": 1.4669339656829834,
      "learning_rate": 0.0001,
      "loss": 3.6899,
      "step": 160
    },
    {
      "epoch": 0.0934354711277524,
      "grad_norm": 1.4774737358093262,
      "learning_rate": 0.0001,
      "loss": 3.6942,
      "step": 170
    },
    {
      "epoch": 0.09893167531173783,
      "grad_norm": 1.5756595134735107,
      "learning_rate": 0.0001,
      "loss": 3.7116,
      "step": 180
    },
    {
      "epoch": 0.10442787949572327,
      "grad_norm": 1.5350004434585571,
      "learning_rate": 0.0001,
      "loss": 3.6587,
      "step": 190
    },
    {
      "epoch": 0.1099240836797087,
      "grad_norm": 1.5791620016098022,
      "learning_rate": 0.0001,
      "loss": 3.6769,
      "step": 200
    },
    {
      "epoch": 0.11542028786369414,
      "grad_norm": 1.6950517892837524,
      "learning_rate": 0.0001,
      "loss": 3.6714,
      "step": 210
    },
    {
      "epoch": 0.12091649204767957,
      "grad_norm": 1.4750412702560425,
      "learning_rate": 0.0001,
      "loss": 3.65,
      "step": 220
    },
    {
      "epoch": 0.126412696231665,
      "grad_norm": 1.34220290184021,
      "learning_rate": 0.0001,
      "loss": 3.6236,
      "step": 230
    },
    {
      "epoch": 0.13190890041565045,
      "grad_norm": 1.5983737707138062,
      "learning_rate": 0.0001,
      "loss": 3.6091,
      "step": 240
    },
    {
      "epoch": 0.13740510459963587,
      "grad_norm": 1.3340672254562378,
      "learning_rate": 0.0001,
      "loss": 3.6722,
      "step": 250
    },
    {
      "epoch": 0.1429013087836213,
      "grad_norm": 1.358106255531311,
      "learning_rate": 0.0001,
      "loss": 3.6379,
      "step": 260
    },
    {
      "epoch": 0.14839751296760675,
      "grad_norm": 1.5555472373962402,
      "learning_rate": 0.0001,
      "loss": 3.6115,
      "step": 270
    },
    {
      "epoch": 0.15389371715159217,
      "grad_norm": 1.4857287406921387,
      "learning_rate": 0.0001,
      "loss": 3.6556,
      "step": 280
    },
    {
      "epoch": 0.1593899213355776,
      "grad_norm": 1.319998025894165,
      "learning_rate": 0.0001,
      "loss": 3.5537,
      "step": 290
    },
    {
      "epoch": 0.16488612551956305,
      "grad_norm": 1.4714969396591187,
      "learning_rate": 0.0001,
      "loss": 3.6503,
      "step": 300
    },
    {
      "epoch": 0.1703823297035485,
      "grad_norm": 1.3429919481277466,
      "learning_rate": 0.0001,
      "loss": 3.6188,
      "step": 310
    },
    {
      "epoch": 0.1758785338875339,
      "grad_norm": 1.2621735334396362,
      "learning_rate": 0.0001,
      "loss": 3.6273,
      "step": 320
    },
    {
      "epoch": 0.18137473807151935,
      "grad_norm": 1.3003066778182983,
      "learning_rate": 0.0001,
      "loss": 3.6607,
      "step": 330
    },
    {
      "epoch": 0.1868709422555048,
      "grad_norm": 1.366274356842041,
      "learning_rate": 0.0001,
      "loss": 3.6005,
      "step": 340
    },
    {
      "epoch": 0.19236714643949024,
      "grad_norm": 1.6070681810379028,
      "learning_rate": 0.0001,
      "loss": 3.6011,
      "step": 350
    },
    {
      "epoch": 0.19786335062347565,
      "grad_norm": 1.240402102470398,
      "learning_rate": 0.0001,
      "loss": 3.6019,
      "step": 360
    },
    {
      "epoch": 0.2033595548074611,
      "grad_norm": 1.5637304782867432,
      "learning_rate": 0.0001,
      "loss": 3.6344,
      "step": 370
    },
    {
      "epoch": 0.20885575899144654,
      "grad_norm": 1.5416146516799927,
      "learning_rate": 0.0001,
      "loss": 3.6106,
      "step": 380
    },
    {
      "epoch": 0.21435196317543198,
      "grad_norm": 1.320981740951538,
      "learning_rate": 0.0001,
      "loss": 3.5822,
      "step": 390
    },
    {
      "epoch": 0.2198481673594174,
      "grad_norm": 1.403387188911438,
      "learning_rate": 0.0001,
      "loss": 3.5815,
      "step": 400
    },
    {
      "epoch": 0.22534437154340284,
      "grad_norm": 1.3388564586639404,
      "learning_rate": 0.0001,
      "loss": 3.5998,
      "step": 410
    },
    {
      "epoch": 0.23084057572738828,
      "grad_norm": 1.4640089273452759,
      "learning_rate": 0.0001,
      "loss": 3.6167,
      "step": 420
    },
    {
      "epoch": 0.2363367799113737,
      "grad_norm": 1.3539109230041504,
      "learning_rate": 0.0001,
      "loss": 3.5956,
      "step": 430
    },
    {
      "epoch": 0.24183298409535914,
      "grad_norm": 1.3917555809020996,
      "learning_rate": 0.0001,
      "loss": 3.5841,
      "step": 440
    },
    {
      "epoch": 0.24732918827934458,
      "grad_norm": 1.4259294271469116,
      "learning_rate": 0.0001,
      "loss": 3.5545,
      "step": 450
    },
    {
      "epoch": 0.25282539246333,
      "grad_norm": 1.4796851873397827,
      "learning_rate": 0.0001,
      "loss": 3.5421,
      "step": 460
    },
    {
      "epoch": 0.25832159664731547,
      "grad_norm": 1.428291916847229,
      "learning_rate": 0.0001,
      "loss": 3.6088,
      "step": 470
    },
    {
      "epoch": 0.2638178008313009,
      "grad_norm": 1.310523271560669,
      "learning_rate": 0.0001,
      "loss": 3.5901,
      "step": 480
    },
    {
      "epoch": 0.2693140050152863,
      "grad_norm": 1.3059898614883423,
      "learning_rate": 0.0001,
      "loss": 3.536,
      "step": 490
    },
    {
      "epoch": 0.27481020919927174,
      "grad_norm": 1.3618981838226318,
      "learning_rate": 0.0001,
      "loss": 3.6065,
      "step": 500
    },
    {
      "epoch": 0.2803064133832572,
      "grad_norm": 1.30668044090271,
      "learning_rate": 0.0001,
      "loss": 3.5541,
      "step": 510
    },
    {
      "epoch": 0.2858026175672426,
      "grad_norm": 1.3683143854141235,
      "learning_rate": 0.0001,
      "loss": 3.5874,
      "step": 520
    },
    {
      "epoch": 0.29129882175122807,
      "grad_norm": 1.3338778018951416,
      "learning_rate": 0.0001,
      "loss": 3.5554,
      "step": 530
    },
    {
      "epoch": 0.2967950259352135,
      "grad_norm": 1.2904075384140015,
      "learning_rate": 0.0001,
      "loss": 3.565,
      "step": 540
    },
    {
      "epoch": 0.30229123011919895,
      "grad_norm": 1.1777173280715942,
      "learning_rate": 0.0001,
      "loss": 3.5905,
      "step": 550
    },
    {
      "epoch": 0.30778743430318434,
      "grad_norm": 1.2387248277664185,
      "learning_rate": 0.0001,
      "loss": 3.6191,
      "step": 560
    },
    {
      "epoch": 0.3132836384871698,
      "grad_norm": 1.147952914237976,
      "learning_rate": 0.0001,
      "loss": 3.5657,
      "step": 570
    },
    {
      "epoch": 0.3187798426711552,
      "grad_norm": 1.4412426948547363,
      "learning_rate": 0.0001,
      "loss": 3.5896,
      "step": 580
    },
    {
      "epoch": 0.32427604685514066,
      "grad_norm": 3.203050136566162,
      "learning_rate": 0.0001,
      "loss": 3.5782,
      "step": 590
    },
    {
      "epoch": 0.3297722510391261,
      "grad_norm": 1.2521212100982666,
      "learning_rate": 0.0001,
      "loss": 3.5448,
      "step": 600
    },
    {
      "epoch": 0.33526845522311155,
      "grad_norm": 1.272554874420166,
      "learning_rate": 0.0001,
      "loss": 3.5208,
      "step": 610
    },
    {
      "epoch": 0.340764659407097,
      "grad_norm": 1.4449344873428345,
      "learning_rate": 0.0001,
      "loss": 3.5523,
      "step": 620
    },
    {
      "epoch": 0.34626086359108244,
      "grad_norm": 1.2702823877334595,
      "learning_rate": 0.0001,
      "loss": 3.5456,
      "step": 630
    },
    {
      "epoch": 0.3517570677750678,
      "grad_norm": 1.350616693496704,
      "learning_rate": 0.0001,
      "loss": 3.5453,
      "step": 640
    },
    {
      "epoch": 0.35725327195905326,
      "grad_norm": 1.2807093858718872,
      "learning_rate": 0.0001,
      "loss": 3.5298,
      "step": 650
    },
    {
      "epoch": 0.3627494761430387,
      "grad_norm": 1.2044228315353394,
      "learning_rate": 0.0001,
      "loss": 3.5079,
      "step": 660
    },
    {
      "epoch": 0.36824568032702415,
      "grad_norm": 1.2934069633483887,
      "learning_rate": 0.0001,
      "loss": 3.5518,
      "step": 670
    },
    {
      "epoch": 0.3737418845110096,
      "grad_norm": 1.3152157068252563,
      "learning_rate": 0.0001,
      "loss": 3.5344,
      "step": 680
    },
    {
      "epoch": 0.37923808869499503,
      "grad_norm": 1.1720658540725708,
      "learning_rate": 0.0001,
      "loss": 3.5268,
      "step": 690
    },
    {
      "epoch": 0.3847342928789805,
      "grad_norm": 1.1579952239990234,
      "learning_rate": 0.0001,
      "loss": 3.4908,
      "step": 700
    },
    {
      "epoch": 0.39023049706296586,
      "grad_norm": 1.40224289894104,
      "learning_rate": 0.0001,
      "loss": 3.5466,
      "step": 710
    },
    {
      "epoch": 0.3957267012469513,
      "grad_norm": 1.3983180522918701,
      "learning_rate": 0.0001,
      "loss": 3.5208,
      "step": 720
    },
    {
      "epoch": 0.40122290543093675,
      "grad_norm": 1.241005778312683,
      "learning_rate": 0.0001,
      "loss": 3.5246,
      "step": 730
    },
    {
      "epoch": 0.4067191096149222,
      "grad_norm": 1.2624355554580688,
      "learning_rate": 0.0001,
      "loss": 3.5272,
      "step": 740
    },
    {
      "epoch": 0.41221531379890763,
      "grad_norm": 1.3770426511764526,
      "learning_rate": 0.0001,
      "loss": 3.498,
      "step": 750
    },
    {
      "epoch": 0.4177115179828931,
      "grad_norm": 1.1742141246795654,
      "learning_rate": 0.0001,
      "loss": 3.5427,
      "step": 760
    },
    {
      "epoch": 0.4232077221668785,
      "grad_norm": 1.2212649583816528,
      "learning_rate": 0.0001,
      "loss": 3.5615,
      "step": 770
    },
    {
      "epoch": 0.42870392635086396,
      "grad_norm": 1.362916111946106,
      "learning_rate": 0.0001,
      "loss": 3.4874,
      "step": 780
    },
    {
      "epoch": 0.43420013053484935,
      "grad_norm": 1.250014066696167,
      "learning_rate": 0.0001,
      "loss": 3.5169,
      "step": 790
    },
    {
      "epoch": 0.4396963347188348,
      "grad_norm": 1.2860496044158936,
      "learning_rate": 0.0001,
      "loss": 3.5214,
      "step": 800
    },
    {
      "epoch": 0.44519253890282023,
      "grad_norm": 1.4945728778839111,
      "learning_rate": 0.0001,
      "loss": 3.5149,
      "step": 810
    },
    {
      "epoch": 0.4506887430868057,
      "grad_norm": 1.1810028553009033,
      "learning_rate": 0.0001,
      "loss": 3.5388,
      "step": 820
    },
    {
      "epoch": 0.4561849472707911,
      "grad_norm": 1.4050931930541992,
      "learning_rate": 0.0001,
      "loss": 3.4967,
      "step": 830
    },
    {
      "epoch": 0.46168115145477656,
      "grad_norm": 1.3100612163543701,
      "learning_rate": 0.0001,
      "loss": 3.4897,
      "step": 840
    },
    {
      "epoch": 0.467177355638762,
      "grad_norm": 1.187811255455017,
      "learning_rate": 0.0001,
      "loss": 3.4699,
      "step": 850
    },
    {
      "epoch": 0.4726735598227474,
      "grad_norm": 1.1779650449752808,
      "learning_rate": 0.0001,
      "loss": 3.4728,
      "step": 860
    },
    {
      "epoch": 0.47816976400673283,
      "grad_norm": 1.4053645133972168,
      "learning_rate": 0.0001,
      "loss": 3.5275,
      "step": 870
    },
    {
      "epoch": 0.4836659681907183,
      "grad_norm": 1.1470776796340942,
      "learning_rate": 0.0001,
      "loss": 3.5384,
      "step": 880
    },
    {
      "epoch": 0.4891621723747037,
      "grad_norm": 1.2952297925949097,
      "learning_rate": 0.0001,
      "loss": 3.5112,
      "step": 890
    },
    {
      "epoch": 0.49465837655868916,
      "grad_norm": 1.2032427787780762,
      "learning_rate": 0.0001,
      "loss": 3.4736,
      "step": 900
    },
    {
      "epoch": 0.5001545807426746,
      "grad_norm": 1.1555235385894775,
      "learning_rate": 0.0001,
      "loss": 3.4998,
      "step": 910
    },
    {
      "epoch": 0.50565078492666,
      "grad_norm": 1.1954271793365479,
      "learning_rate": 0.0001,
      "loss": 3.4778,
      "step": 920
    },
    {
      "epoch": 0.5111469891106455,
      "grad_norm": 1.294547438621521,
      "learning_rate": 0.0001,
      "loss": 3.5467,
      "step": 930
    },
    {
      "epoch": 0.5166431932946309,
      "grad_norm": 1.67118501663208,
      "learning_rate": 0.0001,
      "loss": 3.5017,
      "step": 940
    },
    {
      "epoch": 0.5221393974786164,
      "grad_norm": 1.3437601327896118,
      "learning_rate": 0.0001,
      "loss": 3.523,
      "step": 950
    },
    {
      "epoch": 0.5276356016626018,
      "grad_norm": 1.3175538778305054,
      "learning_rate": 0.0001,
      "loss": 3.5265,
      "step": 960
    },
    {
      "epoch": 0.5331318058465871,
      "grad_norm": 1.245805263519287,
      "learning_rate": 0.0001,
      "loss": 3.535,
      "step": 970
    },
    {
      "epoch": 0.5386280100305726,
      "grad_norm": 1.1516107320785522,
      "learning_rate": 0.0001,
      "loss": 3.5166,
      "step": 980
    },
    {
      "epoch": 0.544124214214558,
      "grad_norm": 1.334301233291626,
      "learning_rate": 0.0001,
      "loss": 3.4723,
      "step": 990
    },
    {
      "epoch": 0.5496204183985435,
      "grad_norm": 1.2482355833053589,
      "learning_rate": 0.0001,
      "loss": 3.4779,
      "step": 1000
    },
    {
      "epoch": 0.5496204183985435,
      "eval_loss": 3.4970736503601074,
      "eval_runtime": 238.0532,
      "eval_samples_per_second": 48.75,
      "eval_steps_per_second": 12.191,
      "step": 1000
    },
    {
      "epoch": 0.5551166225825289,
      "grad_norm": 1.1763381958007812,
      "learning_rate": 0.0001,
      "loss": 3.4761,
      "step": 1010
    },
    {
      "epoch": 0.5606128267665144,
      "grad_norm": 1.1030555963516235,
      "learning_rate": 0.0001,
      "loss": 3.4873,
      "step": 1020
    },
    {
      "epoch": 0.5661090309504998,
      "grad_norm": 1.1991091966629028,
      "learning_rate": 0.0001,
      "loss": 3.498,
      "step": 1030
    },
    {
      "epoch": 0.5716052351344852,
      "grad_norm": 1.1184805631637573,
      "learning_rate": 0.0001,
      "loss": 3.4657,
      "step": 1040
    },
    {
      "epoch": 0.5771014393184707,
      "grad_norm": 1.2221451997756958,
      "learning_rate": 0.0001,
      "loss": 3.4888,
      "step": 1050
    },
    {
      "epoch": 0.5825976435024561,
      "grad_norm": 1.2518234252929688,
      "learning_rate": 0.0001,
      "loss": 3.4588,
      "step": 1060
    },
    {
      "epoch": 0.5880938476864416,
      "grad_norm": 1.3804452419281006,
      "learning_rate": 0.0001,
      "loss": 3.4965,
      "step": 1070
    },
    {
      "epoch": 0.593590051870427,
      "grad_norm": 1.187764048576355,
      "learning_rate": 0.0001,
      "loss": 3.5044,
      "step": 1080
    },
    {
      "epoch": 0.5990862560544125,
      "grad_norm": 1.1077783107757568,
      "learning_rate": 0.0001,
      "loss": 3.4671,
      "step": 1090
    },
    {
      "epoch": 0.6045824602383979,
      "grad_norm": 1.2046529054641724,
      "learning_rate": 0.0001,
      "loss": 3.4593,
      "step": 1100
    },
    {
      "epoch": 0.6100786644223833,
      "grad_norm": 1.3243950605392456,
      "learning_rate": 0.0001,
      "loss": 3.4692,
      "step": 1110
    },
    {
      "epoch": 0.6155748686063687,
      "grad_norm": 1.1026771068572998,
      "learning_rate": 0.0001,
      "loss": 3.5012,
      "step": 1120
    },
    {
      "epoch": 0.6210710727903541,
      "grad_norm": 1.0982083082199097,
      "learning_rate": 0.0001,
      "loss": 3.4883,
      "step": 1130
    },
    {
      "epoch": 0.6265672769743396,
      "grad_norm": 1.2036494016647339,
      "learning_rate": 0.0001,
      "loss": 3.4498,
      "step": 1140
    },
    {
      "epoch": 0.632063481158325,
      "grad_norm": 1.323048710823059,
      "learning_rate": 0.0001,
      "loss": 3.487,
      "step": 1150
    },
    {
      "epoch": 0.6375596853423104,
      "grad_norm": 1.165819764137268,
      "learning_rate": 0.0001,
      "loss": 3.4566,
      "step": 1160
    },
    {
      "epoch": 0.6430558895262959,
      "grad_norm": 1.1782619953155518,
      "learning_rate": 0.0001,
      "loss": 3.4405,
      "step": 1170
    },
    {
      "epoch": 0.6485520937102813,
      "grad_norm": 1.262436866760254,
      "learning_rate": 0.0001,
      "loss": 3.4961,
      "step": 1180
    },
    {
      "epoch": 0.6540482978942668,
      "grad_norm": 1.1781889200210571,
      "learning_rate": 0.0001,
      "loss": 3.4821,
      "step": 1190
    },
    {
      "epoch": 0.6595445020782522,
      "grad_norm": 1.1448516845703125,
      "learning_rate": 0.0001,
      "loss": 3.4357,
      "step": 1200
    },
    {
      "epoch": 0.6650407062622377,
      "grad_norm": 1.4102641344070435,
      "learning_rate": 0.0001,
      "loss": 3.5235,
      "step": 1210
    },
    {
      "epoch": 0.6705369104462231,
      "grad_norm": 1.2819691896438599,
      "learning_rate": 0.0001,
      "loss": 3.4811,
      "step": 1220
    },
    {
      "epoch": 0.6760331146302085,
      "grad_norm": 1.377400279045105,
      "learning_rate": 0.0001,
      "loss": 3.4336,
      "step": 1230
    },
    {
      "epoch": 0.681529318814194,
      "grad_norm": 1.386212706565857,
      "learning_rate": 0.0001,
      "loss": 3.4685,
      "step": 1240
    },
    {
      "epoch": 0.6870255229981794,
      "grad_norm": 1.0781010389328003,
      "learning_rate": 0.0001,
      "loss": 3.466,
      "step": 1250
    },
    {
      "epoch": 0.6925217271821649,
      "grad_norm": 1.2826201915740967,
      "learning_rate": 0.0001,
      "loss": 3.4564,
      "step": 1260
    },
    {
      "epoch": 0.6980179313661502,
      "grad_norm": 1.2103276252746582,
      "learning_rate": 0.0001,
      "loss": 3.4222,
      "step": 1270
    },
    {
      "epoch": 0.7035141355501356,
      "grad_norm": 1.1128135919570923,
      "learning_rate": 0.0001,
      "loss": 3.4676,
      "step": 1280
    },
    {
      "epoch": 0.7090103397341211,
      "grad_norm": 1.225954532623291,
      "learning_rate": 0.0001,
      "loss": 3.4542,
      "step": 1290
    },
    {
      "epoch": 0.7145065439181065,
      "grad_norm": 1.1208913326263428,
      "learning_rate": 0.0001,
      "loss": 3.4554,
      "step": 1300
    },
    {
      "epoch": 0.720002748102092,
      "grad_norm": 1.0974119901657104,
      "learning_rate": 0.0001,
      "loss": 3.4286,
      "step": 1310
    },
    {
      "epoch": 0.7254989522860774,
      "grad_norm": 1.141831874847412,
      "learning_rate": 0.0001,
      "loss": 3.4264,
      "step": 1320
    },
    {
      "epoch": 0.7309951564700629,
      "grad_norm": 1.2689261436462402,
      "learning_rate": 0.0001,
      "loss": 3.4746,
      "step": 1330
    },
    {
      "epoch": 0.7364913606540483,
      "grad_norm": 1.242922067642212,
      "learning_rate": 0.0001,
      "loss": 3.4529,
      "step": 1340
    },
    {
      "epoch": 0.7419875648380337,
      "grad_norm": 1.1915768384933472,
      "learning_rate": 0.0001,
      "loss": 3.4254,
      "step": 1350
    },
    {
      "epoch": 0.7474837690220192,
      "grad_norm": 1.209321141242981,
      "learning_rate": 0.0001,
      "loss": 3.3768,
      "step": 1360
    },
    {
      "epoch": 0.7529799732060046,
      "grad_norm": 1.2635948657989502,
      "learning_rate": 0.0001,
      "loss": 3.4594,
      "step": 1370
    },
    {
      "epoch": 0.7584761773899901,
      "grad_norm": 1.2348524332046509,
      "learning_rate": 0.0001,
      "loss": 3.4163,
      "step": 1380
    },
    {
      "epoch": 0.7639723815739755,
      "grad_norm": 1.1849157810211182,
      "learning_rate": 0.0001,
      "loss": 3.4317,
      "step": 1390
    },
    {
      "epoch": 0.769468585757961,
      "grad_norm": 1.2812527418136597,
      "learning_rate": 0.0001,
      "loss": 3.4705,
      "step": 1400
    },
    {
      "epoch": 0.7749647899419464,
      "grad_norm": 1.251151204109192,
      "learning_rate": 0.0001,
      "loss": 3.4168,
      "step": 1410
    },
    {
      "epoch": 0.7804609941259317,
      "grad_norm": 1.132025957107544,
      "learning_rate": 0.0001,
      "loss": 3.4109,
      "step": 1420
    },
    {
      "epoch": 0.7859571983099172,
      "grad_norm": 1.1950461864471436,
      "learning_rate": 0.0001,
      "loss": 3.4282,
      "step": 1430
    },
    {
      "epoch": 0.7914534024939026,
      "grad_norm": 1.229685664176941,
      "learning_rate": 0.0001,
      "loss": 3.4573,
      "step": 1440
    },
    {
      "epoch": 0.7969496066778881,
      "grad_norm": 1.1049673557281494,
      "learning_rate": 0.0001,
      "loss": 3.437,
      "step": 1450
    },
    {
      "epoch": 0.8024458108618735,
      "grad_norm": 1.4923242330551147,
      "learning_rate": 0.0001,
      "loss": 3.4633,
      "step": 1460
    },
    {
      "epoch": 0.8079420150458589,
      "grad_norm": 0.9987558126449585,
      "learning_rate": 0.0001,
      "loss": 3.419,
      "step": 1470
    },
    {
      "epoch": 0.8134382192298444,
      "grad_norm": 1.0430119037628174,
      "learning_rate": 0.0001,
      "loss": 3.4097,
      "step": 1480
    },
    {
      "epoch": 0.8189344234138298,
      "grad_norm": 1.389499545097351,
      "learning_rate": 0.0001,
      "loss": 3.4099,
      "step": 1490
    },
    {
      "epoch": 0.8244306275978153,
      "grad_norm": 1.1823776960372925,
      "learning_rate": 0.0001,
      "loss": 3.4068,
      "step": 1500
    },
    {
      "epoch": 0.8299268317818007,
      "grad_norm": 1.1344056129455566,
      "learning_rate": 0.0001,
      "loss": 3.3981,
      "step": 1510
    },
    {
      "epoch": 0.8354230359657862,
      "grad_norm": 1.1387733221054077,
      "learning_rate": 0.0001,
      "loss": 3.44,
      "step": 1520
    },
    {
      "epoch": 0.8409192401497716,
      "grad_norm": 1.1681692600250244,
      "learning_rate": 0.0001,
      "loss": 3.3546,
      "step": 1530
    },
    {
      "epoch": 0.846415444333757,
      "grad_norm": 1.1288210153579712,
      "learning_rate": 0.0001,
      "loss": 3.4554,
      "step": 1540
    },
    {
      "epoch": 0.8519116485177425,
      "grad_norm": 1.0630574226379395,
      "learning_rate": 0.0001,
      "loss": 3.4049,
      "step": 1550
    },
    {
      "epoch": 0.8574078527017279,
      "grad_norm": 1.2158282995224,
      "learning_rate": 0.0001,
      "loss": 3.4025,
      "step": 1560
    },
    {
      "epoch": 0.8629040568857133,
      "grad_norm": 1.1517502069473267,
      "learning_rate": 0.0001,
      "loss": 3.4476,
      "step": 1570
    },
    {
      "epoch": 0.8684002610696987,
      "grad_norm": 1.0827487707138062,
      "learning_rate": 0.0001,
      "loss": 3.4028,
      "step": 1580
    },
    {
      "epoch": 0.8738964652536841,
      "grad_norm": 1.2675656080245972,
      "learning_rate": 0.0001,
      "loss": 3.3877,
      "step": 1590
    },
    {
      "epoch": 0.8793926694376696,
      "grad_norm": 1.184187889099121,
      "learning_rate": 0.0001,
      "loss": 3.4013,
      "step": 1600
    },
    {
      "epoch": 0.884888873621655,
      "grad_norm": 1.1876347064971924,
      "learning_rate": 0.0001,
      "loss": 3.4086,
      "step": 1610
    },
    {
      "epoch": 0.8903850778056405,
      "grad_norm": 1.1080913543701172,
      "learning_rate": 0.0001,
      "loss": 3.3832,
      "step": 1620
    },
    {
      "epoch": 0.8958812819896259,
      "grad_norm": 1.2310543060302734,
      "learning_rate": 0.0001,
      "loss": 3.3998,
      "step": 1630
    },
    {
      "epoch": 0.9013774861736114,
      "grad_norm": 1.1029901504516602,
      "learning_rate": 0.0001,
      "loss": 3.3775,
      "step": 1640
    },
    {
      "epoch": 0.9068736903575968,
      "grad_norm": 1.061594009399414,
      "learning_rate": 0.0001,
      "loss": 3.4764,
      "step": 1650
    },
    {
      "epoch": 0.9123698945415822,
      "grad_norm": 1.2652283906936646,
      "learning_rate": 0.0001,
      "loss": 3.4336,
      "step": 1660
    },
    {
      "epoch": 0.9178660987255677,
      "grad_norm": 1.1041178703308105,
      "learning_rate": 0.0001,
      "loss": 3.4306,
      "step": 1670
    },
    {
      "epoch": 0.9233623029095531,
      "grad_norm": 1.38111412525177,
      "learning_rate": 0.0001,
      "loss": 3.4494,
      "step": 1680
    },
    {
      "epoch": 0.9288585070935386,
      "grad_norm": 1.2200348377227783,
      "learning_rate": 0.0001,
      "loss": 3.4011,
      "step": 1690
    },
    {
      "epoch": 0.934354711277524,
      "grad_norm": 1.10311758518219,
      "learning_rate": 0.0001,
      "loss": 3.4358,
      "step": 1700
    },
    {
      "epoch": 0.9398509154615093,
      "grad_norm": 1.1746776103973389,
      "learning_rate": 0.0001,
      "loss": 3.3604,
      "step": 1710
    },
    {
      "epoch": 0.9453471196454948,
      "grad_norm": 1.1462090015411377,
      "learning_rate": 0.0001,
      "loss": 3.3696,
      "step": 1720
    },
    {
      "epoch": 0.9508433238294802,
      "grad_norm": 1.2675930261611938,
      "learning_rate": 0.0001,
      "loss": 3.4146,
      "step": 1730
    },
    {
      "epoch": 0.9563395280134657,
      "grad_norm": 1.1577253341674805,
      "learning_rate": 0.0001,
      "loss": 3.3868,
      "step": 1740
    },
    {
      "epoch": 0.9618357321974511,
      "grad_norm": 1.2053645849227905,
      "learning_rate": 0.0001,
      "loss": 3.3985,
      "step": 1750
    },
    {
      "epoch": 0.9673319363814366,
      "grad_norm": 1.3231219053268433,
      "learning_rate": 0.0001,
      "loss": 3.3716,
      "step": 1760
    },
    {
      "epoch": 0.972828140565422,
      "grad_norm": 1.2774081230163574,
      "learning_rate": 0.0001,
      "loss": 3.4003,
      "step": 1770
    },
    {
      "epoch": 0.9783243447494074,
      "grad_norm": 1.1424671411514282,
      "learning_rate": 0.0001,
      "loss": 3.3804,
      "step": 1780
    },
    {
      "epoch": 0.9838205489333929,
      "grad_norm": 1.2055776119232178,
      "learning_rate": 0.0001,
      "loss": 3.3404,
      "step": 1790
    },
    {
      "epoch": 0.9893167531173783,
      "grad_norm": 1.1879137754440308,
      "learning_rate": 0.0001,
      "loss": 3.3815,
      "step": 1800
    },
    {
      "epoch": 0.9948129573013638,
      "grad_norm": 1.201130986213684,
      "learning_rate": 0.0001,
      "loss": 3.4203,
      "step": 1810
    }
  ],
  "logging_steps": 10,
  "max_steps": 1819,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 1000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 5.867253266168218e+17,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
