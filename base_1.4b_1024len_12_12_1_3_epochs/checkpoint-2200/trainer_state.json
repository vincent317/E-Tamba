{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.5906238464378,
  "eval_steps": 2200,
  "global_step": 2200,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.013423269237222726,
      "grad_norm": 1.6249005794525146,
      "learning_rate": 0.00019910490511994272,
      "loss": 6.0397,
      "step": 50
    },
    {
      "epoch": 0.02684653847444545,
      "grad_norm": 1.2585577964782715,
      "learning_rate": 0.00019820981023988544,
      "loss": 4.0591,
      "step": 100
    },
    {
      "epoch": 0.040269807711668174,
      "grad_norm": 1.242455005645752,
      "learning_rate": 0.00019731471535982815,
      "loss": 3.928,
      "step": 150
    },
    {
      "epoch": 0.0536930769488909,
      "grad_norm": 1.077959418296814,
      "learning_rate": 0.00019641962047977087,
      "loss": 3.8786,
      "step": 200
    },
    {
      "epoch": 0.06711634618611363,
      "grad_norm": 1.1293054819107056,
      "learning_rate": 0.00019552452559971358,
      "loss": 3.808,
      "step": 250
    },
    {
      "epoch": 0.08053961542333635,
      "grad_norm": 1.379184365272522,
      "learning_rate": 0.0001946294307196563,
      "loss": 3.7592,
      "step": 300
    },
    {
      "epoch": 0.09396288466055908,
      "grad_norm": 1.199040412902832,
      "learning_rate": 0.000193734335839599,
      "loss": 3.7393,
      "step": 350
    },
    {
      "epoch": 0.1073861538977818,
      "grad_norm": 1.1102811098098755,
      "learning_rate": 0.00019283924095954172,
      "loss": 3.697,
      "step": 400
    },
    {
      "epoch": 0.12080942313500453,
      "grad_norm": 0.9569101929664612,
      "learning_rate": 0.00019194414607948444,
      "loss": 3.6766,
      "step": 450
    },
    {
      "epoch": 0.13423269237222726,
      "grad_norm": 1.0286988019943237,
      "learning_rate": 0.00019104905119942715,
      "loss": 3.6546,
      "step": 500
    },
    {
      "epoch": 0.14765596160945,
      "grad_norm": 1.2503851652145386,
      "learning_rate": 0.00019015395631936987,
      "loss": 3.6156,
      "step": 550
    },
    {
      "epoch": 0.1610792308466727,
      "grad_norm": 1.0122041702270508,
      "learning_rate": 0.00018925886143931258,
      "loss": 3.6052,
      "step": 600
    },
    {
      "epoch": 0.17450250008389542,
      "grad_norm": 0.8883369565010071,
      "learning_rate": 0.0001883637665592553,
      "loss": 3.5868,
      "step": 650
    },
    {
      "epoch": 0.18792576932111815,
      "grad_norm": 0.9619415998458862,
      "learning_rate": 0.00018746867167919798,
      "loss": 3.5688,
      "step": 700
    },
    {
      "epoch": 0.20134903855834088,
      "grad_norm": 0.8808920979499817,
      "learning_rate": 0.00018657357679914072,
      "loss": 3.5493,
      "step": 750
    },
    {
      "epoch": 0.2147723077955636,
      "grad_norm": 0.8533366322517395,
      "learning_rate": 0.00018567848191908344,
      "loss": 3.5457,
      "step": 800
    },
    {
      "epoch": 0.22819557703278634,
      "grad_norm": 0.8686419725418091,
      "learning_rate": 0.00018478338703902612,
      "loss": 3.5578,
      "step": 850
    },
    {
      "epoch": 0.24161884627000907,
      "grad_norm": 0.8461309671401978,
      "learning_rate": 0.00018388829215896886,
      "loss": 3.5134,
      "step": 900
    },
    {
      "epoch": 0.25504211550723177,
      "grad_norm": 0.8715841174125671,
      "learning_rate": 0.00018299319727891158,
      "loss": 3.5076,
      "step": 950
    },
    {
      "epoch": 0.2684653847444545,
      "grad_norm": 0.8817312121391296,
      "learning_rate": 0.0001820981023988543,
      "loss": 3.5107,
      "step": 1000
    },
    {
      "epoch": 0.28188865398167723,
      "grad_norm": 0.9123731255531311,
      "learning_rate": 0.000181203007518797,
      "loss": 3.477,
      "step": 1050
    },
    {
      "epoch": 0.2953119232189,
      "grad_norm": 0.876594603061676,
      "learning_rate": 0.00018030791263873972,
      "loss": 3.4432,
      "step": 1100
    },
    {
      "epoch": 0.3087351924561227,
      "grad_norm": 0.785525381565094,
      "learning_rate": 0.00017941281775868243,
      "loss": 3.4906,
      "step": 1150
    },
    {
      "epoch": 0.3221584616933454,
      "grad_norm": 0.8188530802726746,
      "learning_rate": 0.00017851772287862515,
      "loss": 3.4667,
      "step": 1200
    },
    {
      "epoch": 0.33558173093056815,
      "grad_norm": 0.8998259902000427,
      "learning_rate": 0.00017762262799856786,
      "loss": 3.4792,
      "step": 1250
    },
    {
      "epoch": 0.34900500016779085,
      "grad_norm": 0.8735019564628601,
      "learning_rate": 0.00017672753311851058,
      "loss": 3.4353,
      "step": 1300
    },
    {
      "epoch": 0.3624282694050136,
      "grad_norm": 0.8192775845527649,
      "learning_rate": 0.0001758324382384533,
      "loss": 3.4445,
      "step": 1350
    },
    {
      "epoch": 0.3758515386422363,
      "grad_norm": 0.8715808987617493,
      "learning_rate": 0.000174937343358396,
      "loss": 3.4642,
      "step": 1400
    },
    {
      "epoch": 0.38927480787945906,
      "grad_norm": 0.779262125492096,
      "learning_rate": 0.00017404224847833872,
      "loss": 3.4009,
      "step": 1450
    },
    {
      "epoch": 0.40269807711668176,
      "grad_norm": 0.8343179225921631,
      "learning_rate": 0.0001731471535982814,
      "loss": 3.3731,
      "step": 1500
    },
    {
      "epoch": 0.4161213463539045,
      "grad_norm": 0.7869422435760498,
      "learning_rate": 0.00017225205871822415,
      "loss": 3.4094,
      "step": 1550
    },
    {
      "epoch": 0.4295446155911272,
      "grad_norm": 0.7299124598503113,
      "learning_rate": 0.00017135696383816686,
      "loss": 3.4067,
      "step": 1600
    },
    {
      "epoch": 0.4429678848283499,
      "grad_norm": 0.8106259703636169,
      "learning_rate": 0.00017046186895810955,
      "loss": 3.4192,
      "step": 1650
    },
    {
      "epoch": 0.4563911540655727,
      "grad_norm": 0.7745542526245117,
      "learning_rate": 0.0001695667740780523,
      "loss": 3.4032,
      "step": 1700
    },
    {
      "epoch": 0.4698144233027954,
      "grad_norm": 0.771173894405365,
      "learning_rate": 0.000168671679197995,
      "loss": 3.3865,
      "step": 1750
    },
    {
      "epoch": 0.48323769254001814,
      "grad_norm": 0.7654825448989868,
      "learning_rate": 0.0001677765843179377,
      "loss": 3.4023,
      "step": 1800
    },
    {
      "epoch": 0.49666096177724084,
      "grad_norm": 0.7796964645385742,
      "learning_rate": 0.00016688148943788043,
      "loss": 3.3585,
      "step": 1850
    },
    {
      "epoch": 0.5100842310144635,
      "grad_norm": 0.8113115429878235,
      "learning_rate": 0.00016598639455782315,
      "loss": 3.3631,
      "step": 1900
    },
    {
      "epoch": 0.5235075002516864,
      "grad_norm": 0.7632923126220703,
      "learning_rate": 0.00016509129967776583,
      "loss": 3.3308,
      "step": 1950
    },
    {
      "epoch": 0.536930769488909,
      "grad_norm": 0.7579735517501831,
      "learning_rate": 0.00016419620479770857,
      "loss": 3.3389,
      "step": 2000
    },
    {
      "epoch": 0.5503540387261318,
      "grad_norm": 0.7850564122200012,
      "learning_rate": 0.0001633011099176513,
      "loss": 3.3867,
      "step": 2050
    },
    {
      "epoch": 0.5637773079633545,
      "grad_norm": 0.7464714050292969,
      "learning_rate": 0.00016240601503759398,
      "loss": 3.3666,
      "step": 2100
    },
    {
      "epoch": 0.5772005772005772,
      "grad_norm": 1.0022751092910767,
      "learning_rate": 0.00016151092015753672,
      "loss": 3.3545,
      "step": 2150
    },
    {
      "epoch": 0.5906238464378,
      "grad_norm": 0.7488406896591187,
      "learning_rate": 0.00016061582527747943,
      "loss": 3.3252,
      "step": 2200
    },
    {
      "epoch": 0.5906238464378,
      "eval_loss": 3.372422933578491,
      "eval_runtime": 1418.9064,
      "eval_samples_per_second": 5.211,
      "eval_steps_per_second": 1.303,
      "step": 2200
    }
  ],
  "logging_steps": 50,
  "max_steps": 11172,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 1100,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 2.324910223392768e+17,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
