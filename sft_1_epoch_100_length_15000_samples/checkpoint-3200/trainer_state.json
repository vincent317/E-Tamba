{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.8028098344204716,
  "eval_steps": 800,
  "global_step": 3200,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.012543903662819869,
      "grad_norm": 1.0704247951507568,
      "learning_rate": 1.9749121926743604e-05,
      "loss": 0.0531,
      "step": 50
    },
    {
      "epoch": 0.025087807325639738,
      "grad_norm": 0.7099398374557495,
      "learning_rate": 1.9498243853487206e-05,
      "loss": 0.0413,
      "step": 100
    },
    {
      "epoch": 0.03763171098845961,
      "grad_norm": 0.6941176056861877,
      "learning_rate": 1.924736578023081e-05,
      "loss": 0.0408,
      "step": 150
    },
    {
      "epoch": 0.050175614651279475,
      "grad_norm": 0.9004220366477966,
      "learning_rate": 1.899648770697441e-05,
      "loss": 0.0378,
      "step": 200
    },
    {
      "epoch": 0.06271951831409935,
      "grad_norm": 0.960844099521637,
      "learning_rate": 1.8745609633718013e-05,
      "loss": 0.0361,
      "step": 250
    },
    {
      "epoch": 0.07526342197691922,
      "grad_norm": 0.6969327330589294,
      "learning_rate": 1.8494731560461615e-05,
      "loss": 0.0301,
      "step": 300
    },
    {
      "epoch": 0.08780732563973909,
      "grad_norm": 0.7679114937782288,
      "learning_rate": 1.8243853487205218e-05,
      "loss": 0.0253,
      "step": 350
    },
    {
      "epoch": 0.10035122930255895,
      "grad_norm": 0.6460243463516235,
      "learning_rate": 1.7992975413948823e-05,
      "loss": 0.0259,
      "step": 400
    },
    {
      "epoch": 0.11289513296537883,
      "grad_norm": 0.6342681050300598,
      "learning_rate": 1.7742097340692426e-05,
      "loss": 0.0245,
      "step": 450
    },
    {
      "epoch": 0.1254390366281987,
      "grad_norm": 0.6866570711135864,
      "learning_rate": 1.7491219267436028e-05,
      "loss": 0.0252,
      "step": 500
    },
    {
      "epoch": 0.13798294029101857,
      "grad_norm": 0.468817800283432,
      "learning_rate": 1.724034119417963e-05,
      "loss": 0.0238,
      "step": 550
    },
    {
      "epoch": 0.15052684395383845,
      "grad_norm": 0.7380320429801941,
      "learning_rate": 1.6989463120923233e-05,
      "loss": 0.0217,
      "step": 600
    },
    {
      "epoch": 0.1630707476166583,
      "grad_norm": 0.5688631534576416,
      "learning_rate": 1.6738585047666835e-05,
      "loss": 0.0207,
      "step": 650
    },
    {
      "epoch": 0.17561465127947817,
      "grad_norm": 0.7884639501571655,
      "learning_rate": 1.6487706974410437e-05,
      "loss": 0.021,
      "step": 700
    },
    {
      "epoch": 0.18815855494229805,
      "grad_norm": 1.1118905544281006,
      "learning_rate": 1.623682890115404e-05,
      "loss": 0.0205,
      "step": 750
    },
    {
      "epoch": 0.2007024586051179,
      "grad_norm": 0.6408849954605103,
      "learning_rate": 1.5985950827897642e-05,
      "loss": 0.0231,
      "step": 800
    },
    {
      "epoch": 0.2007024586051179,
      "eval_loss": 0.020331038162112236,
      "eval_runtime": 22.9871,
      "eval_samples_per_second": 170.879,
      "eval_steps_per_second": 21.36,
      "step": 800
    },
    {
      "epoch": 0.21324636226793778,
      "grad_norm": 0.57598876953125,
      "learning_rate": 1.5735072754641244e-05,
      "loss": 0.0189,
      "step": 850
    },
    {
      "epoch": 0.22579026593075766,
      "grad_norm": 0.43264487385749817,
      "learning_rate": 1.5484194681384846e-05,
      "loss": 0.0165,
      "step": 900
    },
    {
      "epoch": 0.23833416959357753,
      "grad_norm": 0.48817911744117737,
      "learning_rate": 1.523331660812845e-05,
      "loss": 0.0162,
      "step": 950
    },
    {
      "epoch": 0.2508780732563974,
      "grad_norm": 0.5032162666320801,
      "learning_rate": 1.4982438534872053e-05,
      "loss": 0.0151,
      "step": 1000
    },
    {
      "epoch": 0.26342197691921726,
      "grad_norm": 0.3321874439716339,
      "learning_rate": 1.4731560461615655e-05,
      "loss": 0.0159,
      "step": 1050
    },
    {
      "epoch": 0.27596588058203714,
      "grad_norm": 0.51109778881073,
      "learning_rate": 1.4480682388359259e-05,
      "loss": 0.0159,
      "step": 1100
    },
    {
      "epoch": 0.288509784244857,
      "grad_norm": 0.562524676322937,
      "learning_rate": 1.4229804315102861e-05,
      "loss": 0.0146,
      "step": 1150
    },
    {
      "epoch": 0.3010536879076769,
      "grad_norm": 0.414717435836792,
      "learning_rate": 1.3978926241846464e-05,
      "loss": 0.0154,
      "step": 1200
    },
    {
      "epoch": 0.3135975915704967,
      "grad_norm": 0.6690582036972046,
      "learning_rate": 1.3728048168590068e-05,
      "loss": 0.0142,
      "step": 1250
    },
    {
      "epoch": 0.3261414952333166,
      "grad_norm": 0.4664822518825531,
      "learning_rate": 1.347717009533367e-05,
      "loss": 0.0159,
      "step": 1300
    },
    {
      "epoch": 0.33868539889613647,
      "grad_norm": 0.7217100262641907,
      "learning_rate": 1.3226292022077272e-05,
      "loss": 0.0167,
      "step": 1350
    },
    {
      "epoch": 0.35122930255895635,
      "grad_norm": 0.5258963704109192,
      "learning_rate": 1.2975413948820875e-05,
      "loss": 0.0139,
      "step": 1400
    },
    {
      "epoch": 0.3637732062217762,
      "grad_norm": 0.46249595284461975,
      "learning_rate": 1.2724535875564477e-05,
      "loss": 0.0137,
      "step": 1450
    },
    {
      "epoch": 0.3763171098845961,
      "grad_norm": 0.6240169405937195,
      "learning_rate": 1.2473657802308079e-05,
      "loss": 0.0139,
      "step": 1500
    },
    {
      "epoch": 0.388861013547416,
      "grad_norm": 0.4037911891937256,
      "learning_rate": 1.2222779729051681e-05,
      "loss": 0.0134,
      "step": 1550
    },
    {
      "epoch": 0.4014049172102358,
      "grad_norm": 0.45748963952064514,
      "learning_rate": 1.1971901655795284e-05,
      "loss": 0.0122,
      "step": 1600
    },
    {
      "epoch": 0.4014049172102358,
      "eval_loss": 0.01502222940325737,
      "eval_runtime": 23.3328,
      "eval_samples_per_second": 168.347,
      "eval_steps_per_second": 21.043,
      "step": 1600
    },
    {
      "epoch": 0.4139488208730557,
      "grad_norm": 0.24865801632404327,
      "learning_rate": 1.1721023582538886e-05,
      "loss": 0.0124,
      "step": 1650
    },
    {
      "epoch": 0.42649272453587556,
      "grad_norm": 0.5147280097007751,
      "learning_rate": 1.1470145509282488e-05,
      "loss": 0.0122,
      "step": 1700
    },
    {
      "epoch": 0.43903662819869543,
      "grad_norm": 0.5739248394966125,
      "learning_rate": 1.121926743602609e-05,
      "loss": 0.0132,
      "step": 1750
    },
    {
      "epoch": 0.4515805318615153,
      "grad_norm": 0.483505517244339,
      "learning_rate": 1.0968389362769696e-05,
      "loss": 0.0108,
      "step": 1800
    },
    {
      "epoch": 0.4641244355243352,
      "grad_norm": 0.7091925740242004,
      "learning_rate": 1.0717511289513299e-05,
      "loss": 0.0155,
      "step": 1850
    },
    {
      "epoch": 0.47666833918715507,
      "grad_norm": 0.38349398970603943,
      "learning_rate": 1.0466633216256901e-05,
      "loss": 0.0117,
      "step": 1900
    },
    {
      "epoch": 0.4892122428499749,
      "grad_norm": 0.25685688853263855,
      "learning_rate": 1.0215755143000503e-05,
      "loss": 0.0109,
      "step": 1950
    },
    {
      "epoch": 0.5017561465127948,
      "grad_norm": 0.32460150122642517,
      "learning_rate": 9.964877069744106e-06,
      "loss": 0.0123,
      "step": 2000
    },
    {
      "epoch": 0.5143000501756146,
      "grad_norm": 0.3709569275379181,
      "learning_rate": 9.713998996487708e-06,
      "loss": 0.0132,
      "step": 2050
    },
    {
      "epoch": 0.5268439538384345,
      "grad_norm": 0.4557553231716156,
      "learning_rate": 9.46312092323131e-06,
      "loss": 0.011,
      "step": 2100
    },
    {
      "epoch": 0.5393878575012544,
      "grad_norm": 0.27447274327278137,
      "learning_rate": 9.212242849974912e-06,
      "loss": 0.0114,
      "step": 2150
    },
    {
      "epoch": 0.5519317611640743,
      "grad_norm": 0.45794954895973206,
      "learning_rate": 8.961364776718515e-06,
      "loss": 0.011,
      "step": 2200
    },
    {
      "epoch": 0.5644756648268942,
      "grad_norm": 0.32490074634552,
      "learning_rate": 8.710486703462117e-06,
      "loss": 0.0102,
      "step": 2250
    },
    {
      "epoch": 0.577019568489714,
      "grad_norm": 0.5136626958847046,
      "learning_rate": 8.459608630205721e-06,
      "loss": 0.0106,
      "step": 2300
    },
    {
      "epoch": 0.5895634721525339,
      "grad_norm": 0.42534998059272766,
      "learning_rate": 8.208730556949323e-06,
      "loss": 0.0093,
      "step": 2350
    },
    {
      "epoch": 0.6021073758153538,
      "grad_norm": 0.43679532408714294,
      "learning_rate": 7.957852483692926e-06,
      "loss": 0.0104,
      "step": 2400
    },
    {
      "epoch": 0.6021073758153538,
      "eval_loss": 0.011843070387840271,
      "eval_runtime": 23.4847,
      "eval_samples_per_second": 167.258,
      "eval_steps_per_second": 20.907,
      "step": 2400
    },
    {
      "epoch": 0.6146512794781737,
      "grad_norm": 0.5039234757423401,
      "learning_rate": 7.706974410436528e-06,
      "loss": 0.0107,
      "step": 2450
    },
    {
      "epoch": 0.6271951831409934,
      "grad_norm": 0.4773517847061157,
      "learning_rate": 7.456096337180131e-06,
      "loss": 0.0098,
      "step": 2500
    },
    {
      "epoch": 0.6397390868038133,
      "grad_norm": 0.4157596826553345,
      "learning_rate": 7.205218263923733e-06,
      "loss": 0.0089,
      "step": 2550
    },
    {
      "epoch": 0.6522829904666332,
      "grad_norm": 0.24115760624408722,
      "learning_rate": 6.954340190667336e-06,
      "loss": 0.0094,
      "step": 2600
    },
    {
      "epoch": 0.6648268941294531,
      "grad_norm": 0.6312189102172852,
      "learning_rate": 6.70346211741094e-06,
      "loss": 0.0102,
      "step": 2650
    },
    {
      "epoch": 0.6773707977922729,
      "grad_norm": 0.2178553342819214,
      "learning_rate": 6.452584044154542e-06,
      "loss": 0.0093,
      "step": 2700
    },
    {
      "epoch": 0.6899147014550928,
      "grad_norm": 0.5677631497383118,
      "learning_rate": 6.201705970898144e-06,
      "loss": 0.0092,
      "step": 2750
    },
    {
      "epoch": 0.7024586051179127,
      "grad_norm": 0.4755932092666626,
      "learning_rate": 5.950827897641747e-06,
      "loss": 0.0099,
      "step": 2800
    },
    {
      "epoch": 0.7150025087807326,
      "grad_norm": 0.39095038175582886,
      "learning_rate": 5.699949824385349e-06,
      "loss": 0.0101,
      "step": 2850
    },
    {
      "epoch": 0.7275464124435524,
      "grad_norm": 0.23268954455852509,
      "learning_rate": 5.449071751128951e-06,
      "loss": 0.0108,
      "step": 2900
    },
    {
      "epoch": 0.7400903161063723,
      "grad_norm": 0.3099881708621979,
      "learning_rate": 5.1981936778725535e-06,
      "loss": 0.0104,
      "step": 2950
    },
    {
      "epoch": 0.7526342197691922,
      "grad_norm": 0.5433809757232666,
      "learning_rate": 4.947315604616157e-06,
      "loss": 0.0094,
      "step": 3000
    },
    {
      "epoch": 0.7651781234320121,
      "grad_norm": 0.4957410395145416,
      "learning_rate": 4.696437531359759e-06,
      "loss": 0.0098,
      "step": 3050
    },
    {
      "epoch": 0.777722027094832,
      "grad_norm": 0.5080188512802124,
      "learning_rate": 4.445559458103362e-06,
      "loss": 0.009,
      "step": 3100
    },
    {
      "epoch": 0.7902659307576518,
      "grad_norm": 0.2538832128047943,
      "learning_rate": 4.194681384846964e-06,
      "loss": 0.008,
      "step": 3150
    },
    {
      "epoch": 0.8028098344204716,
      "grad_norm": 0.18825191259384155,
      "learning_rate": 3.9438033115905676e-06,
      "loss": 0.0082,
      "step": 3200
    },
    {
      "epoch": 0.8028098344204716,
      "eval_loss": 0.010425237007439137,
      "eval_runtime": 23.4427,
      "eval_samples_per_second": 167.558,
      "eval_steps_per_second": 20.945,
      "step": 3200
    }
  ],
  "logging_steps": 50,
  "max_steps": 3986,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 800,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1.021912547328e+16,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
