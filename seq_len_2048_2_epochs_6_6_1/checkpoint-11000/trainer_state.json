{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 2.8068384792038783,
  "eval_steps": 1100,
  "global_step": 11000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.012758356723653993,
      "grad_norm": 9.147294044494629,
      "learning_rate": 0.00019914944288508974,
      "loss": 6.2717,
      "step": 50
    },
    {
      "epoch": 0.025516713447307986,
      "grad_norm": 8.049263954162598,
      "learning_rate": 0.00019829888577017947,
      "loss": 5.409,
      "step": 100
    },
    {
      "epoch": 0.03827507017096198,
      "grad_norm": 9.0841646194458,
      "learning_rate": 0.0001974483286552692,
      "loss": 5.1211,
      "step": 150
    },
    {
      "epoch": 0.05103342689461597,
      "grad_norm": 5.547089576721191,
      "learning_rate": 0.00019659777154035893,
      "loss": 4.8191,
      "step": 200
    },
    {
      "epoch": 0.06379178361826997,
      "grad_norm": 7.46530294418335,
      "learning_rate": 0.00019574721442544866,
      "loss": 4.6707,
      "step": 250
    },
    {
      "epoch": 0.07655014034192396,
      "grad_norm": 4.436773777008057,
      "learning_rate": 0.00019489665731053842,
      "loss": 4.4972,
      "step": 300
    },
    {
      "epoch": 0.08930849706557796,
      "grad_norm": 3.7118868827819824,
      "learning_rate": 0.00019404610019562815,
      "loss": 4.4096,
      "step": 350
    },
    {
      "epoch": 0.10206685378923194,
      "grad_norm": 3.9533448219299316,
      "learning_rate": 0.00019319554308071788,
      "loss": 4.3373,
      "step": 400
    },
    {
      "epoch": 0.11482521051288594,
      "grad_norm": 3.2572319507598877,
      "learning_rate": 0.00019234498596580762,
      "loss": 4.3061,
      "step": 450
    },
    {
      "epoch": 0.12758356723653994,
      "grad_norm": 3.4508166313171387,
      "learning_rate": 0.00019149442885089735,
      "loss": 4.1463,
      "step": 500
    },
    {
      "epoch": 0.14034192396019393,
      "grad_norm": 2.8880720138549805,
      "learning_rate": 0.00019064387173598708,
      "loss": 4.1579,
      "step": 550
    },
    {
      "epoch": 0.15310028068384793,
      "grad_norm": 3.8020811080932617,
      "learning_rate": 0.0001897933146210768,
      "loss": 4.1318,
      "step": 600
    },
    {
      "epoch": 0.16585863740750192,
      "grad_norm": 2.858781337738037,
      "learning_rate": 0.00018894275750616654,
      "loss": 4.1893,
      "step": 650
    },
    {
      "epoch": 0.17861699413115592,
      "grad_norm": 2.4542739391326904,
      "learning_rate": 0.00018809220039125627,
      "loss": 4.0708,
      "step": 700
    },
    {
      "epoch": 0.1913753508548099,
      "grad_norm": 3.704606533050537,
      "learning_rate": 0.000187241643276346,
      "loss": 4.027,
      "step": 750
    },
    {
      "epoch": 0.20413370757846389,
      "grad_norm": 2.6289255619049072,
      "learning_rate": 0.00018639108616143576,
      "loss": 4.0755,
      "step": 800
    },
    {
      "epoch": 0.21689206430211788,
      "grad_norm": 2.527933359146118,
      "learning_rate": 0.0001855405290465255,
      "loss": 4.039,
      "step": 850
    },
    {
      "epoch": 0.22965042102577188,
      "grad_norm": 2.700329542160034,
      "learning_rate": 0.00018468997193161522,
      "loss": 4.0265,
      "step": 900
    },
    {
      "epoch": 0.24240877774942587,
      "grad_norm": 2.6162185668945312,
      "learning_rate": 0.00018383941481670495,
      "loss": 3.9644,
      "step": 950
    },
    {
      "epoch": 0.25516713447307987,
      "grad_norm": 2.9507060050964355,
      "learning_rate": 0.00018298885770179468,
      "loss": 4.0404,
      "step": 1000
    },
    {
      "epoch": 0.26792549119673387,
      "grad_norm": 2.838250160217285,
      "learning_rate": 0.0001821383005868844,
      "loss": 3.9647,
      "step": 1050
    },
    {
      "epoch": 0.28068384792038786,
      "grad_norm": 2.8724100589752197,
      "learning_rate": 0.00018128774347197414,
      "loss": 3.9612,
      "step": 1100
    },
    {
      "epoch": 0.28068384792038786,
      "eval_loss": 3.9976484775543213,
      "eval_runtime": 101.8251,
      "eval_samples_per_second": 18.561,
      "eval_steps_per_second": 4.645,
      "step": 1100
    },
    {
      "epoch": 0.29344220464404186,
      "grad_norm": 2.6082093715667725,
      "learning_rate": 0.00018043718635706388,
      "loss": 3.9662,
      "step": 1150
    },
    {
      "epoch": 0.30620056136769586,
      "grad_norm": 2.335679769515991,
      "learning_rate": 0.0001795866292421536,
      "loss": 3.9747,
      "step": 1200
    },
    {
      "epoch": 0.31895891809134985,
      "grad_norm": 2.3881022930145264,
      "learning_rate": 0.00017873607212724334,
      "loss": 3.9709,
      "step": 1250
    },
    {
      "epoch": 0.33171727481500385,
      "grad_norm": 2.431628465652466,
      "learning_rate": 0.00017788551501233307,
      "loss": 4.0042,
      "step": 1300
    },
    {
      "epoch": 0.34447563153865784,
      "grad_norm": 2.7356693744659424,
      "learning_rate": 0.00017703495789742283,
      "loss": 3.8947,
      "step": 1350
    },
    {
      "epoch": 0.35723398826231184,
      "grad_norm": 2.750070810317993,
      "learning_rate": 0.00017618440078251256,
      "loss": 3.8512,
      "step": 1400
    },
    {
      "epoch": 0.3699923449859658,
      "grad_norm": 2.4731366634368896,
      "learning_rate": 0.0001753338436676023,
      "loss": 3.9356,
      "step": 1450
    },
    {
      "epoch": 0.3827507017096198,
      "grad_norm": 2.494988441467285,
      "learning_rate": 0.00017448328655269202,
      "loss": 3.8421,
      "step": 1500
    },
    {
      "epoch": 0.3955090584332738,
      "grad_norm": 2.4767820835113525,
      "learning_rate": 0.00017363272943778175,
      "loss": 3.8235,
      "step": 1550
    },
    {
      "epoch": 0.40826741515692777,
      "grad_norm": 2.1864161491394043,
      "learning_rate": 0.00017278217232287148,
      "loss": 3.8312,
      "step": 1600
    },
    {
      "epoch": 0.42102577188058177,
      "grad_norm": 2.7326765060424805,
      "learning_rate": 0.0001719316152079612,
      "loss": 3.9002,
      "step": 1650
    },
    {
      "epoch": 0.43378412860423576,
      "grad_norm": 2.288320779800415,
      "learning_rate": 0.00017108105809305094,
      "loss": 3.891,
      "step": 1700
    },
    {
      "epoch": 0.44654248532788976,
      "grad_norm": 2.375645399093628,
      "learning_rate": 0.00017023050097814067,
      "loss": 3.8729,
      "step": 1750
    },
    {
      "epoch": 0.45930084205154376,
      "grad_norm": 2.413512706756592,
      "learning_rate": 0.0001693799438632304,
      "loss": 3.9292,
      "step": 1800
    },
    {
      "epoch": 0.47205919877519775,
      "grad_norm": 5.769064426422119,
      "learning_rate": 0.00016852938674832016,
      "loss": 3.7835,
      "step": 1850
    },
    {
      "epoch": 0.48481755549885175,
      "grad_norm": 3.1181743144989014,
      "learning_rate": 0.0001676788296334099,
      "loss": 3.8242,
      "step": 1900
    },
    {
      "epoch": 0.49757591222250575,
      "grad_norm": 2.055314064025879,
      "learning_rate": 0.00016682827251849962,
      "loss": 3.8701,
      "step": 1950
    },
    {
      "epoch": 0.5103342689461597,
      "grad_norm": 2.1133522987365723,
      "learning_rate": 0.00016597771540358936,
      "loss": 3.8705,
      "step": 2000
    },
    {
      "epoch": 0.5230926256698137,
      "grad_norm": 2.106095552444458,
      "learning_rate": 0.00016512715828867909,
      "loss": 3.8059,
      "step": 2050
    },
    {
      "epoch": 0.5358509823934677,
      "grad_norm": 2.7277326583862305,
      "learning_rate": 0.00016427660117376882,
      "loss": 3.921,
      "step": 2100
    },
    {
      "epoch": 0.5486093391171217,
      "grad_norm": 2.029937505722046,
      "learning_rate": 0.00016342604405885855,
      "loss": 3.9004,
      "step": 2150
    },
    {
      "epoch": 0.5613676958407757,
      "grad_norm": 2.120204210281372,
      "learning_rate": 0.00016257548694394828,
      "loss": 3.8354,
      "step": 2200
    },
    {
      "epoch": 0.5613676958407757,
      "eval_loss": 3.84678053855896,
      "eval_runtime": 101.8589,
      "eval_samples_per_second": 18.555,
      "eval_steps_per_second": 4.644,
      "step": 2200
    },
    {
      "epoch": 0.5741260525644297,
      "grad_norm": 2.6318702697753906,
      "learning_rate": 0.000161724929829038,
      "loss": 3.8114,
      "step": 2250
    },
    {
      "epoch": 0.5868844092880837,
      "grad_norm": 2.216700315475464,
      "learning_rate": 0.00016087437271412774,
      "loss": 3.8347,
      "step": 2300
    },
    {
      "epoch": 0.5996427660117377,
      "grad_norm": 2.1919617652893066,
      "learning_rate": 0.0001600238155992175,
      "loss": 3.9048,
      "step": 2350
    },
    {
      "epoch": 0.6124011227353917,
      "grad_norm": 2.238442897796631,
      "learning_rate": 0.00015917325848430723,
      "loss": 3.7875,
      "step": 2400
    },
    {
      "epoch": 0.6251594794590457,
      "grad_norm": 2.6809442043304443,
      "learning_rate": 0.00015832270136939696,
      "loss": 3.7464,
      "step": 2450
    },
    {
      "epoch": 0.6379178361826997,
      "grad_norm": 2.3197567462921143,
      "learning_rate": 0.0001574721442544867,
      "loss": 3.7307,
      "step": 2500
    },
    {
      "epoch": 0.6506761929063537,
      "grad_norm": 2.233642339706421,
      "learning_rate": 0.00015662158713957642,
      "loss": 3.8067,
      "step": 2550
    },
    {
      "epoch": 0.6634345496300077,
      "grad_norm": 2.7977259159088135,
      "learning_rate": 0.00015577103002466615,
      "loss": 3.7619,
      "step": 2600
    },
    {
      "epoch": 0.6761929063536617,
      "grad_norm": 2.60278058052063,
      "learning_rate": 0.00015492047290975588,
      "loss": 3.7053,
      "step": 2650
    },
    {
      "epoch": 0.6889512630773157,
      "grad_norm": 2.35569167137146,
      "learning_rate": 0.00015406991579484562,
      "loss": 3.7592,
      "step": 2700
    },
    {
      "epoch": 0.7017096198009697,
      "grad_norm": 2.5158402919769287,
      "learning_rate": 0.00015321935867993535,
      "loss": 3.7243,
      "step": 2750
    },
    {
      "epoch": 0.7144679765246237,
      "grad_norm": 2.0924301147460938,
      "learning_rate": 0.00015236880156502508,
      "loss": 3.7075,
      "step": 2800
    },
    {
      "epoch": 0.7272263332482776,
      "grad_norm": 2.0635266304016113,
      "learning_rate": 0.00015151824445011484,
      "loss": 3.7878,
      "step": 2850
    },
    {
      "epoch": 0.7399846899719316,
      "grad_norm": 2.352959632873535,
      "learning_rate": 0.00015066768733520457,
      "loss": 3.7586,
      "step": 2900
    },
    {
      "epoch": 0.7527430466955856,
      "grad_norm": 2.2424824237823486,
      "learning_rate": 0.0001498171302202943,
      "loss": 3.8198,
      "step": 2950
    },
    {
      "epoch": 0.7655014034192396,
      "grad_norm": 2.235342502593994,
      "learning_rate": 0.00014896657310538406,
      "loss": 3.7726,
      "step": 3000
    },
    {
      "epoch": 0.7782597601428936,
      "grad_norm": 2.2025787830352783,
      "learning_rate": 0.00014811601599047379,
      "loss": 3.7704,
      "step": 3050
    },
    {
      "epoch": 0.7910181168665475,
      "grad_norm": 2.1054816246032715,
      "learning_rate": 0.00014726545887556352,
      "loss": 3.7905,
      "step": 3100
    },
    {
      "epoch": 0.8037764735902015,
      "grad_norm": 2.4116783142089844,
      "learning_rate": 0.00014641490176065325,
      "loss": 3.7456,
      "step": 3150
    },
    {
      "epoch": 0.8165348303138555,
      "grad_norm": 2.0435521602630615,
      "learning_rate": 0.00014556434464574298,
      "loss": 3.8111,
      "step": 3200
    },
    {
      "epoch": 0.8292931870375095,
      "grad_norm": 2.5290606021881104,
      "learning_rate": 0.0001447137875308327,
      "loss": 3.7812,
      "step": 3250
    },
    {
      "epoch": 0.8420515437611635,
      "grad_norm": 1.9299403429031372,
      "learning_rate": 0.00014386323041592244,
      "loss": 3.7357,
      "step": 3300
    },
    {
      "epoch": 0.8420515437611635,
      "eval_loss": 3.7748160362243652,
      "eval_runtime": 102.0347,
      "eval_samples_per_second": 18.523,
      "eval_steps_per_second": 4.636,
      "step": 3300
    },
    {
      "epoch": 0.8548099004848175,
      "grad_norm": 2.268869638442993,
      "learning_rate": 0.00014301267330101217,
      "loss": 3.6925,
      "step": 3350
    },
    {
      "epoch": 0.8675682572084715,
      "grad_norm": 2.2348482608795166,
      "learning_rate": 0.0001421621161861019,
      "loss": 3.7762,
      "step": 3400
    },
    {
      "epoch": 0.8803266139321255,
      "grad_norm": 1.943167805671692,
      "learning_rate": 0.00014131155907119163,
      "loss": 3.6863,
      "step": 3450
    },
    {
      "epoch": 0.8930849706557795,
      "grad_norm": 1.9835277795791626,
      "learning_rate": 0.0001404610019562814,
      "loss": 3.6065,
      "step": 3500
    },
    {
      "epoch": 0.9058433273794335,
      "grad_norm": 2.2734317779541016,
      "learning_rate": 0.00013961044484137112,
      "loss": 3.7516,
      "step": 3550
    },
    {
      "epoch": 0.9186016841030875,
      "grad_norm": 1.9005863666534424,
      "learning_rate": 0.00013875988772646085,
      "loss": 3.6978,
      "step": 3600
    },
    {
      "epoch": 0.9313600408267415,
      "grad_norm": 2.0506598949432373,
      "learning_rate": 0.00013790933061155058,
      "loss": 3.7121,
      "step": 3650
    },
    {
      "epoch": 0.9441183975503955,
      "grad_norm": 1.9326155185699463,
      "learning_rate": 0.00013705877349664032,
      "loss": 3.7293,
      "step": 3700
    },
    {
      "epoch": 0.9568767542740495,
      "grad_norm": 2.07138729095459,
      "learning_rate": 0.00013620821638173005,
      "loss": 3.7677,
      "step": 3750
    },
    {
      "epoch": 0.9696351109977035,
      "grad_norm": 2.286412239074707,
      "learning_rate": 0.00013535765926681978,
      "loss": 3.6795,
      "step": 3800
    },
    {
      "epoch": 0.9823934677213575,
      "grad_norm": 2.0788633823394775,
      "learning_rate": 0.0001345071021519095,
      "loss": 3.6892,
      "step": 3850
    },
    {
      "epoch": 0.9951518244450115,
      "grad_norm": 2.2463693618774414,
      "learning_rate": 0.00013365654503699924,
      "loss": 3.7122,
      "step": 3900
    },
    {
      "epoch": 1.0079101811686655,
      "grad_norm": 2.0061423778533936,
      "learning_rate": 0.00013280598792208897,
      "loss": 3.6109,
      "step": 3950
    },
    {
      "epoch": 1.0206685378923195,
      "grad_norm": 2.2510948181152344,
      "learning_rate": 0.00013195543080717873,
      "loss": 3.5075,
      "step": 4000
    },
    {
      "epoch": 1.0334268946159735,
      "grad_norm": 2.0288259983062744,
      "learning_rate": 0.00013110487369226846,
      "loss": 3.4662,
      "step": 4050
    },
    {
      "epoch": 1.0461852513396275,
      "grad_norm": 1.9691715240478516,
      "learning_rate": 0.0001302543165773582,
      "loss": 3.5862,
      "step": 4100
    },
    {
      "epoch": 1.0589436080632815,
      "grad_norm": 1.9248460531234741,
      "learning_rate": 0.00012940375946244792,
      "loss": 3.5035,
      "step": 4150
    },
    {
      "epoch": 1.0717019647869355,
      "grad_norm": 2.031043291091919,
      "learning_rate": 0.00012855320234753765,
      "loss": 3.5817,
      "step": 4200
    },
    {
      "epoch": 1.0844603215105895,
      "grad_norm": 1.8697270154953003,
      "learning_rate": 0.00012770264523262738,
      "loss": 3.4659,
      "step": 4250
    },
    {
      "epoch": 1.0972186782342435,
      "grad_norm": 2.042685031890869,
      "learning_rate": 0.00012685208811771711,
      "loss": 3.6012,
      "step": 4300
    },
    {
      "epoch": 1.1099770349578975,
      "grad_norm": 1.9254460334777832,
      "learning_rate": 0.00012600153100280684,
      "loss": 3.4919,
      "step": 4350
    },
    {
      "epoch": 1.1227353916815515,
      "grad_norm": 2.110335111618042,
      "learning_rate": 0.00012515097388789658,
      "loss": 3.5149,
      "step": 4400
    },
    {
      "epoch": 1.1227353916815515,
      "eval_loss": 3.7428693771362305,
      "eval_runtime": 101.9113,
      "eval_samples_per_second": 18.546,
      "eval_steps_per_second": 4.641,
      "step": 4400
    },
    {
      "epoch": 1.1354937484052054,
      "grad_norm": 2.0809109210968018,
      "learning_rate": 0.0001243004167729863,
      "loss": 3.4931,
      "step": 4450
    },
    {
      "epoch": 1.1482521051288594,
      "grad_norm": 2.0175459384918213,
      "learning_rate": 0.00012344985965807604,
      "loss": 3.5401,
      "step": 4500
    },
    {
      "epoch": 1.1610104618525134,
      "grad_norm": 12.140454292297363,
      "learning_rate": 0.0001225993025431658,
      "loss": 3.5346,
      "step": 4550
    },
    {
      "epoch": 1.1737688185761674,
      "grad_norm": 1.9812700748443604,
      "learning_rate": 0.00012174874542825551,
      "loss": 3.6311,
      "step": 4600
    },
    {
      "epoch": 1.1865271752998214,
      "grad_norm": 1.9584025144577026,
      "learning_rate": 0.00012089818831334526,
      "loss": 3.6153,
      "step": 4650
    },
    {
      "epoch": 1.1992855320234754,
      "grad_norm": 1.9618053436279297,
      "learning_rate": 0.00012004763119843499,
      "loss": 3.5527,
      "step": 4700
    },
    {
      "epoch": 1.2120438887471294,
      "grad_norm": 1.9533425569534302,
      "learning_rate": 0.00011919707408352472,
      "loss": 3.4523,
      "step": 4750
    },
    {
      "epoch": 1.2248022454707834,
      "grad_norm": 2.2324249744415283,
      "learning_rate": 0.00011834651696861445,
      "loss": 3.4474,
      "step": 4800
    },
    {
      "epoch": 1.2375606021944374,
      "grad_norm": 1.8629523515701294,
      "learning_rate": 0.00011749595985370418,
      "loss": 3.5724,
      "step": 4850
    },
    {
      "epoch": 1.2503189589180914,
      "grad_norm": 1.9518123865127563,
      "learning_rate": 0.00011664540273879391,
      "loss": 3.5311,
      "step": 4900
    },
    {
      "epoch": 1.2630773156417454,
      "grad_norm": 1.9785577058792114,
      "learning_rate": 0.00011579484562388366,
      "loss": 3.5853,
      "step": 4950
    },
    {
      "epoch": 1.2758356723653994,
      "grad_norm": 2.035661458969116,
      "learning_rate": 0.00011494428850897339,
      "loss": 3.5056,
      "step": 5000
    },
    {
      "epoch": 1.2885940290890534,
      "grad_norm": 1.9358999729156494,
      "learning_rate": 0.00011409373139406312,
      "loss": 3.5082,
      "step": 5050
    },
    {
      "epoch": 1.3013523858127074,
      "grad_norm": 1.8603458404541016,
      "learning_rate": 0.00011324317427915285,
      "loss": 3.5124,
      "step": 5100
    },
    {
      "epoch": 1.3141107425363614,
      "grad_norm": 1.8311318159103394,
      "learning_rate": 0.00011239261716424258,
      "loss": 3.5699,
      "step": 5150
    },
    {
      "epoch": 1.3268690992600152,
      "grad_norm": 2.081312656402588,
      "learning_rate": 0.00011154206004933232,
      "loss": 3.5261,
      "step": 5200
    },
    {
      "epoch": 1.3396274559836692,
      "grad_norm": 8.304096221923828,
      "learning_rate": 0.00011069150293442206,
      "loss": 3.5415,
      "step": 5250
    },
    {
      "epoch": 1.3523858127073232,
      "grad_norm": 1.9684617519378662,
      "learning_rate": 0.00010984094581951179,
      "loss": 3.5881,
      "step": 5300
    },
    {
      "epoch": 1.3651441694309772,
      "grad_norm": 1.8356890678405762,
      "learning_rate": 0.00010899038870460152,
      "loss": 3.4828,
      "step": 5350
    },
    {
      "epoch": 1.3779025261546312,
      "grad_norm": 2.0584628582000732,
      "learning_rate": 0.00010813983158969125,
      "loss": 3.5211,
      "step": 5400
    },
    {
      "epoch": 1.3906608828782852,
      "grad_norm": 1.899770736694336,
      "learning_rate": 0.00010728927447478099,
      "loss": 3.5187,
      "step": 5450
    },
    {
      "epoch": 1.4034192396019392,
      "grad_norm": 2.0028083324432373,
      "learning_rate": 0.00010643871735987072,
      "loss": 3.6176,
      "step": 5500
    },
    {
      "epoch": 1.4034192396019392,
      "eval_loss": 3.711334228515625,
      "eval_runtime": 102.5063,
      "eval_samples_per_second": 18.438,
      "eval_steps_per_second": 4.614,
      "step": 5500
    },
    {
      "epoch": 1.4161775963255931,
      "grad_norm": 2.332319736480713,
      "learning_rate": 0.00010558816024496045,
      "loss": 3.5868,
      "step": 5550
    },
    {
      "epoch": 1.4289359530492471,
      "grad_norm": 1.9084954261779785,
      "learning_rate": 0.00010473760313005019,
      "loss": 3.4491,
      "step": 5600
    },
    {
      "epoch": 1.4416943097729011,
      "grad_norm": 1.885914921760559,
      "learning_rate": 0.00010388704601513992,
      "loss": 3.4782,
      "step": 5650
    },
    {
      "epoch": 1.4544526664965551,
      "grad_norm": 2.0243961811065674,
      "learning_rate": 0.00010303648890022966,
      "loss": 3.5664,
      "step": 5700
    },
    {
      "epoch": 1.4672110232202091,
      "grad_norm": 1.9133459329605103,
      "learning_rate": 0.00010218593178531939,
      "loss": 3.5593,
      "step": 5750
    },
    {
      "epoch": 1.4799693799438631,
      "grad_norm": 1.9750125408172607,
      "learning_rate": 0.00010133537467040912,
      "loss": 3.5874,
      "step": 5800
    },
    {
      "epoch": 1.4927277366675171,
      "grad_norm": 1.9703706502914429,
      "learning_rate": 0.00010048481755549885,
      "loss": 3.5248,
      "step": 5850
    },
    {
      "epoch": 1.5054860933911711,
      "grad_norm": 1.9754643440246582,
      "learning_rate": 9.963426044058859e-05,
      "loss": 3.5464,
      "step": 5900
    },
    {
      "epoch": 1.5182444501148251,
      "grad_norm": 1.9626408815383911,
      "learning_rate": 9.878370332567833e-05,
      "loss": 3.486,
      "step": 5950
    },
    {
      "epoch": 1.5310028068384791,
      "grad_norm": 1.9652138948440552,
      "learning_rate": 9.793314621076806e-05,
      "loss": 3.512,
      "step": 6000
    },
    {
      "epoch": 1.543761163562133,
      "grad_norm": 1.9963724613189697,
      "learning_rate": 9.708258909585779e-05,
      "loss": 3.4893,
      "step": 6050
    },
    {
      "epoch": 1.556519520285787,
      "grad_norm": 1.7744921445846558,
      "learning_rate": 9.623203198094752e-05,
      "loss": 3.5811,
      "step": 6100
    },
    {
      "epoch": 1.569277877009441,
      "grad_norm": 2.0228095054626465,
      "learning_rate": 9.538147486603725e-05,
      "loss": 3.4817,
      "step": 6150
    },
    {
      "epoch": 1.582036233733095,
      "grad_norm": 2.150089740753174,
      "learning_rate": 9.453091775112698e-05,
      "loss": 3.6006,
      "step": 6200
    },
    {
      "epoch": 1.594794590456749,
      "grad_norm": 2.1277596950531006,
      "learning_rate": 9.368036063621673e-05,
      "loss": 3.4965,
      "step": 6250
    },
    {
      "epoch": 1.607552947180403,
      "grad_norm": 1.9649592638015747,
      "learning_rate": 9.282980352130646e-05,
      "loss": 3.4765,
      "step": 6300
    },
    {
      "epoch": 1.620311303904057,
      "grad_norm": 1.7634326219558716,
      "learning_rate": 9.197924640639619e-05,
      "loss": 3.5473,
      "step": 6350
    },
    {
      "epoch": 1.633069660627711,
      "grad_norm": 1.7260735034942627,
      "learning_rate": 9.112868929148592e-05,
      "loss": 3.4967,
      "step": 6400
    },
    {
      "epoch": 1.645828017351365,
      "grad_norm": 1.9747576713562012,
      "learning_rate": 9.027813217657565e-05,
      "loss": 3.4865,
      "step": 6450
    },
    {
      "epoch": 1.658586374075019,
      "grad_norm": 1.9290027618408203,
      "learning_rate": 8.94275750616654e-05,
      "loss": 3.4852,
      "step": 6500
    },
    {
      "epoch": 1.671344730798673,
      "grad_norm": 1.8202295303344727,
      "learning_rate": 8.857701794675513e-05,
      "loss": 3.4108,
      "step": 6550
    },
    {
      "epoch": 1.684103087522327,
      "grad_norm": 1.8330860137939453,
      "learning_rate": 8.772646083184486e-05,
      "loss": 3.522,
      "step": 6600
    },
    {
      "epoch": 1.684103087522327,
      "eval_loss": 3.6831488609313965,
      "eval_runtime": 101.9668,
      "eval_samples_per_second": 18.535,
      "eval_steps_per_second": 4.639,
      "step": 6600
    },
    {
      "epoch": 1.696861444245981,
      "grad_norm": 1.699510931968689,
      "learning_rate": 8.687590371693459e-05,
      "loss": 3.4557,
      "step": 6650
    },
    {
      "epoch": 1.709619800969635,
      "grad_norm": 1.7714710235595703,
      "learning_rate": 8.602534660202432e-05,
      "loss": 3.5712,
      "step": 6700
    },
    {
      "epoch": 1.722378157693289,
      "grad_norm": 1.8145521879196167,
      "learning_rate": 8.517478948711407e-05,
      "loss": 3.4813,
      "step": 6750
    },
    {
      "epoch": 1.735136514416943,
      "grad_norm": 1.756770372390747,
      "learning_rate": 8.43242323722038e-05,
      "loss": 3.4758,
      "step": 6800
    },
    {
      "epoch": 1.747894871140597,
      "grad_norm": 1.8299537897109985,
      "learning_rate": 8.347367525729353e-05,
      "loss": 3.5239,
      "step": 6850
    },
    {
      "epoch": 1.760653227864251,
      "grad_norm": 1.8698481321334839,
      "learning_rate": 8.262311814238326e-05,
      "loss": 3.4899,
      "step": 6900
    },
    {
      "epoch": 1.773411584587905,
      "grad_norm": 1.8405089378356934,
      "learning_rate": 8.177256102747299e-05,
      "loss": 3.5848,
      "step": 6950
    },
    {
      "epoch": 1.786169941311559,
      "grad_norm": 1.700426697731018,
      "learning_rate": 8.092200391256273e-05,
      "loss": 3.4831,
      "step": 7000
    },
    {
      "epoch": 1.798928298035213,
      "grad_norm": 1.8490235805511475,
      "learning_rate": 8.007144679765246e-05,
      "loss": 3.4462,
      "step": 7050
    },
    {
      "epoch": 1.811686654758867,
      "grad_norm": 2.0403380393981934,
      "learning_rate": 7.922088968274221e-05,
      "loss": 3.4939,
      "step": 7100
    },
    {
      "epoch": 1.824445011482521,
      "grad_norm": 1.9084793329238892,
      "learning_rate": 7.837033256783194e-05,
      "loss": 3.4578,
      "step": 7150
    },
    {
      "epoch": 1.837203368206175,
      "grad_norm": 1.9655534029006958,
      "learning_rate": 7.751977545292167e-05,
      "loss": 3.5367,
      "step": 7200
    },
    {
      "epoch": 1.849961724929829,
      "grad_norm": 2.0519189834594727,
      "learning_rate": 7.66692183380114e-05,
      "loss": 3.441,
      "step": 7250
    },
    {
      "epoch": 1.862720081653483,
      "grad_norm": 1.7243608236312866,
      "learning_rate": 7.581866122310115e-05,
      "loss": 3.5171,
      "step": 7300
    },
    {
      "epoch": 1.875478438377137,
      "grad_norm": 1.9046722650527954,
      "learning_rate": 7.496810410819088e-05,
      "loss": 3.4942,
      "step": 7350
    },
    {
      "epoch": 1.888236795100791,
      "grad_norm": 1.6559139490127563,
      "learning_rate": 7.411754699328061e-05,
      "loss": 3.4425,
      "step": 7400
    },
    {
      "epoch": 1.900995151824445,
      "grad_norm": 1.6546818017959595,
      "learning_rate": 7.326698987837034e-05,
      "loss": 3.4819,
      "step": 7450
    },
    {
      "epoch": 1.913753508548099,
      "grad_norm": 1.755567193031311,
      "learning_rate": 7.241643276346007e-05,
      "loss": 3.5707,
      "step": 7500
    },
    {
      "epoch": 1.926511865271753,
      "grad_norm": 2.0869128704071045,
      "learning_rate": 7.15658756485498e-05,
      "loss": 3.4028,
      "step": 7550
    },
    {
      "epoch": 1.939270221995407,
      "grad_norm": 1.7882663011550903,
      "learning_rate": 7.071531853363955e-05,
      "loss": 3.4436,
      "step": 7600
    },
    {
      "epoch": 1.952028578719061,
      "grad_norm": 1.7748770713806152,
      "learning_rate": 6.986476141872928e-05,
      "loss": 3.4288,
      "step": 7650
    },
    {
      "epoch": 1.964786935442715,
      "grad_norm": 1.8809453248977661,
      "learning_rate": 6.901420430381901e-05,
      "loss": 3.4507,
      "step": 7700
    },
    {
      "epoch": 1.964786935442715,
      "eval_loss": 3.6579558849334717,
      "eval_runtime": 101.9254,
      "eval_samples_per_second": 18.543,
      "eval_steps_per_second": 4.641,
      "step": 7700
    },
    {
      "epoch": 1.977545292166369,
      "grad_norm": 2.001955509185791,
      "learning_rate": 6.816364718890874e-05,
      "loss": 3.4121,
      "step": 7750
    },
    {
      "epoch": 1.990303648890023,
      "grad_norm": 1.8482496738433838,
      "learning_rate": 6.731309007399847e-05,
      "loss": 3.51,
      "step": 7800
    },
    {
      "epoch": 2.003062005613677,
      "grad_norm": 1.6995916366577148,
      "learning_rate": 6.646253295908821e-05,
      "loss": 3.4374,
      "step": 7850
    },
    {
      "epoch": 2.015820362337331,
      "grad_norm": 1.8331130743026733,
      "learning_rate": 6.561197584417794e-05,
      "loss": 3.231,
      "step": 7900
    },
    {
      "epoch": 2.028578719060985,
      "grad_norm": 1.766611099243164,
      "learning_rate": 6.476141872926768e-05,
      "loss": 3.2389,
      "step": 7950
    },
    {
      "epoch": 2.041337075784639,
      "grad_norm": 1.7027119398117065,
      "learning_rate": 6.39108616143574e-05,
      "loss": 3.3444,
      "step": 8000
    },
    {
      "epoch": 2.054095432508293,
      "grad_norm": 3.6559247970581055,
      "learning_rate": 6.306030449944714e-05,
      "loss": 3.2116,
      "step": 8050
    },
    {
      "epoch": 2.066853789231947,
      "grad_norm": 1.9382686614990234,
      "learning_rate": 6.220974738453688e-05,
      "loss": 3.3162,
      "step": 8100
    },
    {
      "epoch": 2.079612145955601,
      "grad_norm": 1.886792540550232,
      "learning_rate": 6.135919026962661e-05,
      "loss": 3.3509,
      "step": 8150
    },
    {
      "epoch": 2.092370502679255,
      "grad_norm": 1.8941816091537476,
      "learning_rate": 6.0508633154716344e-05,
      "loss": 3.2839,
      "step": 8200
    },
    {
      "epoch": 2.105128859402909,
      "grad_norm": 1.6910144090652466,
      "learning_rate": 5.9658076039806074e-05,
      "loss": 3.3453,
      "step": 8250
    },
    {
      "epoch": 2.117887216126563,
      "grad_norm": 1.7123456001281738,
      "learning_rate": 5.880751892489581e-05,
      "loss": 3.2995,
      "step": 8300
    },
    {
      "epoch": 2.130645572850217,
      "grad_norm": 1.7959822416305542,
      "learning_rate": 5.795696180998554e-05,
      "loss": 3.2933,
      "step": 8350
    },
    {
      "epoch": 2.143403929573871,
      "grad_norm": 1.7456386089324951,
      "learning_rate": 5.7106404695075274e-05,
      "loss": 3.3031,
      "step": 8400
    },
    {
      "epoch": 2.156162286297525,
      "grad_norm": 1.7973300218582153,
      "learning_rate": 5.625584758016501e-05,
      "loss": 3.2886,
      "step": 8450
    },
    {
      "epoch": 2.168920643021179,
      "grad_norm": 1.9373586177825928,
      "learning_rate": 5.540529046525474e-05,
      "loss": 3.2654,
      "step": 8500
    },
    {
      "epoch": 2.181678999744833,
      "grad_norm": 1.8130970001220703,
      "learning_rate": 5.455473335034448e-05,
      "loss": 3.2017,
      "step": 8550
    },
    {
      "epoch": 2.194437356468487,
      "grad_norm": 2.0180699825286865,
      "learning_rate": 5.370417623543421e-05,
      "loss": 3.2378,
      "step": 8600
    },
    {
      "epoch": 2.207195713192141,
      "grad_norm": 1.8464999198913574,
      "learning_rate": 5.285361912052394e-05,
      "loss": 3.2663,
      "step": 8650
    },
    {
      "epoch": 2.219954069915795,
      "grad_norm": 1.8286857604980469,
      "learning_rate": 5.200306200561368e-05,
      "loss": 3.2182,
      "step": 8700
    },
    {
      "epoch": 2.232712426639449,
      "grad_norm": 1.9602595567703247,
      "learning_rate": 5.115250489070341e-05,
      "loss": 3.3828,
      "step": 8750
    },
    {
      "epoch": 2.245470783363103,
      "grad_norm": 1.5564922094345093,
      "learning_rate": 5.030194777579315e-05,
      "loss": 3.2775,
      "step": 8800
    },
    {
      "epoch": 2.245470783363103,
      "eval_loss": 3.676527738571167,
      "eval_runtime": 102.0649,
      "eval_samples_per_second": 18.518,
      "eval_steps_per_second": 4.634,
      "step": 8800
    },
    {
      "epoch": 2.258229140086757,
      "grad_norm": 1.9747978448867798,
      "learning_rate": 4.945139066088288e-05,
      "loss": 3.3215,
      "step": 8850
    },
    {
      "epoch": 2.270987496810411,
      "grad_norm": 1.682971477508545,
      "learning_rate": 4.860083354597261e-05,
      "loss": 3.3282,
      "step": 8900
    },
    {
      "epoch": 2.283745853534065,
      "grad_norm": 1.6897222995758057,
      "learning_rate": 4.775027643106235e-05,
      "loss": 3.2835,
      "step": 8950
    },
    {
      "epoch": 2.296504210257719,
      "grad_norm": 2.041426181793213,
      "learning_rate": 4.689971931615208e-05,
      "loss": 3.2733,
      "step": 9000
    },
    {
      "epoch": 2.309262566981373,
      "grad_norm": 1.8221756219863892,
      "learning_rate": 4.604916220124181e-05,
      "loss": 3.3521,
      "step": 9050
    },
    {
      "epoch": 2.322020923705027,
      "grad_norm": 1.85381019115448,
      "learning_rate": 4.519860508633155e-05,
      "loss": 3.2795,
      "step": 9100
    },
    {
      "epoch": 2.334779280428681,
      "grad_norm": 1.8137328624725342,
      "learning_rate": 4.434804797142128e-05,
      "loss": 3.2471,
      "step": 9150
    },
    {
      "epoch": 2.347537637152335,
      "grad_norm": 1.780596137046814,
      "learning_rate": 4.3497490856511016e-05,
      "loss": 3.2665,
      "step": 9200
    },
    {
      "epoch": 2.360295993875989,
      "grad_norm": 1.9078599214553833,
      "learning_rate": 4.2646933741600754e-05,
      "loss": 3.2949,
      "step": 9250
    },
    {
      "epoch": 2.373054350599643,
      "grad_norm": 1.5747573375701904,
      "learning_rate": 4.1796376626690485e-05,
      "loss": 3.3214,
      "step": 9300
    },
    {
      "epoch": 2.385812707323297,
      "grad_norm": 1.8251575231552124,
      "learning_rate": 4.094581951178022e-05,
      "loss": 3.2141,
      "step": 9350
    },
    {
      "epoch": 2.398571064046951,
      "grad_norm": 1.7244712114334106,
      "learning_rate": 4.0095262396869954e-05,
      "loss": 3.3031,
      "step": 9400
    },
    {
      "epoch": 2.411329420770605,
      "grad_norm": 1.7322242259979248,
      "learning_rate": 3.9244705281959685e-05,
      "loss": 3.2736,
      "step": 9450
    },
    {
      "epoch": 2.424087777494259,
      "grad_norm": 1.750006914138794,
      "learning_rate": 3.839414816704942e-05,
      "loss": 3.3384,
      "step": 9500
    },
    {
      "epoch": 2.436846134217913,
      "grad_norm": 1.8464205265045166,
      "learning_rate": 3.754359105213915e-05,
      "loss": 3.2846,
      "step": 9550
    },
    {
      "epoch": 2.449604490941567,
      "grad_norm": 2.0665221214294434,
      "learning_rate": 3.669303393722889e-05,
      "loss": 3.2534,
      "step": 9600
    },
    {
      "epoch": 2.462362847665221,
      "grad_norm": 2.0907015800476074,
      "learning_rate": 3.584247682231862e-05,
      "loss": 3.3089,
      "step": 9650
    },
    {
      "epoch": 2.475121204388875,
      "grad_norm": 1.7573736906051636,
      "learning_rate": 3.499191970740835e-05,
      "loss": 3.3772,
      "step": 9700
    },
    {
      "epoch": 2.487879561112529,
      "grad_norm": 2.134390115737915,
      "learning_rate": 3.414136259249809e-05,
      "loss": 3.3134,
      "step": 9750
    },
    {
      "epoch": 2.500637917836183,
      "grad_norm": 1.8761241436004639,
      "learning_rate": 3.329080547758782e-05,
      "loss": 3.2467,
      "step": 9800
    },
    {
      "epoch": 2.513396274559837,
      "grad_norm": 1.7575228214263916,
      "learning_rate": 3.244024836267755e-05,
      "loss": 3.2892,
      "step": 9850
    },
    {
      "epoch": 2.526154631283491,
      "grad_norm": 1.5364054441452026,
      "learning_rate": 3.158969124776729e-05,
      "loss": 3.217,
      "step": 9900
    },
    {
      "epoch": 2.526154631283491,
      "eval_loss": 3.668360471725464,
      "eval_runtime": 101.9685,
      "eval_samples_per_second": 18.535,
      "eval_steps_per_second": 4.639,
      "step": 9900
    },
    {
      "epoch": 2.538912988007145,
      "grad_norm": 1.6950840950012207,
      "learning_rate": 3.073913413285702e-05,
      "loss": 3.3189,
      "step": 9950
    },
    {
      "epoch": 2.551671344730799,
      "grad_norm": 1.806368112564087,
      "learning_rate": 2.9888577017946755e-05,
      "loss": 3.2744,
      "step": 10000
    },
    {
      "epoch": 2.564429701454453,
      "grad_norm": 1.7163790464401245,
      "learning_rate": 2.903801990303649e-05,
      "loss": 3.247,
      "step": 10050
    },
    {
      "epoch": 2.577188058178107,
      "grad_norm": 1.5943796634674072,
      "learning_rate": 2.8187462788126224e-05,
      "loss": 3.2706,
      "step": 10100
    },
    {
      "epoch": 2.589946414901761,
      "grad_norm": 1.7288168668746948,
      "learning_rate": 2.733690567321596e-05,
      "loss": 3.3294,
      "step": 10150
    },
    {
      "epoch": 2.602704771625415,
      "grad_norm": 1.8576500415802002,
      "learning_rate": 2.648634855830569e-05,
      "loss": 3.2788,
      "step": 10200
    },
    {
      "epoch": 2.615463128349069,
      "grad_norm": 1.6639173030853271,
      "learning_rate": 2.5635791443395424e-05,
      "loss": 3.3097,
      "step": 10250
    },
    {
      "epoch": 2.628221485072723,
      "grad_norm": 1.641035795211792,
      "learning_rate": 2.478523432848516e-05,
      "loss": 3.3076,
      "step": 10300
    },
    {
      "epoch": 2.640979841796377,
      "grad_norm": 1.7388778924942017,
      "learning_rate": 2.3934677213574892e-05,
      "loss": 3.2818,
      "step": 10350
    },
    {
      "epoch": 2.6537381985200303,
      "grad_norm": 1.569686770439148,
      "learning_rate": 2.3084120098664627e-05,
      "loss": 3.227,
      "step": 10400
    },
    {
      "epoch": 2.6664965552436843,
      "grad_norm": 1.7116789817810059,
      "learning_rate": 2.223356298375436e-05,
      "loss": 3.2711,
      "step": 10450
    },
    {
      "epoch": 2.6792549119673383,
      "grad_norm": 1.6933104991912842,
      "learning_rate": 2.1383005868844095e-05,
      "loss": 3.2926,
      "step": 10500
    },
    {
      "epoch": 2.6920132686909923,
      "grad_norm": 1.710186243057251,
      "learning_rate": 2.0532448753933826e-05,
      "loss": 3.2537,
      "step": 10550
    },
    {
      "epoch": 2.7047716254146463,
      "grad_norm": 1.7682723999023438,
      "learning_rate": 1.968189163902356e-05,
      "loss": 3.3131,
      "step": 10600
    },
    {
      "epoch": 2.7175299821383003,
      "grad_norm": 1.6571098566055298,
      "learning_rate": 1.8831334524113295e-05,
      "loss": 3.3521,
      "step": 10650
    },
    {
      "epoch": 2.7302883388619543,
      "grad_norm": 1.7141178846359253,
      "learning_rate": 1.798077740920303e-05,
      "loss": 3.315,
      "step": 10700
    },
    {
      "epoch": 2.7430466955856083,
      "grad_norm": 1.6615928411483765,
      "learning_rate": 1.7130220294292763e-05,
      "loss": 3.2722,
      "step": 10750
    },
    {
      "epoch": 2.7558050523092623,
      "grad_norm": 1.728774905204773,
      "learning_rate": 1.6279663179382494e-05,
      "loss": 3.2741,
      "step": 10800
    },
    {
      "epoch": 2.7685634090329163,
      "grad_norm": 1.7027873992919922,
      "learning_rate": 1.542910606447223e-05,
      "loss": 3.3248,
      "step": 10850
    },
    {
      "epoch": 2.7813217657565703,
      "grad_norm": 1.5601063966751099,
      "learning_rate": 1.4578548949561963e-05,
      "loss": 3.2596,
      "step": 10900
    },
    {
      "epoch": 2.7940801224802243,
      "grad_norm": 1.7079994678497314,
      "learning_rate": 1.3727991834651696e-05,
      "loss": 3.3357,
      "step": 10950
    },
    {
      "epoch": 2.8068384792038783,
      "grad_norm": 1.7704640626907349,
      "learning_rate": 1.2877434719741432e-05,
      "loss": 3.2783,
      "step": 11000
    },
    {
      "epoch": 2.8068384792038783,
      "eval_loss": 3.6542766094207764,
      "eval_runtime": 102.4772,
      "eval_samples_per_second": 18.443,
      "eval_steps_per_second": 4.616,
      "step": 11000
    }
  ],
  "logging_steps": 50,
  "max_steps": 11757,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 1100,
  "total_flos": 5.994947767644979e+16,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
