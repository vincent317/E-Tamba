{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.9613535858488752,
  "eval_steps": 5000,
  "global_step": 5000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.01,
      "grad_norm": 1.0761053562164307,
      "learning_rate": 0.00019903864641415114,
      "loss": 12.2703,
      "step": 50
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.639334499835968,
      "learning_rate": 0.00019807729282830225,
      "loss": 5.7722,
      "step": 100
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.5162156224250793,
      "learning_rate": 0.00019711593924245338,
      "loss": 5.1244,
      "step": 150
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.3849436044692993,
      "learning_rate": 0.00019615458565660452,
      "loss": 4.9347,
      "step": 200
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.37167486548423767,
      "learning_rate": 0.00019519323207075565,
      "loss": 4.8156,
      "step": 250
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.3494596779346466,
      "learning_rate": 0.00019423187848490676,
      "loss": 4.7258,
      "step": 300
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.3432973623275757,
      "learning_rate": 0.0001932705248990579,
      "loss": 4.6545,
      "step": 350
    },
    {
      "epoch": 0.08,
      "grad_norm": 1.7180005311965942,
      "learning_rate": 0.000192309171313209,
      "loss": 4.6242,
      "step": 400
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.38967305421829224,
      "learning_rate": 0.00019134781772736013,
      "loss": 4.5851,
      "step": 450
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.3197270929813385,
      "learning_rate": 0.00019038646414151127,
      "loss": 4.5365,
      "step": 500
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.37121719121932983,
      "learning_rate": 0.0001894251105556624,
      "loss": 4.5363,
      "step": 550
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.42906275391578674,
      "learning_rate": 0.0001884637569698135,
      "loss": 4.5096,
      "step": 600
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.3132118880748749,
      "learning_rate": 0.00018750240338396464,
      "loss": 4.4701,
      "step": 650
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.3507443368434906,
      "learning_rate": 0.00018654104979811575,
      "loss": 4.4432,
      "step": 700
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.3885868489742279,
      "learning_rate": 0.00018557969621226688,
      "loss": 4.4322,
      "step": 750
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.3975401818752289,
      "learning_rate": 0.000184618342626418,
      "loss": 4.4063,
      "step": 800
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.41002345085144043,
      "learning_rate": 0.00018365698904056915,
      "loss": 4.3862,
      "step": 850
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.36799708008766174,
      "learning_rate": 0.00018269563545472025,
      "loss": 4.3743,
      "step": 900
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.3999990224838257,
      "learning_rate": 0.0001817342818688714,
      "loss": 4.3433,
      "step": 950
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.3548630475997925,
      "learning_rate": 0.0001807729282830225,
      "loss": 4.339,
      "step": 1000
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.4022258222103119,
      "learning_rate": 0.00017981157469717363,
      "loss": 4.3158,
      "step": 1050
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.3360045552253723,
      "learning_rate": 0.00017885022111132474,
      "loss": 4.2895,
      "step": 1100
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.4591478705406189,
      "learning_rate": 0.0001778888675254759,
      "loss": 4.298,
      "step": 1150
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.36591678857803345,
      "learning_rate": 0.000176927513939627,
      "loss": 4.3006,
      "step": 1200
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.3495497405529022,
      "learning_rate": 0.00017596616035377814,
      "loss": 4.2907,
      "step": 1250
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.34594935178756714,
      "learning_rate": 0.00017500480676792924,
      "loss": 4.2518,
      "step": 1300
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.32440927624702454,
      "learning_rate": 0.00017404345318208038,
      "loss": 4.2586,
      "step": 1350
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.3621368408203125,
      "learning_rate": 0.00017308209959623148,
      "loss": 4.2811,
      "step": 1400
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.3388976752758026,
      "learning_rate": 0.00017212074601038262,
      "loss": 4.246,
      "step": 1450
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.3534735441207886,
      "learning_rate": 0.00017115939242453375,
      "loss": 4.2513,
      "step": 1500
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.33655014634132385,
      "learning_rate": 0.00017019803883868489,
      "loss": 4.224,
      "step": 1550
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.32447418570518494,
      "learning_rate": 0.000169236685252836,
      "loss": 4.2365,
      "step": 1600
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.3853776156902313,
      "learning_rate": 0.00016827533166698713,
      "loss": 4.2069,
      "step": 1650
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.3714156150817871,
      "learning_rate": 0.00016731397808113823,
      "loss": 4.2341,
      "step": 1700
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.34729012846946716,
      "learning_rate": 0.00016635262449528937,
      "loss": 4.2142,
      "step": 1750
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.35995766520500183,
      "learning_rate": 0.0001653912709094405,
      "loss": 4.196,
      "step": 1800
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.33667874336242676,
      "learning_rate": 0.00016442991732359163,
      "loss": 4.1983,
      "step": 1850
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.34494590759277344,
      "learning_rate": 0.00016346856373774274,
      "loss": 4.2049,
      "step": 1900
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.6549867987632751,
      "learning_rate": 0.00016250721015189387,
      "loss": 4.1974,
      "step": 1950
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.35763823986053467,
      "learning_rate": 0.000161545856566045,
      "loss": 4.1875,
      "step": 2000
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.3719845712184906,
      "learning_rate": 0.00016058450298019611,
      "loss": 4.2016,
      "step": 2050
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.390328586101532,
      "learning_rate": 0.00015962314939434725,
      "loss": 4.1776,
      "step": 2100
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.34528350830078125,
      "learning_rate": 0.00015866179580849838,
      "loss": 4.1695,
      "step": 2150
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.3470586836338043,
      "learning_rate": 0.00015770044222264952,
      "loss": 4.1674,
      "step": 2200
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.41419652104377747,
      "learning_rate": 0.00015673908863680062,
      "loss": 4.1664,
      "step": 2250
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.4008471369743347,
      "learning_rate": 0.00015577773505095176,
      "loss": 4.1514,
      "step": 2300
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.4852149784564972,
      "learning_rate": 0.00015481638146510286,
      "loss": 4.1238,
      "step": 2350
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.3604600429534912,
      "learning_rate": 0.000153855027879254,
      "loss": 4.1536,
      "step": 2400
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.34047624468803406,
      "learning_rate": 0.00015289367429340513,
      "loss": 4.1451,
      "step": 2450
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.3446938097476959,
      "learning_rate": 0.00015193232070755626,
      "loss": 4.1268,
      "step": 2500
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.35720083117485046,
      "learning_rate": 0.00015097096712170737,
      "loss": 4.1203,
      "step": 2550
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.3874739408493042,
      "learning_rate": 0.0001500096135358585,
      "loss": 4.155,
      "step": 2600
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.3485708236694336,
      "learning_rate": 0.0001490482599500096,
      "loss": 4.1353,
      "step": 2650
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.4150541126728058,
      "learning_rate": 0.00014808690636416074,
      "loss": 4.1346,
      "step": 2700
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.3554892838001251,
      "learning_rate": 0.00014712555277831185,
      "loss": 4.1237,
      "step": 2750
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.35080087184906006,
      "learning_rate": 0.000146164199192463,
      "loss": 4.1351,
      "step": 2800
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.354196697473526,
      "learning_rate": 0.00014520284560661412,
      "loss": 4.1245,
      "step": 2850
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.4444771111011505,
      "learning_rate": 0.00014424149202076525,
      "loss": 4.1121,
      "step": 2900
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.3527624309062958,
      "learning_rate": 0.00014328013843491636,
      "loss": 4.1272,
      "step": 2950
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.3451567590236664,
      "learning_rate": 0.0001423187848490675,
      "loss": 4.103,
      "step": 3000
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.37507736682891846,
      "learning_rate": 0.0001413574312632186,
      "loss": 4.1329,
      "step": 3050
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.34419888257980347,
      "learning_rate": 0.00014039607767736976,
      "loss": 4.0886,
      "step": 3100
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.3465399742126465,
      "learning_rate": 0.00013943472409152087,
      "loss": 4.1282,
      "step": 3150
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.36114686727523804,
      "learning_rate": 0.000138473370505672,
      "loss": 4.0793,
      "step": 3200
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.3817354440689087,
      "learning_rate": 0.0001375120169198231,
      "loss": 4.1171,
      "step": 3250
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.38165584206581116,
      "learning_rate": 0.00013655066333397424,
      "loss": 4.1029,
      "step": 3300
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.4837908446788788,
      "learning_rate": 0.00013558930974812535,
      "loss": 4.1007,
      "step": 3350
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.3582858145236969,
      "learning_rate": 0.00013462795616227648,
      "loss": 4.0926,
      "step": 3400
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.36884820461273193,
      "learning_rate": 0.00013366660257642762,
      "loss": 4.0888,
      "step": 3450
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.35536107420921326,
      "learning_rate": 0.00013270524899057875,
      "loss": 4.0958,
      "step": 3500
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.37632691860198975,
      "learning_rate": 0.00013174389540472986,
      "loss": 4.0673,
      "step": 3550
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.37494945526123047,
      "learning_rate": 0.000130782541818881,
      "loss": 4.073,
      "step": 3600
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.3468009829521179,
      "learning_rate": 0.0001298211882330321,
      "loss": 4.087,
      "step": 3650
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.36169368028640747,
      "learning_rate": 0.00012885983464718323,
      "loss": 4.0633,
      "step": 3700
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.3386775553226471,
      "learning_rate": 0.00012789848106133436,
      "loss": 4.0854,
      "step": 3750
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.4464569389820099,
      "learning_rate": 0.0001269371274754855,
      "loss": 4.0669,
      "step": 3800
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.3487553000450134,
      "learning_rate": 0.0001259757738896366,
      "loss": 4.0607,
      "step": 3850
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.3636760711669922,
      "learning_rate": 0.00012501442030378774,
      "loss": 4.073,
      "step": 3900
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.34341973066329956,
      "learning_rate": 0.00012405306671793887,
      "loss": 4.0717,
      "step": 3950
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.3438337743282318,
      "learning_rate": 0.00012309171313208998,
      "loss": 4.0677,
      "step": 4000
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.3654229938983917,
      "learning_rate": 0.0001221303595462411,
      "loss": 4.0728,
      "step": 4050
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.3589645326137543,
      "learning_rate": 0.00012116900596039225,
      "loss": 4.0541,
      "step": 4100
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.36159446835517883,
      "learning_rate": 0.00012020765237454337,
      "loss": 4.0444,
      "step": 4150
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.4326479434967041,
      "learning_rate": 0.00011924629878869449,
      "loss": 4.078,
      "step": 4200
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.37138986587524414,
      "learning_rate": 0.0001182849452028456,
      "loss": 4.0649,
      "step": 4250
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.37474194169044495,
      "learning_rate": 0.00011732359161699673,
      "loss": 4.0451,
      "step": 4300
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.3771936297416687,
      "learning_rate": 0.00011636223803114785,
      "loss": 4.0472,
      "step": 4350
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.3596436381340027,
      "learning_rate": 0.000115400884445299,
      "loss": 4.0368,
      "step": 4400
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.373518168926239,
      "learning_rate": 0.00011443953085945011,
      "loss": 4.0404,
      "step": 4450
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.34516286849975586,
      "learning_rate": 0.00011347817727360123,
      "loss": 4.0461,
      "step": 4500
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.3621443212032318,
      "learning_rate": 0.00011251682368775235,
      "loss": 4.0492,
      "step": 4550
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.34863021969795227,
      "learning_rate": 0.00011155547010190348,
      "loss": 4.0567,
      "step": 4600
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.36528900265693665,
      "learning_rate": 0.00011059411651605461,
      "loss": 4.0421,
      "step": 4650
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.4197595417499542,
      "learning_rate": 0.00010963276293020574,
      "loss": 4.0189,
      "step": 4700
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.354596346616745,
      "learning_rate": 0.00010867140934435686,
      "loss": 4.0258,
      "step": 4750
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.3808305263519287,
      "learning_rate": 0.00010771005575850798,
      "loss": 4.0354,
      "step": 4800
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.3323865234851837,
      "learning_rate": 0.0001067487021726591,
      "loss": 4.0246,
      "step": 4850
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.356784462928772,
      "learning_rate": 0.00010578734858681024,
      "loss": 4.0141,
      "step": 4900
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.41858378052711487,
      "learning_rate": 0.00010482599500096136,
      "loss": 4.0181,
      "step": 4950
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.3484872579574585,
      "learning_rate": 0.00010386464141511248,
      "loss": 4.0386,
      "step": 5000
    },
    {
      "epoch": 0.96,
      "eval_loss": 4.043379783630371,
      "eval_runtime": 371.6621,
      "eval_samples_per_second": 86.638,
      "eval_steps_per_second": 1.356,
      "step": 5000
    }
  ],
  "logging_steps": 50,
  "max_steps": 10402,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 5000,
  "total_flos": 4.070804815872e+16,
  "train_batch_size": 48,
  "trial_name": null,
  "trial_params": null
}
