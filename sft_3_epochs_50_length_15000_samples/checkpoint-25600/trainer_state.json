{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 2.966396292004635,
  "eval_steps": 800,
  "global_step": 25600,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.005793742757821553,
      "grad_norm": 0.9015988111495972,
      "learning_rate": 4.9903437620702974e-05,
      "loss": 0.0451,
      "step": 50
    },
    {
      "epoch": 0.011587485515643106,
      "grad_norm": 0.8262414336204529,
      "learning_rate": 4.9806875241405946e-05,
      "loss": 0.0369,
      "step": 100
    },
    {
      "epoch": 0.01738122827346466,
      "grad_norm": 0.5884218811988831,
      "learning_rate": 4.9710312862108924e-05,
      "loss": 0.0319,
      "step": 150
    },
    {
      "epoch": 0.023174971031286212,
      "grad_norm": 0.7194057703018188,
      "learning_rate": 4.9613750482811896e-05,
      "loss": 0.0253,
      "step": 200
    },
    {
      "epoch": 0.028968713789107765,
      "grad_norm": 0.718901515007019,
      "learning_rate": 4.9517188103514875e-05,
      "loss": 0.0265,
      "step": 250
    },
    {
      "epoch": 0.03476245654692932,
      "grad_norm": 0.5028207302093506,
      "learning_rate": 4.9420625724217846e-05,
      "loss": 0.0228,
      "step": 300
    },
    {
      "epoch": 0.04055619930475087,
      "grad_norm": 1.3596848249435425,
      "learning_rate": 4.9324063344920825e-05,
      "loss": 0.0216,
      "step": 350
    },
    {
      "epoch": 0.046349942062572425,
      "grad_norm": 0.8826834559440613,
      "learning_rate": 4.92275009656238e-05,
      "loss": 0.0219,
      "step": 400
    },
    {
      "epoch": 0.05214368482039398,
      "grad_norm": 0.9546010494232178,
      "learning_rate": 4.913093858632677e-05,
      "loss": 0.0186,
      "step": 450
    },
    {
      "epoch": 0.05793742757821553,
      "grad_norm": 1.1299761533737183,
      "learning_rate": 4.903437620702974e-05,
      "loss": 0.019,
      "step": 500
    },
    {
      "epoch": 0.06373117033603708,
      "grad_norm": 1.175066351890564,
      "learning_rate": 4.893781382773272e-05,
      "loss": 0.0167,
      "step": 550
    },
    {
      "epoch": 0.06952491309385864,
      "grad_norm": 0.7849754691123962,
      "learning_rate": 4.884125144843569e-05,
      "loss": 0.0145,
      "step": 600
    },
    {
      "epoch": 0.07531865585168018,
      "grad_norm": 0.7362697720527649,
      "learning_rate": 4.874468906913867e-05,
      "loss": 0.0191,
      "step": 650
    },
    {
      "epoch": 0.08111239860950174,
      "grad_norm": 0.8225959539413452,
      "learning_rate": 4.864812668984164e-05,
      "loss": 0.0186,
      "step": 700
    },
    {
      "epoch": 0.08690614136732329,
      "grad_norm": 0.7669305205345154,
      "learning_rate": 4.855156431054461e-05,
      "loss": 0.0165,
      "step": 750
    },
    {
      "epoch": 0.09269988412514485,
      "grad_norm": 0.8869622349739075,
      "learning_rate": 4.845500193124759e-05,
      "loss": 0.0145,
      "step": 800
    },
    {
      "epoch": 0.09269988412514485,
      "eval_loss": 0.014705277048051357,
      "eval_runtime": 30.3599,
      "eval_samples_per_second": 275.001,
      "eval_steps_per_second": 34.387,
      "step": 800
    },
    {
      "epoch": 0.0984936268829664,
      "grad_norm": 0.501187264919281,
      "learning_rate": 4.835843955195056e-05,
      "loss": 0.0138,
      "step": 850
    },
    {
      "epoch": 0.10428736964078796,
      "grad_norm": 0.6415677070617676,
      "learning_rate": 4.8261877172653534e-05,
      "loss": 0.0123,
      "step": 900
    },
    {
      "epoch": 0.1100811123986095,
      "grad_norm": 0.45325443148612976,
      "learning_rate": 4.8165314793356506e-05,
      "loss": 0.0154,
      "step": 950
    },
    {
      "epoch": 0.11587485515643106,
      "grad_norm": 0.9843746423721313,
      "learning_rate": 4.8068752414059485e-05,
      "loss": 0.0143,
      "step": 1000
    },
    {
      "epoch": 0.12166859791425261,
      "grad_norm": 0.3961015045642853,
      "learning_rate": 4.797219003476246e-05,
      "loss": 0.0165,
      "step": 1050
    },
    {
      "epoch": 0.12746234067207415,
      "grad_norm": 0.6081988215446472,
      "learning_rate": 4.7875627655465435e-05,
      "loss": 0.0139,
      "step": 1100
    },
    {
      "epoch": 0.1332560834298957,
      "grad_norm": 0.40655919909477234,
      "learning_rate": 4.7779065276168407e-05,
      "loss": 0.0117,
      "step": 1150
    },
    {
      "epoch": 0.13904982618771727,
      "grad_norm": 0.440121591091156,
      "learning_rate": 4.7682502896871385e-05,
      "loss": 0.0109,
      "step": 1200
    },
    {
      "epoch": 0.14484356894553882,
      "grad_norm": 0.4829511046409607,
      "learning_rate": 4.758594051757436e-05,
      "loss": 0.0148,
      "step": 1250
    },
    {
      "epoch": 0.15063731170336037,
      "grad_norm": 0.5535592436790466,
      "learning_rate": 4.748937813827733e-05,
      "loss": 0.0109,
      "step": 1300
    },
    {
      "epoch": 0.1564310544611819,
      "grad_norm": 0.7100790739059448,
      "learning_rate": 4.73928157589803e-05,
      "loss": 0.0105,
      "step": 1350
    },
    {
      "epoch": 0.16222479721900349,
      "grad_norm": 0.7035263776779175,
      "learning_rate": 4.729625337968327e-05,
      "loss": 0.0123,
      "step": 1400
    },
    {
      "epoch": 0.16801853997682503,
      "grad_norm": 0.40050727128982544,
      "learning_rate": 4.719969100038625e-05,
      "loss": 0.0105,
      "step": 1450
    },
    {
      "epoch": 0.17381228273464658,
      "grad_norm": 0.6117890477180481,
      "learning_rate": 4.710312862108923e-05,
      "loss": 0.0127,
      "step": 1500
    },
    {
      "epoch": 0.17960602549246812,
      "grad_norm": 0.6033618450164795,
      "learning_rate": 4.70065662417922e-05,
      "loss": 0.0102,
      "step": 1550
    },
    {
      "epoch": 0.1853997682502897,
      "grad_norm": 0.42555925250053406,
      "learning_rate": 4.691000386249517e-05,
      "loss": 0.0106,
      "step": 1600
    },
    {
      "epoch": 0.1853997682502897,
      "eval_loss": 0.010340389795601368,
      "eval_runtime": 31.0954,
      "eval_samples_per_second": 268.497,
      "eval_steps_per_second": 33.574,
      "step": 1600
    },
    {
      "epoch": 0.19119351100811124,
      "grad_norm": 0.6431093811988831,
      "learning_rate": 4.681344148319815e-05,
      "loss": 0.0099,
      "step": 1650
    },
    {
      "epoch": 0.1969872537659328,
      "grad_norm": 0.759358823299408,
      "learning_rate": 4.671687910390112e-05,
      "loss": 0.0075,
      "step": 1700
    },
    {
      "epoch": 0.20278099652375434,
      "grad_norm": 0.5433902144432068,
      "learning_rate": 4.6620316724604095e-05,
      "loss": 0.0089,
      "step": 1750
    },
    {
      "epoch": 0.2085747392815759,
      "grad_norm": 0.6349948644638062,
      "learning_rate": 4.6523754345307066e-05,
      "loss": 0.0092,
      "step": 1800
    },
    {
      "epoch": 0.21436848203939746,
      "grad_norm": 0.6115148067474365,
      "learning_rate": 4.6427191966010045e-05,
      "loss": 0.0095,
      "step": 1850
    },
    {
      "epoch": 0.220162224797219,
      "grad_norm": 0.5991566181182861,
      "learning_rate": 4.633062958671302e-05,
      "loss": 0.0092,
      "step": 1900
    },
    {
      "epoch": 0.22595596755504055,
      "grad_norm": 0.6056459546089172,
      "learning_rate": 4.6234067207415995e-05,
      "loss": 0.0086,
      "step": 1950
    },
    {
      "epoch": 0.23174971031286212,
      "grad_norm": 0.7087140083312988,
      "learning_rate": 4.613750482811897e-05,
      "loss": 0.0079,
      "step": 2000
    },
    {
      "epoch": 0.23754345307068367,
      "grad_norm": 1.2786970138549805,
      "learning_rate": 4.604094244882194e-05,
      "loss": 0.0087,
      "step": 2050
    },
    {
      "epoch": 0.24333719582850522,
      "grad_norm": 0.7099520564079285,
      "learning_rate": 4.594438006952492e-05,
      "loss": 0.0091,
      "step": 2100
    },
    {
      "epoch": 0.24913093858632676,
      "grad_norm": 0.36427679657936096,
      "learning_rate": 4.584781769022789e-05,
      "loss": 0.0069,
      "step": 2150
    },
    {
      "epoch": 0.2549246813441483,
      "grad_norm": 0.5436188578605652,
      "learning_rate": 4.575125531093086e-05,
      "loss": 0.0105,
      "step": 2200
    },
    {
      "epoch": 0.2607184241019699,
      "grad_norm": 0.5294811129570007,
      "learning_rate": 4.565469293163384e-05,
      "loss": 0.0071,
      "step": 2250
    },
    {
      "epoch": 0.2665121668597914,
      "grad_norm": 0.4667142629623413,
      "learning_rate": 4.555813055233681e-05,
      "loss": 0.0098,
      "step": 2300
    },
    {
      "epoch": 0.272305909617613,
      "grad_norm": 0.10541722178459167,
      "learning_rate": 4.546156817303979e-05,
      "loss": 0.0072,
      "step": 2350
    },
    {
      "epoch": 0.27809965237543455,
      "grad_norm": 0.8768095374107361,
      "learning_rate": 4.536500579374276e-05,
      "loss": 0.0068,
      "step": 2400
    },
    {
      "epoch": 0.27809965237543455,
      "eval_loss": 0.007022703066468239,
      "eval_runtime": 30.2494,
      "eval_samples_per_second": 276.005,
      "eval_steps_per_second": 34.513,
      "step": 2400
    },
    {
      "epoch": 0.28389339513325607,
      "grad_norm": 0.4989618957042694,
      "learning_rate": 4.526844341444573e-05,
      "loss": 0.0067,
      "step": 2450
    },
    {
      "epoch": 0.28968713789107764,
      "grad_norm": 0.8193396925926208,
      "learning_rate": 4.517188103514871e-05,
      "loss": 0.0075,
      "step": 2500
    },
    {
      "epoch": 0.2954808806488992,
      "grad_norm": 0.6720287203788757,
      "learning_rate": 4.507531865585168e-05,
      "loss": 0.0067,
      "step": 2550
    },
    {
      "epoch": 0.30127462340672073,
      "grad_norm": 0.5689917206764221,
      "learning_rate": 4.4978756276554655e-05,
      "loss": 0.0079,
      "step": 2600
    },
    {
      "epoch": 0.3070683661645423,
      "grad_norm": 0.5828694105148315,
      "learning_rate": 4.4882193897257626e-05,
      "loss": 0.0081,
      "step": 2650
    },
    {
      "epoch": 0.3128621089223638,
      "grad_norm": 0.3012040853500366,
      "learning_rate": 4.4785631517960605e-05,
      "loss": 0.0056,
      "step": 2700
    },
    {
      "epoch": 0.3186558516801854,
      "grad_norm": 0.06717745214700699,
      "learning_rate": 4.4689069138663583e-05,
      "loss": 0.007,
      "step": 2750
    },
    {
      "epoch": 0.32444959443800697,
      "grad_norm": 0.3349093198776245,
      "learning_rate": 4.4592506759366555e-05,
      "loss": 0.0074,
      "step": 2800
    },
    {
      "epoch": 0.3302433371958285,
      "grad_norm": 0.7426846623420715,
      "learning_rate": 4.449594438006953e-05,
      "loss": 0.007,
      "step": 2850
    },
    {
      "epoch": 0.33603707995365006,
      "grad_norm": 0.5471540689468384,
      "learning_rate": 4.43993820007725e-05,
      "loss": 0.005,
      "step": 2900
    },
    {
      "epoch": 0.34183082271147164,
      "grad_norm": 0.8610389828681946,
      "learning_rate": 4.430281962147548e-05,
      "loss": 0.0069,
      "step": 2950
    },
    {
      "epoch": 0.34762456546929316,
      "grad_norm": 0.2734038531780243,
      "learning_rate": 4.420625724217845e-05,
      "loss": 0.0055,
      "step": 3000
    },
    {
      "epoch": 0.35341830822711473,
      "grad_norm": 0.4025421142578125,
      "learning_rate": 4.410969486288142e-05,
      "loss": 0.0059,
      "step": 3050
    },
    {
      "epoch": 0.35921205098493625,
      "grad_norm": 0.2193228155374527,
      "learning_rate": 4.40131324835844e-05,
      "loss": 0.0055,
      "step": 3100
    },
    {
      "epoch": 0.3650057937427578,
      "grad_norm": 0.21991129219532013,
      "learning_rate": 4.391657010428738e-05,
      "loss": 0.0065,
      "step": 3150
    },
    {
      "epoch": 0.3707995365005794,
      "grad_norm": 0.39193442463874817,
      "learning_rate": 4.382000772499035e-05,
      "loss": 0.0051,
      "step": 3200
    },
    {
      "epoch": 0.3707995365005794,
      "eval_loss": 0.005369638558477163,
      "eval_runtime": 30.2846,
      "eval_samples_per_second": 275.684,
      "eval_steps_per_second": 34.473,
      "step": 3200
    },
    {
      "epoch": 0.3765932792584009,
      "grad_norm": 0.4397052526473999,
      "learning_rate": 4.372344534569332e-05,
      "loss": 0.0047,
      "step": 3250
    },
    {
      "epoch": 0.3823870220162225,
      "grad_norm": 0.5035011172294617,
      "learning_rate": 4.362688296639629e-05,
      "loss": 0.0057,
      "step": 3300
    },
    {
      "epoch": 0.388180764774044,
      "grad_norm": 0.04084254428744316,
      "learning_rate": 4.3530320587099265e-05,
      "loss": 0.0058,
      "step": 3350
    },
    {
      "epoch": 0.3939745075318656,
      "grad_norm": 0.14411714673042297,
      "learning_rate": 4.343375820780224e-05,
      "loss": 0.0043,
      "step": 3400
    },
    {
      "epoch": 0.39976825028968715,
      "grad_norm": 0.312691867351532,
      "learning_rate": 4.3337195828505215e-05,
      "loss": 0.0054,
      "step": 3450
    },
    {
      "epoch": 0.4055619930475087,
      "grad_norm": 0.3853745758533478,
      "learning_rate": 4.324063344920819e-05,
      "loss": 0.0084,
      "step": 3500
    },
    {
      "epoch": 0.41135573580533025,
      "grad_norm": 0.026873880997300148,
      "learning_rate": 4.3144071069911165e-05,
      "loss": 0.005,
      "step": 3550
    },
    {
      "epoch": 0.4171494785631518,
      "grad_norm": 0.24004387855529785,
      "learning_rate": 4.3047508690614144e-05,
      "loss": 0.005,
      "step": 3600
    },
    {
      "epoch": 0.42294322132097334,
      "grad_norm": 2.2305290699005127,
      "learning_rate": 4.2950946311317115e-05,
      "loss": 0.0048,
      "step": 3650
    },
    {
      "epoch": 0.4287369640787949,
      "grad_norm": 0.42415350675582886,
      "learning_rate": 4.285438393202009e-05,
      "loss": 0.0044,
      "step": 3700
    },
    {
      "epoch": 0.43453070683661643,
      "grad_norm": 0.4258793294429779,
      "learning_rate": 4.275782155272306e-05,
      "loss": 0.0042,
      "step": 3750
    },
    {
      "epoch": 0.440324449594438,
      "grad_norm": 0.48924168944358826,
      "learning_rate": 4.266125917342603e-05,
      "loss": 0.0036,
      "step": 3800
    },
    {
      "epoch": 0.4461181923522596,
      "grad_norm": 0.31692904233932495,
      "learning_rate": 4.256469679412901e-05,
      "loss": 0.0045,
      "step": 3850
    },
    {
      "epoch": 0.4519119351100811,
      "grad_norm": 0.15519000589847565,
      "learning_rate": 4.246813441483198e-05,
      "loss": 0.0045,
      "step": 3900
    },
    {
      "epoch": 0.45770567786790267,
      "grad_norm": 0.11082504689693451,
      "learning_rate": 4.237157203553496e-05,
      "loss": 0.0038,
      "step": 3950
    },
    {
      "epoch": 0.46349942062572425,
      "grad_norm": 0.325684517621994,
      "learning_rate": 4.227500965623793e-05,
      "loss": 0.0045,
      "step": 4000
    },
    {
      "epoch": 0.46349942062572425,
      "eval_loss": 0.004584184847772121,
      "eval_runtime": 30.7305,
      "eval_samples_per_second": 271.685,
      "eval_steps_per_second": 33.973,
      "step": 4000
    },
    {
      "epoch": 0.46929316338354576,
      "grad_norm": 0.14410516619682312,
      "learning_rate": 4.217844727694091e-05,
      "loss": 0.0041,
      "step": 4050
    },
    {
      "epoch": 0.47508690614136734,
      "grad_norm": 0.05660077556967735,
      "learning_rate": 4.208188489764388e-05,
      "loss": 0.0041,
      "step": 4100
    },
    {
      "epoch": 0.48088064889918886,
      "grad_norm": 0.37509527802467346,
      "learning_rate": 4.198532251834685e-05,
      "loss": 0.0053,
      "step": 4150
    },
    {
      "epoch": 0.48667439165701043,
      "grad_norm": 0.2966362535953522,
      "learning_rate": 4.1888760139049825e-05,
      "loss": 0.0047,
      "step": 4200
    },
    {
      "epoch": 0.492468134414832,
      "grad_norm": 0.4756720960140228,
      "learning_rate": 4.17921977597528e-05,
      "loss": 0.0045,
      "step": 4250
    },
    {
      "epoch": 0.4982618771726535,
      "grad_norm": 0.4304160475730896,
      "learning_rate": 4.1695635380455775e-05,
      "loss": 0.0045,
      "step": 4300
    },
    {
      "epoch": 0.5040556199304751,
      "grad_norm": 0.3820752501487732,
      "learning_rate": 4.1599073001158754e-05,
      "loss": 0.0042,
      "step": 4350
    },
    {
      "epoch": 0.5098493626882966,
      "grad_norm": 0.23547232151031494,
      "learning_rate": 4.1502510621861725e-05,
      "loss": 0.0048,
      "step": 4400
    },
    {
      "epoch": 0.5156431054461182,
      "grad_norm": 0.2992587089538574,
      "learning_rate": 4.14059482425647e-05,
      "loss": 0.0038,
      "step": 4450
    },
    {
      "epoch": 0.5214368482039398,
      "grad_norm": 0.07047656178474426,
      "learning_rate": 4.1309385863267676e-05,
      "loss": 0.0051,
      "step": 4500
    },
    {
      "epoch": 0.5272305909617613,
      "grad_norm": 0.3696020543575287,
      "learning_rate": 4.121282348397065e-05,
      "loss": 0.0034,
      "step": 4550
    },
    {
      "epoch": 0.5330243337195828,
      "grad_norm": 0.48181113600730896,
      "learning_rate": 4.111626110467362e-05,
      "loss": 0.0037,
      "step": 4600
    },
    {
      "epoch": 0.5388180764774044,
      "grad_norm": 0.3764299154281616,
      "learning_rate": 4.101969872537659e-05,
      "loss": 0.0036,
      "step": 4650
    },
    {
      "epoch": 0.544611819235226,
      "grad_norm": 0.020168185234069824,
      "learning_rate": 4.092313634607957e-05,
      "loss": 0.0041,
      "step": 4700
    },
    {
      "epoch": 0.5504055619930475,
      "grad_norm": 0.19567376375198364,
      "learning_rate": 4.082657396678254e-05,
      "loss": 0.0035,
      "step": 4750
    },
    {
      "epoch": 0.5561993047508691,
      "grad_norm": 1.4019365310668945,
      "learning_rate": 4.073001158748552e-05,
      "loss": 0.0037,
      "step": 4800
    },
    {
      "epoch": 0.5561993047508691,
      "eval_loss": 0.0032822140492498875,
      "eval_runtime": 30.3748,
      "eval_samples_per_second": 274.866,
      "eval_steps_per_second": 34.371,
      "step": 4800
    },
    {
      "epoch": 0.5619930475086906,
      "grad_norm": 0.34296461939811707,
      "learning_rate": 4.063344920818849e-05,
      "loss": 0.0059,
      "step": 4850
    },
    {
      "epoch": 0.5677867902665121,
      "grad_norm": 0.10435555875301361,
      "learning_rate": 4.053688682889147e-05,
      "loss": 0.0039,
      "step": 4900
    },
    {
      "epoch": 0.5735805330243338,
      "grad_norm": 0.5425751805305481,
      "learning_rate": 4.044032444959444e-05,
      "loss": 0.0019,
      "step": 4950
    },
    {
      "epoch": 0.5793742757821553,
      "grad_norm": 0.6283212304115295,
      "learning_rate": 4.034376207029741e-05,
      "loss": 0.0048,
      "step": 5000
    },
    {
      "epoch": 0.5851680185399768,
      "grad_norm": 0.08391517400741577,
      "learning_rate": 4.0247199691000385e-05,
      "loss": 0.0038,
      "step": 5050
    },
    {
      "epoch": 0.5909617612977984,
      "grad_norm": 0.18475058674812317,
      "learning_rate": 4.015063731170336e-05,
      "loss": 0.0036,
      "step": 5100
    },
    {
      "epoch": 0.59675550405562,
      "grad_norm": 0.11465679854154587,
      "learning_rate": 4.0054074932406335e-05,
      "loss": 0.0023,
      "step": 5150
    },
    {
      "epoch": 0.6025492468134415,
      "grad_norm": 0.24168607592582703,
      "learning_rate": 3.9957512553109314e-05,
      "loss": 0.0026,
      "step": 5200
    },
    {
      "epoch": 0.608342989571263,
      "grad_norm": 0.6648272275924683,
      "learning_rate": 3.9860950173812286e-05,
      "loss": 0.0022,
      "step": 5250
    },
    {
      "epoch": 0.6141367323290846,
      "grad_norm": 0.4484269618988037,
      "learning_rate": 3.976438779451526e-05,
      "loss": 0.0034,
      "step": 5300
    },
    {
      "epoch": 0.6199304750869061,
      "grad_norm": 0.3479553163051605,
      "learning_rate": 3.9667825415218236e-05,
      "loss": 0.0043,
      "step": 5350
    },
    {
      "epoch": 0.6257242178447276,
      "grad_norm": 0.33821019530296326,
      "learning_rate": 3.957126303592121e-05,
      "loss": 0.0027,
      "step": 5400
    },
    {
      "epoch": 0.6315179606025493,
      "grad_norm": 0.21118463575839996,
      "learning_rate": 3.947470065662418e-05,
      "loss": 0.0038,
      "step": 5450
    },
    {
      "epoch": 0.6373117033603708,
      "grad_norm": 0.43943360447883606,
      "learning_rate": 3.937813827732715e-05,
      "loss": 0.0024,
      "step": 5500
    },
    {
      "epoch": 0.6431054461181923,
      "grad_norm": 0.017820201814174652,
      "learning_rate": 3.928157589803013e-05,
      "loss": 0.0034,
      "step": 5550
    },
    {
      "epoch": 0.6488991888760139,
      "grad_norm": 0.1020517498254776,
      "learning_rate": 3.918501351873311e-05,
      "loss": 0.0036,
      "step": 5600
    },
    {
      "epoch": 0.6488991888760139,
      "eval_loss": 0.002559999469667673,
      "eval_runtime": 30.6865,
      "eval_samples_per_second": 272.074,
      "eval_steps_per_second": 34.021,
      "step": 5600
    },
    {
      "epoch": 0.6546929316338355,
      "grad_norm": 0.3468809127807617,
      "learning_rate": 3.908845113943608e-05,
      "loss": 0.0029,
      "step": 5650
    },
    {
      "epoch": 0.660486674391657,
      "grad_norm": 0.18016532063484192,
      "learning_rate": 3.899188876013905e-05,
      "loss": 0.0021,
      "step": 5700
    },
    {
      "epoch": 0.6662804171494786,
      "grad_norm": 0.18251793086528778,
      "learning_rate": 3.889532638084202e-05,
      "loss": 0.0023,
      "step": 5750
    },
    {
      "epoch": 0.6720741599073001,
      "grad_norm": 0.09648478031158447,
      "learning_rate": 3.8798764001545e-05,
      "loss": 0.0023,
      "step": 5800
    },
    {
      "epoch": 0.6778679026651216,
      "grad_norm": 0.01662004552781582,
      "learning_rate": 3.8702201622247974e-05,
      "loss": 0.0016,
      "step": 5850
    },
    {
      "epoch": 0.6836616454229433,
      "grad_norm": 0.2509492039680481,
      "learning_rate": 3.8605639242950945e-05,
      "loss": 0.0037,
      "step": 5900
    },
    {
      "epoch": 0.6894553881807648,
      "grad_norm": 0.5872455835342407,
      "learning_rate": 3.850907686365392e-05,
      "loss": 0.003,
      "step": 5950
    },
    {
      "epoch": 0.6952491309385863,
      "grad_norm": 0.4868471324443817,
      "learning_rate": 3.8412514484356895e-05,
      "loss": 0.0027,
      "step": 6000
    },
    {
      "epoch": 0.7010428736964078,
      "grad_norm": 0.006623609457165003,
      "learning_rate": 3.8315952105059874e-05,
      "loss": 0.003,
      "step": 6050
    },
    {
      "epoch": 0.7068366164542295,
      "grad_norm": 0.28752458095550537,
      "learning_rate": 3.8219389725762846e-05,
      "loss": 0.0027,
      "step": 6100
    },
    {
      "epoch": 0.712630359212051,
      "grad_norm": 0.1267365962266922,
      "learning_rate": 3.812282734646582e-05,
      "loss": 0.0026,
      "step": 6150
    },
    {
      "epoch": 0.7184241019698725,
      "grad_norm": 0.13195572793483734,
      "learning_rate": 3.8026264967168796e-05,
      "loss": 0.0043,
      "step": 6200
    },
    {
      "epoch": 0.7242178447276941,
      "grad_norm": 0.04465218260884285,
      "learning_rate": 3.792970258787177e-05,
      "loss": 0.003,
      "step": 6250
    },
    {
      "epoch": 0.7300115874855156,
      "grad_norm": 0.4886331856250763,
      "learning_rate": 3.783314020857474e-05,
      "loss": 0.0023,
      "step": 6300
    },
    {
      "epoch": 0.7358053302433372,
      "grad_norm": 0.4542882442474365,
      "learning_rate": 3.773657782927771e-05,
      "loss": 0.0034,
      "step": 6350
    },
    {
      "epoch": 0.7415990730011588,
      "grad_norm": 0.49597832560539246,
      "learning_rate": 3.764001544998069e-05,
      "loss": 0.0025,
      "step": 6400
    },
    {
      "epoch": 0.7415990730011588,
      "eval_loss": 0.002450130647048354,
      "eval_runtime": 30.3474,
      "eval_samples_per_second": 275.114,
      "eval_steps_per_second": 34.402,
      "step": 6400
    },
    {
      "epoch": 0.7473928157589803,
      "grad_norm": 0.04083779826760292,
      "learning_rate": 3.754345307068367e-05,
      "loss": 0.003,
      "step": 6450
    },
    {
      "epoch": 0.7531865585168018,
      "grad_norm": 0.02894924208521843,
      "learning_rate": 3.744689069138664e-05,
      "loss": 0.0031,
      "step": 6500
    },
    {
      "epoch": 0.7589803012746235,
      "grad_norm": 0.01401441264897585,
      "learning_rate": 3.735032831208961e-05,
      "loss": 0.0039,
      "step": 6550
    },
    {
      "epoch": 0.764774044032445,
      "grad_norm": 0.37826597690582275,
      "learning_rate": 3.7253765932792583e-05,
      "loss": 0.003,
      "step": 6600
    },
    {
      "epoch": 0.7705677867902665,
      "grad_norm": 0.02620162069797516,
      "learning_rate": 3.715720355349556e-05,
      "loss": 0.0039,
      "step": 6650
    },
    {
      "epoch": 0.776361529548088,
      "grad_norm": 0.09673400223255157,
      "learning_rate": 3.7060641174198534e-05,
      "loss": 0.0026,
      "step": 6700
    },
    {
      "epoch": 0.7821552723059096,
      "grad_norm": 0.013869996182620525,
      "learning_rate": 3.6964078794901505e-05,
      "loss": 0.0029,
      "step": 6750
    },
    {
      "epoch": 0.7879490150637312,
      "grad_norm": 0.38505369424819946,
      "learning_rate": 3.686751641560448e-05,
      "loss": 0.003,
      "step": 6800
    },
    {
      "epoch": 0.7937427578215527,
      "grad_norm": 0.38833510875701904,
      "learning_rate": 3.6770954036307456e-05,
      "loss": 0.0021,
      "step": 6850
    },
    {
      "epoch": 0.7995365005793743,
      "grad_norm": 0.29443198442459106,
      "learning_rate": 3.6674391657010434e-05,
      "loss": 0.0023,
      "step": 6900
    },
    {
      "epoch": 0.8053302433371958,
      "grad_norm": 0.29389679431915283,
      "learning_rate": 3.6577829277713406e-05,
      "loss": 0.0029,
      "step": 6950
    },
    {
      "epoch": 0.8111239860950173,
      "grad_norm": 0.3981935679912567,
      "learning_rate": 3.648126689841638e-05,
      "loss": 0.0022,
      "step": 7000
    },
    {
      "epoch": 0.816917728852839,
      "grad_norm": 0.0944986566901207,
      "learning_rate": 3.638470451911935e-05,
      "loss": 0.0016,
      "step": 7050
    },
    {
      "epoch": 0.8227114716106605,
      "grad_norm": 0.03990459814667702,
      "learning_rate": 3.628814213982233e-05,
      "loss": 0.0021,
      "step": 7100
    },
    {
      "epoch": 0.828505214368482,
      "grad_norm": 0.17997848987579346,
      "learning_rate": 3.61915797605253e-05,
      "loss": 0.0034,
      "step": 7150
    },
    {
      "epoch": 0.8342989571263036,
      "grad_norm": 0.009982865303754807,
      "learning_rate": 3.609501738122827e-05,
      "loss": 0.003,
      "step": 7200
    },
    {
      "epoch": 0.8342989571263036,
      "eval_loss": 0.002091832458972931,
      "eval_runtime": 31.083,
      "eval_samples_per_second": 268.603,
      "eval_steps_per_second": 33.587,
      "step": 7200
    },
    {
      "epoch": 0.8400926998841252,
      "grad_norm": 0.06212818622589111,
      "learning_rate": 3.599845500193125e-05,
      "loss": 0.0016,
      "step": 7250
    },
    {
      "epoch": 0.8458864426419467,
      "grad_norm": 0.19707468152046204,
      "learning_rate": 3.590189262263423e-05,
      "loss": 0.0031,
      "step": 7300
    },
    {
      "epoch": 0.8516801853997682,
      "grad_norm": 0.045984480530023575,
      "learning_rate": 3.58053302433372e-05,
      "loss": 0.0021,
      "step": 7350
    },
    {
      "epoch": 0.8574739281575898,
      "grad_norm": 0.2486204355955124,
      "learning_rate": 3.570876786404017e-05,
      "loss": 0.0017,
      "step": 7400
    },
    {
      "epoch": 0.8632676709154113,
      "grad_norm": 0.0859985277056694,
      "learning_rate": 3.5612205484743144e-05,
      "loss": 0.0021,
      "step": 7450
    },
    {
      "epoch": 0.8690614136732329,
      "grad_norm": 0.3519059121608734,
      "learning_rate": 3.551564310544612e-05,
      "loss": 0.0023,
      "step": 7500
    },
    {
      "epoch": 0.8748551564310545,
      "grad_norm": 0.026555625721812248,
      "learning_rate": 3.5419080726149094e-05,
      "loss": 0.0021,
      "step": 7550
    },
    {
      "epoch": 0.880648899188876,
      "grad_norm": 0.06450613588094711,
      "learning_rate": 3.5322518346852066e-05,
      "loss": 0.0022,
      "step": 7600
    },
    {
      "epoch": 0.8864426419466975,
      "grad_norm": 0.08076789975166321,
      "learning_rate": 3.5225955967555044e-05,
      "loss": 0.0022,
      "step": 7650
    },
    {
      "epoch": 0.8922363847045192,
      "grad_norm": 0.20462551712989807,
      "learning_rate": 3.5129393588258016e-05,
      "loss": 0.0015,
      "step": 7700
    },
    {
      "epoch": 0.8980301274623407,
      "grad_norm": 0.34991350769996643,
      "learning_rate": 3.5032831208960994e-05,
      "loss": 0.0029,
      "step": 7750
    },
    {
      "epoch": 0.9038238702201622,
      "grad_norm": 0.05825328081846237,
      "learning_rate": 3.4936268829663966e-05,
      "loss": 0.0021,
      "step": 7800
    },
    {
      "epoch": 0.9096176129779838,
      "grad_norm": 0.7029446959495544,
      "learning_rate": 3.483970645036694e-05,
      "loss": 0.0026,
      "step": 7850
    },
    {
      "epoch": 0.9154113557358053,
      "grad_norm": 0.01964762434363365,
      "learning_rate": 3.474314407106991e-05,
      "loss": 0.0021,
      "step": 7900
    },
    {
      "epoch": 0.9212050984936269,
      "grad_norm": 0.42110002040863037,
      "learning_rate": 3.464658169177289e-05,
      "loss": 0.0017,
      "step": 7950
    },
    {
      "epoch": 0.9269988412514485,
      "grad_norm": 0.022556796669960022,
      "learning_rate": 3.455001931247586e-05,
      "loss": 0.0018,
      "step": 8000
    },
    {
      "epoch": 0.9269988412514485,
      "eval_loss": 0.0017229578224942088,
      "eval_runtime": 31.1271,
      "eval_samples_per_second": 268.223,
      "eval_steps_per_second": 33.54,
      "step": 8000
    },
    {
      "epoch": 0.93279258400927,
      "grad_norm": 0.38895460963249207,
      "learning_rate": 3.445345693317883e-05,
      "loss": 0.0017,
      "step": 8050
    },
    {
      "epoch": 0.9385863267670915,
      "grad_norm": 0.042585261166095734,
      "learning_rate": 3.435689455388181e-05,
      "loss": 0.0019,
      "step": 8100
    },
    {
      "epoch": 0.944380069524913,
      "grad_norm": 0.2215544432401657,
      "learning_rate": 3.426033217458479e-05,
      "loss": 0.002,
      "step": 8150
    },
    {
      "epoch": 0.9501738122827347,
      "grad_norm": 0.37921997904777527,
      "learning_rate": 3.416376979528776e-05,
      "loss": 0.0013,
      "step": 8200
    },
    {
      "epoch": 0.9559675550405562,
      "grad_norm": 0.43363893032073975,
      "learning_rate": 3.406720741599073e-05,
      "loss": 0.0016,
      "step": 8250
    },
    {
      "epoch": 0.9617612977983777,
      "grad_norm": 0.44662803411483765,
      "learning_rate": 3.3970645036693704e-05,
      "loss": 0.0034,
      "step": 8300
    },
    {
      "epoch": 0.9675550405561993,
      "grad_norm": 0.09996017813682556,
      "learning_rate": 3.3874082657396676e-05,
      "loss": 0.0029,
      "step": 8350
    },
    {
      "epoch": 0.9733487833140209,
      "grad_norm": 0.21419040858745575,
      "learning_rate": 3.3777520278099654e-05,
      "loss": 0.0016,
      "step": 8400
    },
    {
      "epoch": 0.9791425260718424,
      "grad_norm": 0.030668923631310463,
      "learning_rate": 3.3680957898802626e-05,
      "loss": 0.0012,
      "step": 8450
    },
    {
      "epoch": 0.984936268829664,
      "grad_norm": 0.16841459274291992,
      "learning_rate": 3.3584395519505604e-05,
      "loss": 0.0022,
      "step": 8500
    },
    {
      "epoch": 0.9907300115874855,
      "grad_norm": 0.02914620004594326,
      "learning_rate": 3.3487833140208576e-05,
      "loss": 0.0012,
      "step": 8550
    },
    {
      "epoch": 0.996523754345307,
      "grad_norm": 0.10397280007600784,
      "learning_rate": 3.3391270760911555e-05,
      "loss": 0.0013,
      "step": 8600
    },
    {
      "epoch": 1.0023174971031286,
      "grad_norm": 0.0022870274260640144,
      "learning_rate": 3.3294708381614526e-05,
      "loss": 0.0014,
      "step": 8650
    },
    {
      "epoch": 1.0081112398609502,
      "grad_norm": 0.01722894422709942,
      "learning_rate": 3.31981460023175e-05,
      "loss": 0.0007,
      "step": 8700
    },
    {
      "epoch": 1.0139049826187718,
      "grad_norm": 0.8029111623764038,
      "learning_rate": 3.310158362302047e-05,
      "loss": 0.0004,
      "step": 8750
    },
    {
      "epoch": 1.0196987253765932,
      "grad_norm": 0.025156155228614807,
      "learning_rate": 3.300502124372345e-05,
      "loss": 0.0007,
      "step": 8800
    },
    {
      "epoch": 1.0196987253765932,
      "eval_loss": 0.0016393496189266443,
      "eval_runtime": 30.9988,
      "eval_samples_per_second": 269.333,
      "eval_steps_per_second": 33.679,
      "step": 8800
    },
    {
      "epoch": 1.0254924681344149,
      "grad_norm": 0.026527196168899536,
      "learning_rate": 3.290845886442642e-05,
      "loss": 0.0011,
      "step": 8850
    },
    {
      "epoch": 1.0312862108922365,
      "grad_norm": 0.008809666149318218,
      "learning_rate": 3.28118964851294e-05,
      "loss": 0.0003,
      "step": 8900
    },
    {
      "epoch": 1.037079953650058,
      "grad_norm": 0.0049193548038601875,
      "learning_rate": 3.271533410583237e-05,
      "loss": 0.0002,
      "step": 8950
    },
    {
      "epoch": 1.0428736964078795,
      "grad_norm": 0.0010966419940814376,
      "learning_rate": 3.261877172653534e-05,
      "loss": 0.0001,
      "step": 9000
    },
    {
      "epoch": 1.0486674391657012,
      "grad_norm": 0.40858957171440125,
      "learning_rate": 3.252220934723832e-05,
      "loss": 0.0004,
      "step": 9050
    },
    {
      "epoch": 1.0544611819235226,
      "grad_norm": 0.002533968538045883,
      "learning_rate": 3.242564696794129e-05,
      "loss": 0.0004,
      "step": 9100
    },
    {
      "epoch": 1.0602549246813442,
      "grad_norm": 0.0053468141704797745,
      "learning_rate": 3.2329084588644264e-05,
      "loss": 0.0004,
      "step": 9150
    },
    {
      "epoch": 1.0660486674391656,
      "grad_norm": 0.07306642085313797,
      "learning_rate": 3.2232522209347236e-05,
      "loss": 0.0004,
      "step": 9200
    },
    {
      "epoch": 1.0718424101969872,
      "grad_norm": 0.03605573996901512,
      "learning_rate": 3.2135959830050214e-05,
      "loss": 0.0006,
      "step": 9250
    },
    {
      "epoch": 1.0776361529548089,
      "grad_norm": 0.026397038251161575,
      "learning_rate": 3.2039397450753186e-05,
      "loss": 0.0013,
      "step": 9300
    },
    {
      "epoch": 1.0834298957126303,
      "grad_norm": 0.4145176112651825,
      "learning_rate": 3.1942835071456165e-05,
      "loss": 0.0008,
      "step": 9350
    },
    {
      "epoch": 1.089223638470452,
      "grad_norm": 0.014815337024629116,
      "learning_rate": 3.1846272692159136e-05,
      "loss": 0.0006,
      "step": 9400
    },
    {
      "epoch": 1.0950173812282735,
      "grad_norm": 0.00928493868559599,
      "learning_rate": 3.1749710312862115e-05,
      "loss": 0.0004,
      "step": 9450
    },
    {
      "epoch": 1.100811123986095,
      "grad_norm": 0.03743578493595123,
      "learning_rate": 3.1653147933565087e-05,
      "loss": 0.0002,
      "step": 9500
    },
    {
      "epoch": 1.1066048667439166,
      "grad_norm": 0.07678569853305817,
      "learning_rate": 3.155658555426806e-05,
      "loss": 0.0003,
      "step": 9550
    },
    {
      "epoch": 1.1123986095017382,
      "grad_norm": 0.005834976211190224,
      "learning_rate": 3.146002317497103e-05,
      "loss": 0.001,
      "step": 9600
    },
    {
      "epoch": 1.1123986095017382,
      "eval_loss": 0.0017434164183214307,
      "eval_runtime": 30.0694,
      "eval_samples_per_second": 277.658,
      "eval_steps_per_second": 34.72,
      "step": 9600
    },
    {
      "epoch": 1.1181923522595596,
      "grad_norm": 0.23893316090106964,
      "learning_rate": 3.1363460795674e-05,
      "loss": 0.0006,
      "step": 9650
    },
    {
      "epoch": 1.1239860950173812,
      "grad_norm": 0.007597323507070541,
      "learning_rate": 3.126689841637698e-05,
      "loss": 0.0009,
      "step": 9700
    },
    {
      "epoch": 1.1297798377752029,
      "grad_norm": 0.012808909639716148,
      "learning_rate": 3.117033603707996e-05,
      "loss": 0.0004,
      "step": 9750
    },
    {
      "epoch": 1.1355735805330243,
      "grad_norm": 0.0007842679042369127,
      "learning_rate": 3.107377365778293e-05,
      "loss": 0.0004,
      "step": 9800
    },
    {
      "epoch": 1.141367323290846,
      "grad_norm": 0.02126714400947094,
      "learning_rate": 3.09772112784859e-05,
      "loss": 0.0005,
      "step": 9850
    },
    {
      "epoch": 1.1471610660486675,
      "grad_norm": 0.056082457304000854,
      "learning_rate": 3.088064889918888e-05,
      "loss": 0.0007,
      "step": 9900
    },
    {
      "epoch": 1.152954808806489,
      "grad_norm": 0.0037291394546628,
      "learning_rate": 3.078408651989185e-05,
      "loss": 0.0003,
      "step": 9950
    },
    {
      "epoch": 1.1587485515643106,
      "grad_norm": 0.401956170797348,
      "learning_rate": 3.0687524140594824e-05,
      "loss": 0.0004,
      "step": 10000
    },
    {
      "epoch": 1.1645422943221322,
      "grad_norm": 0.007157019805163145,
      "learning_rate": 3.0590961761297796e-05,
      "loss": 0.0005,
      "step": 10050
    },
    {
      "epoch": 1.1703360370799536,
      "grad_norm": 0.0017656689742580056,
      "learning_rate": 3.0494399382000778e-05,
      "loss": 0.0004,
      "step": 10100
    },
    {
      "epoch": 1.1761297798377752,
      "grad_norm": 0.3991684913635254,
      "learning_rate": 3.039783700270375e-05,
      "loss": 0.0002,
      "step": 10150
    },
    {
      "epoch": 1.1819235225955969,
      "grad_norm": 0.06410790979862213,
      "learning_rate": 3.030127462340672e-05,
      "loss": 0.0002,
      "step": 10200
    },
    {
      "epoch": 1.1877172653534183,
      "grad_norm": 0.005789545364677906,
      "learning_rate": 3.0204712244109696e-05,
      "loss": 0.0007,
      "step": 10250
    },
    {
      "epoch": 1.19351100811124,
      "grad_norm": 0.0023386087268590927,
      "learning_rate": 3.0108149864812668e-05,
      "loss": 0.0005,
      "step": 10300
    },
    {
      "epoch": 1.1993047508690613,
      "grad_norm": 0.0019295525271445513,
      "learning_rate": 3.0011587485515647e-05,
      "loss": 0.0006,
      "step": 10350
    },
    {
      "epoch": 1.205098493626883,
      "grad_norm": 0.007169957738369703,
      "learning_rate": 2.991502510621862e-05,
      "loss": 0.001,
      "step": 10400
    },
    {
      "epoch": 1.205098493626883,
      "eval_loss": 0.0016350292135030031,
      "eval_runtime": 30.2081,
      "eval_samples_per_second": 276.383,
      "eval_steps_per_second": 34.56,
      "step": 10400
    },
    {
      "epoch": 1.2108922363847046,
      "grad_norm": 0.05452016741037369,
      "learning_rate": 2.9818462726921594e-05,
      "loss": 0.0002,
      "step": 10450
    },
    {
      "epoch": 1.2166859791425262,
      "grad_norm": 0.0062760962173342705,
      "learning_rate": 2.9721900347624565e-05,
      "loss": 0.0006,
      "step": 10500
    },
    {
      "epoch": 1.2224797219003476,
      "grad_norm": 0.11779949814081192,
      "learning_rate": 2.9625337968327544e-05,
      "loss": 0.0009,
      "step": 10550
    },
    {
      "epoch": 1.2282734646581692,
      "grad_norm": 0.005324659403413534,
      "learning_rate": 2.9528775589030516e-05,
      "loss": 0.0003,
      "step": 10600
    },
    {
      "epoch": 1.2340672074159906,
      "grad_norm": 0.4975464940071106,
      "learning_rate": 2.943221320973349e-05,
      "loss": 0.0005,
      "step": 10650
    },
    {
      "epoch": 1.2398609501738123,
      "grad_norm": 0.024553434923291206,
      "learning_rate": 2.9335650830436462e-05,
      "loss": 0.0003,
      "step": 10700
    },
    {
      "epoch": 1.2456546929316339,
      "grad_norm": 0.0659535825252533,
      "learning_rate": 2.9239088451139434e-05,
      "loss": 0.0012,
      "step": 10750
    },
    {
      "epoch": 1.2514484356894555,
      "grad_norm": 0.014234902337193489,
      "learning_rate": 2.9142526071842413e-05,
      "loss": 0.0004,
      "step": 10800
    },
    {
      "epoch": 1.257242178447277,
      "grad_norm": 0.004768546670675278,
      "learning_rate": 2.9045963692545384e-05,
      "loss": 0.0003,
      "step": 10850
    },
    {
      "epoch": 1.2630359212050986,
      "grad_norm": 0.004967998247593641,
      "learning_rate": 2.894940131324836e-05,
      "loss": 0.0008,
      "step": 10900
    },
    {
      "epoch": 1.26882966396292,
      "grad_norm": 0.008971461094915867,
      "learning_rate": 2.885283893395133e-05,
      "loss": 0.0003,
      "step": 10950
    },
    {
      "epoch": 1.2746234067207416,
      "grad_norm": 0.0020105079747736454,
      "learning_rate": 2.875627655465431e-05,
      "loss": 0.0008,
      "step": 11000
    },
    {
      "epoch": 1.2804171494785632,
      "grad_norm": 0.0007301581790670753,
      "learning_rate": 2.865971417535728e-05,
      "loss": 0.0003,
      "step": 11050
    },
    {
      "epoch": 1.2862108922363846,
      "grad_norm": 0.009957979433238506,
      "learning_rate": 2.8563151796060257e-05,
      "loss": 0.0006,
      "step": 11100
    },
    {
      "epoch": 1.2920046349942063,
      "grad_norm": 0.0031213280744850636,
      "learning_rate": 2.846658941676323e-05,
      "loss": 0.0003,
      "step": 11150
    },
    {
      "epoch": 1.2977983777520279,
      "grad_norm": 0.07214701920747757,
      "learning_rate": 2.8370027037466207e-05,
      "loss": 0.0004,
      "step": 11200
    },
    {
      "epoch": 1.2977983777520279,
      "eval_loss": 0.0014696128200739622,
      "eval_runtime": 30.0948,
      "eval_samples_per_second": 277.424,
      "eval_steps_per_second": 34.69,
      "step": 11200
    },
    {
      "epoch": 1.3035921205098493,
      "grad_norm": 0.033364374190568924,
      "learning_rate": 2.827346465816918e-05,
      "loss": 0.0005,
      "step": 11250
    },
    {
      "epoch": 1.309385863267671,
      "grad_norm": 0.17112727463245392,
      "learning_rate": 2.8176902278872154e-05,
      "loss": 0.0007,
      "step": 11300
    },
    {
      "epoch": 1.3151796060254926,
      "grad_norm": 0.013092126697301865,
      "learning_rate": 2.8080339899575126e-05,
      "loss": 0.0003,
      "step": 11350
    },
    {
      "epoch": 1.320973348783314,
      "grad_norm": 0.0022877403534948826,
      "learning_rate": 2.7983777520278097e-05,
      "loss": 0.0009,
      "step": 11400
    },
    {
      "epoch": 1.3267670915411356,
      "grad_norm": 0.05622849240899086,
      "learning_rate": 2.7887215140981076e-05,
      "loss": 0.0011,
      "step": 11450
    },
    {
      "epoch": 1.332560834298957,
      "grad_norm": 0.007929747924208641,
      "learning_rate": 2.779065276168405e-05,
      "loss": 0.0008,
      "step": 11500
    },
    {
      "epoch": 1.3383545770567786,
      "grad_norm": 0.012732041999697685,
      "learning_rate": 2.7694090382387023e-05,
      "loss": 0.0002,
      "step": 11550
    },
    {
      "epoch": 1.3441483198146003,
      "grad_norm": 0.0109108816832304,
      "learning_rate": 2.7597528003089994e-05,
      "loss": 0.0009,
      "step": 11600
    },
    {
      "epoch": 1.3499420625724219,
      "grad_norm": 0.003643434029072523,
      "learning_rate": 2.7500965623792973e-05,
      "loss": 0.0004,
      "step": 11650
    },
    {
      "epoch": 1.3557358053302433,
      "grad_norm": 0.0012721378589048982,
      "learning_rate": 2.7404403244495948e-05,
      "loss": 0.0004,
      "step": 11700
    },
    {
      "epoch": 1.361529548088065,
      "grad_norm": 0.016069402918219566,
      "learning_rate": 2.730784086519892e-05,
      "loss": 0.0014,
      "step": 11750
    },
    {
      "epoch": 1.3673232908458863,
      "grad_norm": 0.025186050683259964,
      "learning_rate": 2.721127848590189e-05,
      "loss": 0.0004,
      "step": 11800
    },
    {
      "epoch": 1.373117033603708,
      "grad_norm": 0.024038294330239296,
      "learning_rate": 2.711471610660487e-05,
      "loss": 0.0011,
      "step": 11850
    },
    {
      "epoch": 1.3789107763615296,
      "grad_norm": 0.00432982761412859,
      "learning_rate": 2.7018153727307842e-05,
      "loss": 0.0005,
      "step": 11900
    },
    {
      "epoch": 1.3847045191193512,
      "grad_norm": 0.017341062426567078,
      "learning_rate": 2.6921591348010817e-05,
      "loss": 0.0003,
      "step": 11950
    },
    {
      "epoch": 1.3904982618771726,
      "grad_norm": 0.004744112491607666,
      "learning_rate": 2.682502896871379e-05,
      "loss": 0.0006,
      "step": 12000
    },
    {
      "epoch": 1.3904982618771726,
      "eval_loss": 0.0015379097312688828,
      "eval_runtime": 31.0416,
      "eval_samples_per_second": 268.962,
      "eval_steps_per_second": 33.632,
      "step": 12000
    },
    {
      "epoch": 1.3962920046349943,
      "grad_norm": 0.005301311612129211,
      "learning_rate": 2.672846658941676e-05,
      "loss": 0.0003,
      "step": 12050
    },
    {
      "epoch": 1.4020857473928157,
      "grad_norm": 0.12466482818126678,
      "learning_rate": 2.663190421011974e-05,
      "loss": 0.0004,
      "step": 12100
    },
    {
      "epoch": 1.4078794901506373,
      "grad_norm": 0.04080437868833542,
      "learning_rate": 2.6535341830822714e-05,
      "loss": 0.0006,
      "step": 12150
    },
    {
      "epoch": 1.413673232908459,
      "grad_norm": 0.010675562545657158,
      "learning_rate": 2.6438779451525686e-05,
      "loss": 0.0014,
      "step": 12200
    },
    {
      "epoch": 1.4194669756662806,
      "grad_norm": 0.005093305371701717,
      "learning_rate": 2.6342217072228657e-05,
      "loss": 0.0011,
      "step": 12250
    },
    {
      "epoch": 1.425260718424102,
      "grad_norm": 0.04350816085934639,
      "learning_rate": 2.6245654692931636e-05,
      "loss": 0.0004,
      "step": 12300
    },
    {
      "epoch": 1.4310544611819236,
      "grad_norm": 0.10468816757202148,
      "learning_rate": 2.614909231363461e-05,
      "loss": 0.0004,
      "step": 12350
    },
    {
      "epoch": 1.436848203939745,
      "grad_norm": 0.0029557852540165186,
      "learning_rate": 2.6052529934337583e-05,
      "loss": 0.0003,
      "step": 12400
    },
    {
      "epoch": 1.4426419466975666,
      "grad_norm": 0.0021281770896166563,
      "learning_rate": 2.5955967555040555e-05,
      "loss": 0.0003,
      "step": 12450
    },
    {
      "epoch": 1.4484356894553883,
      "grad_norm": 0.021754609420895576,
      "learning_rate": 2.5859405175743533e-05,
      "loss": 0.0013,
      "step": 12500
    },
    {
      "epoch": 1.4542294322132097,
      "grad_norm": 0.0030576526187360287,
      "learning_rate": 2.5762842796446508e-05,
      "loss": 0.0004,
      "step": 12550
    },
    {
      "epoch": 1.4600231749710313,
      "grad_norm": 0.00224380474537611,
      "learning_rate": 2.566628041714948e-05,
      "loss": 0.0002,
      "step": 12600
    },
    {
      "epoch": 1.465816917728853,
      "grad_norm": 0.02321048080921173,
      "learning_rate": 2.556971803785245e-05,
      "loss": 0.0006,
      "step": 12650
    },
    {
      "epoch": 1.4716106604866743,
      "grad_norm": 0.497958242893219,
      "learning_rate": 2.5473155658555427e-05,
      "loss": 0.0005,
      "step": 12700
    },
    {
      "epoch": 1.477404403244496,
      "grad_norm": 0.1575850546360016,
      "learning_rate": 2.5376593279258405e-05,
      "loss": 0.0003,
      "step": 12750
    },
    {
      "epoch": 1.4831981460023176,
      "grad_norm": 0.002618068130686879,
      "learning_rate": 2.5280030899961377e-05,
      "loss": 0.0004,
      "step": 12800
    },
    {
      "epoch": 1.4831981460023176,
      "eval_loss": 0.001354728708975017,
      "eval_runtime": 30.1751,
      "eval_samples_per_second": 276.685,
      "eval_steps_per_second": 34.598,
      "step": 12800
    },
    {
      "epoch": 1.488991888760139,
      "grad_norm": 0.002513567451387644,
      "learning_rate": 2.518346852066435e-05,
      "loss": 0.0006,
      "step": 12850
    },
    {
      "epoch": 1.4947856315179606,
      "grad_norm": 0.004851147066801786,
      "learning_rate": 2.5086906141367324e-05,
      "loss": 0.0003,
      "step": 12900
    },
    {
      "epoch": 1.500579374275782,
      "grad_norm": 0.31344202160835266,
      "learning_rate": 2.49903437620703e-05,
      "loss": 0.0003,
      "step": 12950
    },
    {
      "epoch": 1.5063731170336037,
      "grad_norm": 0.2232929766178131,
      "learning_rate": 2.4893781382773274e-05,
      "loss": 0.0004,
      "step": 13000
    },
    {
      "epoch": 1.5121668597914253,
      "grad_norm": 0.003831357229501009,
      "learning_rate": 2.4797219003476246e-05,
      "loss": 0.0002,
      "step": 13050
    },
    {
      "epoch": 1.517960602549247,
      "grad_norm": 0.0026098156813532114,
      "learning_rate": 2.470065662417922e-05,
      "loss": 0.0002,
      "step": 13100
    },
    {
      "epoch": 1.5237543453070683,
      "grad_norm": 0.003784582717344165,
      "learning_rate": 2.4604094244882196e-05,
      "loss": 0.0002,
      "step": 13150
    },
    {
      "epoch": 1.52954808806489,
      "grad_norm": 0.001545886741951108,
      "learning_rate": 2.450753186558517e-05,
      "loss": 0.0004,
      "step": 13200
    },
    {
      "epoch": 1.5353418308227114,
      "grad_norm": 0.007164437789469957,
      "learning_rate": 2.4410969486288143e-05,
      "loss": 0.0005,
      "step": 13250
    },
    {
      "epoch": 1.541135573580533,
      "grad_norm": 0.021096745505928993,
      "learning_rate": 2.4314407106991115e-05,
      "loss": 0.0003,
      "step": 13300
    },
    {
      "epoch": 1.5469293163383546,
      "grad_norm": 0.003268806729465723,
      "learning_rate": 2.4217844727694093e-05,
      "loss": 0.0005,
      "step": 13350
    },
    {
      "epoch": 1.5527230590961763,
      "grad_norm": 0.016798729076981544,
      "learning_rate": 2.4121282348397065e-05,
      "loss": 0.0005,
      "step": 13400
    },
    {
      "epoch": 1.5585168018539977,
      "grad_norm": 0.0013366605853661895,
      "learning_rate": 2.402471996910004e-05,
      "loss": 0.0004,
      "step": 13450
    },
    {
      "epoch": 1.5643105446118193,
      "grad_norm": 0.4219683110713959,
      "learning_rate": 2.3928157589803012e-05,
      "loss": 0.0005,
      "step": 13500
    },
    {
      "epoch": 1.5701042873696407,
      "grad_norm": 0.017800012603402138,
      "learning_rate": 2.3831595210505987e-05,
      "loss": 0.0009,
      "step": 13550
    },
    {
      "epoch": 1.5758980301274623,
      "grad_norm": 0.003166822949424386,
      "learning_rate": 2.3735032831208962e-05,
      "loss": 0.0009,
      "step": 13600
    },
    {
      "epoch": 1.5758980301274623,
      "eval_loss": 0.001585853984579444,
      "eval_runtime": 30.2894,
      "eval_samples_per_second": 275.641,
      "eval_steps_per_second": 34.467,
      "step": 13600
    },
    {
      "epoch": 1.581691772885284,
      "grad_norm": 0.02817007340490818,
      "learning_rate": 2.3638470451911937e-05,
      "loss": 0.0009,
      "step": 13650
    },
    {
      "epoch": 1.5874855156431056,
      "grad_norm": 0.002048031659796834,
      "learning_rate": 2.354190807261491e-05,
      "loss": 0.0003,
      "step": 13700
    },
    {
      "epoch": 1.593279258400927,
      "grad_norm": 0.007058173883706331,
      "learning_rate": 2.3445345693317884e-05,
      "loss": 0.001,
      "step": 13750
    },
    {
      "epoch": 1.5990730011587484,
      "grad_norm": 0.008606229908764362,
      "learning_rate": 2.334878331402086e-05,
      "loss": 0.0003,
      "step": 13800
    },
    {
      "epoch": 1.60486674391657,
      "grad_norm": 0.0037388477940112352,
      "learning_rate": 2.3252220934723834e-05,
      "loss": 0.0002,
      "step": 13850
    },
    {
      "epoch": 1.6106604866743917,
      "grad_norm": 0.5254272222518921,
      "learning_rate": 2.3155658555426806e-05,
      "loss": 0.0004,
      "step": 13900
    },
    {
      "epoch": 1.6164542294322133,
      "grad_norm": 0.00030313950264826417,
      "learning_rate": 2.305909617612978e-05,
      "loss": 0.0004,
      "step": 13950
    },
    {
      "epoch": 1.622247972190035,
      "grad_norm": 0.012156506069004536,
      "learning_rate": 2.2962533796832756e-05,
      "loss": 0.0002,
      "step": 14000
    },
    {
      "epoch": 1.6280417149478563,
      "grad_norm": 0.047146622091531754,
      "learning_rate": 2.2865971417535728e-05,
      "loss": 0.0004,
      "step": 14050
    },
    {
      "epoch": 1.6338354577056777,
      "grad_norm": 0.004048921167850494,
      "learning_rate": 2.2769409038238703e-05,
      "loss": 0.0002,
      "step": 14100
    },
    {
      "epoch": 1.6396292004634994,
      "grad_norm": 0.02080499567091465,
      "learning_rate": 2.2672846658941675e-05,
      "loss": 0.0002,
      "step": 14150
    },
    {
      "epoch": 1.645422943221321,
      "grad_norm": 0.22628889977931976,
      "learning_rate": 2.2576284279644653e-05,
      "loss": 0.0007,
      "step": 14200
    },
    {
      "epoch": 1.6512166859791426,
      "grad_norm": 0.1285942792892456,
      "learning_rate": 2.2479721900347625e-05,
      "loss": 0.0002,
      "step": 14250
    },
    {
      "epoch": 1.657010428736964,
      "grad_norm": 0.23547831177711487,
      "learning_rate": 2.23831595210506e-05,
      "loss": 0.0006,
      "step": 14300
    },
    {
      "epoch": 1.6628041714947857,
      "grad_norm": 0.009092790074646473,
      "learning_rate": 2.2286597141753572e-05,
      "loss": 0.0003,
      "step": 14350
    },
    {
      "epoch": 1.668597914252607,
      "grad_norm": 0.025414640083909035,
      "learning_rate": 2.219003476245655e-05,
      "loss": 0.001,
      "step": 14400
    },
    {
      "epoch": 1.668597914252607,
      "eval_loss": 0.001212158240377903,
      "eval_runtime": 30.2786,
      "eval_samples_per_second": 275.74,
      "eval_steps_per_second": 34.48,
      "step": 14400
    },
    {
      "epoch": 1.6743916570104287,
      "grad_norm": 0.03752613440155983,
      "learning_rate": 2.2093472383159522e-05,
      "loss": 0.0003,
      "step": 14450
    },
    {
      "epoch": 1.6801853997682503,
      "grad_norm": 0.030389904975891113,
      "learning_rate": 2.1996910003862497e-05,
      "loss": 0.0001,
      "step": 14500
    },
    {
      "epoch": 1.685979142526072,
      "grad_norm": 0.020639220252633095,
      "learning_rate": 2.190034762456547e-05,
      "loss": 0.0003,
      "step": 14550
    },
    {
      "epoch": 1.6917728852838934,
      "grad_norm": 0.014101389795541763,
      "learning_rate": 2.1803785245268444e-05,
      "loss": 0.0003,
      "step": 14600
    },
    {
      "epoch": 1.697566628041715,
      "grad_norm": 0.4119349718093872,
      "learning_rate": 2.170722286597142e-05,
      "loss": 0.0003,
      "step": 14650
    },
    {
      "epoch": 1.7033603707995364,
      "grad_norm": 0.0012601498747244477,
      "learning_rate": 2.161066048667439e-05,
      "loss": 0.0002,
      "step": 14700
    },
    {
      "epoch": 1.709154113557358,
      "grad_norm": 0.0021622462663799524,
      "learning_rate": 2.1514098107377366e-05,
      "loss": 0.0002,
      "step": 14750
    },
    {
      "epoch": 1.7149478563151797,
      "grad_norm": 0.0004178966919425875,
      "learning_rate": 2.141753572808034e-05,
      "loss": 0.0001,
      "step": 14800
    },
    {
      "epoch": 1.7207415990730013,
      "grad_norm": 0.0022063700016587973,
      "learning_rate": 2.1320973348783317e-05,
      "loss": 0.0003,
      "step": 14850
    },
    {
      "epoch": 1.7265353418308227,
      "grad_norm": 0.015073644928634167,
      "learning_rate": 2.1224410969486288e-05,
      "loss": 0.0001,
      "step": 14900
    },
    {
      "epoch": 1.7323290845886443,
      "grad_norm": 0.0011904002167284489,
      "learning_rate": 2.1127848590189263e-05,
      "loss": 0.0001,
      "step": 14950
    },
    {
      "epoch": 1.7381228273464657,
      "grad_norm": 0.05599469318985939,
      "learning_rate": 2.103128621089224e-05,
      "loss": 0.0005,
      "step": 15000
    },
    {
      "epoch": 1.7439165701042874,
      "grad_norm": 0.003173432545736432,
      "learning_rate": 2.0934723831595214e-05,
      "loss": 0.0002,
      "step": 15050
    },
    {
      "epoch": 1.749710312862109,
      "grad_norm": 0.037495944648981094,
      "learning_rate": 2.0838161452298185e-05,
      "loss": 0.0005,
      "step": 15100
    },
    {
      "epoch": 1.7555040556199306,
      "grad_norm": 0.00024179861065931618,
      "learning_rate": 2.074159907300116e-05,
      "loss": 0.0005,
      "step": 15150
    },
    {
      "epoch": 1.761297798377752,
      "grad_norm": 0.006110018584877253,
      "learning_rate": 2.0645036693704132e-05,
      "loss": 0.0001,
      "step": 15200
    },
    {
      "epoch": 1.761297798377752,
      "eval_loss": 0.0010734222596511245,
      "eval_runtime": 31.1035,
      "eval_samples_per_second": 268.427,
      "eval_steps_per_second": 33.565,
      "step": 15200
    },
    {
      "epoch": 1.7670915411355734,
      "grad_norm": 0.012613372877240181,
      "learning_rate": 2.0548474314407107e-05,
      "loss": 0.0002,
      "step": 15250
    },
    {
      "epoch": 1.772885283893395,
      "grad_norm": 0.0011819545179605484,
      "learning_rate": 2.0451911935110083e-05,
      "loss": 0.0001,
      "step": 15300
    },
    {
      "epoch": 1.7786790266512167,
      "grad_norm": 0.03566954657435417,
      "learning_rate": 2.0355349555813054e-05,
      "loss": 0.0002,
      "step": 15350
    },
    {
      "epoch": 1.7844727694090383,
      "grad_norm": 0.016502682119607925,
      "learning_rate": 2.025878717651603e-05,
      "loss": 0.0012,
      "step": 15400
    },
    {
      "epoch": 1.79026651216686,
      "grad_norm": 0.0013906201347708702,
      "learning_rate": 2.0162224797219005e-05,
      "loss": 0.0004,
      "step": 15450
    },
    {
      "epoch": 1.7960602549246814,
      "grad_norm": 0.001252824324183166,
      "learning_rate": 2.006566241792198e-05,
      "loss": 0.0006,
      "step": 15500
    },
    {
      "epoch": 1.8018539976825028,
      "grad_norm": 0.11602045595645905,
      "learning_rate": 1.996910003862495e-05,
      "loss": 0.0003,
      "step": 15550
    },
    {
      "epoch": 1.8076477404403244,
      "grad_norm": 0.00889920350164175,
      "learning_rate": 1.9872537659327926e-05,
      "loss": 0.0001,
      "step": 15600
    },
    {
      "epoch": 1.813441483198146,
      "grad_norm": 0.0026004156097769737,
      "learning_rate": 1.97759752800309e-05,
      "loss": 0.0001,
      "step": 15650
    },
    {
      "epoch": 1.8192352259559676,
      "grad_norm": 0.0003589011903386563,
      "learning_rate": 1.9679412900733877e-05,
      "loss": 0.0002,
      "step": 15700
    },
    {
      "epoch": 1.825028968713789,
      "grad_norm": 0.008999744430184364,
      "learning_rate": 1.958285052143685e-05,
      "loss": 0.0002,
      "step": 15750
    },
    {
      "epoch": 1.8308227114716107,
      "grad_norm": 0.0004603167762979865,
      "learning_rate": 1.948628814213982e-05,
      "loss": 0.0004,
      "step": 15800
    },
    {
      "epoch": 1.836616454229432,
      "grad_norm": 0.10379412025213242,
      "learning_rate": 1.93897257628428e-05,
      "loss": 0.0003,
      "step": 15850
    },
    {
      "epoch": 1.8424101969872537,
      "grad_norm": 0.0012049056822434068,
      "learning_rate": 1.929316338354577e-05,
      "loss": 0.001,
      "step": 15900
    },
    {
      "epoch": 1.8482039397450754,
      "grad_norm": 0.013958266004920006,
      "learning_rate": 1.9196601004248746e-05,
      "loss": 0.0001,
      "step": 15950
    },
    {
      "epoch": 1.853997682502897,
      "grad_norm": 0.002561309142038226,
      "learning_rate": 1.9100038624951717e-05,
      "loss": 0.0001,
      "step": 16000
    },
    {
      "epoch": 1.853997682502897,
      "eval_loss": 0.0010360899614170194,
      "eval_runtime": 30.3286,
      "eval_samples_per_second": 275.285,
      "eval_steps_per_second": 34.423,
      "step": 16000
    },
    {
      "epoch": 1.8597914252607184,
      "grad_norm": 0.01148378849029541,
      "learning_rate": 1.9003476245654696e-05,
      "loss": 0.0005,
      "step": 16050
    },
    {
      "epoch": 1.86558516801854,
      "grad_norm": 0.06007752567529678,
      "learning_rate": 1.8906913866357668e-05,
      "loss": 0.0002,
      "step": 16100
    },
    {
      "epoch": 1.8713789107763614,
      "grad_norm": 0.011761991307139397,
      "learning_rate": 1.8810351487060643e-05,
      "loss": 0.0002,
      "step": 16150
    },
    {
      "epoch": 1.877172653534183,
      "grad_norm": 0.023922981694340706,
      "learning_rate": 1.8713789107763614e-05,
      "loss": 0.0001,
      "step": 16200
    },
    {
      "epoch": 1.8829663962920047,
      "grad_norm": 0.001970020355656743,
      "learning_rate": 1.8617226728466593e-05,
      "loss": 0.0002,
      "step": 16250
    },
    {
      "epoch": 1.8887601390498263,
      "grad_norm": 0.00563754653558135,
      "learning_rate": 1.8520664349169565e-05,
      "loss": 0.0003,
      "step": 16300
    },
    {
      "epoch": 1.8945538818076477,
      "grad_norm": 0.008015465922653675,
      "learning_rate": 1.842410196987254e-05,
      "loss": 0.0002,
      "step": 16350
    },
    {
      "epoch": 1.9003476245654691,
      "grad_norm": 0.01445912104099989,
      "learning_rate": 1.832753959057551e-05,
      "loss": 0.0003,
      "step": 16400
    },
    {
      "epoch": 1.9061413673232908,
      "grad_norm": 0.40340182185173035,
      "learning_rate": 1.8230977211278487e-05,
      "loss": 0.0002,
      "step": 16450
    },
    {
      "epoch": 1.9119351100811124,
      "grad_norm": 0.0014029622543603182,
      "learning_rate": 1.8134414831981462e-05,
      "loss": 0.0005,
      "step": 16500
    },
    {
      "epoch": 1.917728852838934,
      "grad_norm": 0.0013175872154533863,
      "learning_rate": 1.8037852452684434e-05,
      "loss": 0.0006,
      "step": 16550
    },
    {
      "epoch": 1.9235225955967556,
      "grad_norm": 0.001983952010050416,
      "learning_rate": 1.794129007338741e-05,
      "loss": 0.0002,
      "step": 16600
    },
    {
      "epoch": 1.929316338354577,
      "grad_norm": 0.0010192005429416895,
      "learning_rate": 1.7844727694090384e-05,
      "loss": 0.0002,
      "step": 16650
    },
    {
      "epoch": 1.9351100811123985,
      "grad_norm": 0.007952635176479816,
      "learning_rate": 1.774816531479336e-05,
      "loss": 0.0003,
      "step": 16700
    },
    {
      "epoch": 1.94090382387022,
      "grad_norm": 0.0005736993625760078,
      "learning_rate": 1.765160293549633e-05,
      "loss": 0.0001,
      "step": 16750
    },
    {
      "epoch": 1.9466975666280417,
      "grad_norm": 0.0010588100412860513,
      "learning_rate": 1.7555040556199306e-05,
      "loss": 0.0002,
      "step": 16800
    },
    {
      "epoch": 1.9466975666280417,
      "eval_loss": 0.0010054357117041945,
      "eval_runtime": 31.0606,
      "eval_samples_per_second": 268.797,
      "eval_steps_per_second": 33.612,
      "step": 16800
    },
    {
      "epoch": 1.9524913093858633,
      "grad_norm": 0.1847023218870163,
      "learning_rate": 1.745847817690228e-05,
      "loss": 0.0003,
      "step": 16850
    },
    {
      "epoch": 1.958285052143685,
      "grad_norm": 0.0013636029325425625,
      "learning_rate": 1.7361915797605256e-05,
      "loss": 0.0003,
      "step": 16900
    },
    {
      "epoch": 1.9640787949015064,
      "grad_norm": 0.0014041545800864697,
      "learning_rate": 1.7265353418308228e-05,
      "loss": 0.0004,
      "step": 16950
    },
    {
      "epoch": 1.9698725376593278,
      "grad_norm": 0.00099871342536062,
      "learning_rate": 1.7168791039011203e-05,
      "loss": 0.0003,
      "step": 17000
    },
    {
      "epoch": 1.9756662804171494,
      "grad_norm": 0.018809786066412926,
      "learning_rate": 1.7072228659714175e-05,
      "loss": 0.0001,
      "step": 17050
    },
    {
      "epoch": 1.981460023174971,
      "grad_norm": 0.00448035029694438,
      "learning_rate": 1.697566628041715e-05,
      "loss": 0.0001,
      "step": 17100
    },
    {
      "epoch": 1.9872537659327927,
      "grad_norm": 0.023545511066913605,
      "learning_rate": 1.6879103901120125e-05,
      "loss": 0.0002,
      "step": 17150
    },
    {
      "epoch": 1.993047508690614,
      "grad_norm": 0.21534143388271332,
      "learning_rate": 1.6782541521823097e-05,
      "loss": 0.0002,
      "step": 17200
    },
    {
      "epoch": 1.9988412514484357,
      "grad_norm": 0.0005781101062893867,
      "learning_rate": 1.6685979142526072e-05,
      "loss": 0.0002,
      "step": 17250
    },
    {
      "epoch": 2.004634994206257,
      "grad_norm": 0.006527238991111517,
      "learning_rate": 1.6589416763229047e-05,
      "loss": 0.0006,
      "step": 17300
    },
    {
      "epoch": 2.0104287369640788,
      "grad_norm": 0.0013321635778993368,
      "learning_rate": 1.6492854383932022e-05,
      "loss": 0.0,
      "step": 17350
    },
    {
      "epoch": 2.0162224797219004,
      "grad_norm": 0.002014883328229189,
      "learning_rate": 1.6396292004634994e-05,
      "loss": 0.0002,
      "step": 17400
    },
    {
      "epoch": 2.022016222479722,
      "grad_norm": 0.005126982927322388,
      "learning_rate": 1.629972962533797e-05,
      "loss": 0.0002,
      "step": 17450
    },
    {
      "epoch": 2.0278099652375436,
      "grad_norm": 0.00036494340747594833,
      "learning_rate": 1.6203167246040944e-05,
      "loss": 0.0001,
      "step": 17500
    },
    {
      "epoch": 2.033603707995365,
      "grad_norm": 0.0011812652228400111,
      "learning_rate": 1.610660486674392e-05,
      "loss": 0.0009,
      "step": 17550
    },
    {
      "epoch": 2.0393974507531865,
      "grad_norm": 0.0004921978688798845,
      "learning_rate": 1.601004248744689e-05,
      "loss": 0.0012,
      "step": 17600
    },
    {
      "epoch": 2.0393974507531865,
      "eval_loss": 0.0010243866126984358,
      "eval_runtime": 31.1089,
      "eval_samples_per_second": 268.38,
      "eval_steps_per_second": 33.56,
      "step": 17600
    },
    {
      "epoch": 2.045191193511008,
      "grad_norm": 0.0006454274989664555,
      "learning_rate": 1.5913480108149866e-05,
      "loss": 0.0005,
      "step": 17650
    },
    {
      "epoch": 2.0509849362688297,
      "grad_norm": 0.000686915242113173,
      "learning_rate": 1.581691772885284e-05,
      "loss": 0.0001,
      "step": 17700
    },
    {
      "epoch": 2.0567786790266513,
      "grad_norm": 0.008786377497017384,
      "learning_rate": 1.5720355349555813e-05,
      "loss": 0.0,
      "step": 17750
    },
    {
      "epoch": 2.062572421784473,
      "grad_norm": 0.009019596502184868,
      "learning_rate": 1.5623792970258788e-05,
      "loss": 0.0002,
      "step": 17800
    },
    {
      "epoch": 2.068366164542294,
      "grad_norm": 0.007599182892590761,
      "learning_rate": 1.552723059096176e-05,
      "loss": 0.0004,
      "step": 17850
    },
    {
      "epoch": 2.074159907300116,
      "grad_norm": 0.0015160093316808343,
      "learning_rate": 1.5430668211664738e-05,
      "loss": 0.0002,
      "step": 17900
    },
    {
      "epoch": 2.0799536500579374,
      "grad_norm": 0.0026684170588850975,
      "learning_rate": 1.533410583236771e-05,
      "loss": 0.0002,
      "step": 17950
    },
    {
      "epoch": 2.085747392815759,
      "grad_norm": 0.0011683959746733308,
      "learning_rate": 1.5237543453070685e-05,
      "loss": 0.0002,
      "step": 18000
    },
    {
      "epoch": 2.0915411355735807,
      "grad_norm": 0.007348444778472185,
      "learning_rate": 1.5140981073773659e-05,
      "loss": 0.0005,
      "step": 18050
    },
    {
      "epoch": 2.0973348783314023,
      "grad_norm": 0.001787472516298294,
      "learning_rate": 1.5044418694476634e-05,
      "loss": 0.0005,
      "step": 18100
    },
    {
      "epoch": 2.1031286210892235,
      "grad_norm": 0.002660040743649006,
      "learning_rate": 1.4947856315179607e-05,
      "loss": 0.0002,
      "step": 18150
    },
    {
      "epoch": 2.108922363847045,
      "grad_norm": 0.39435362815856934,
      "learning_rate": 1.4851293935882582e-05,
      "loss": 0.0002,
      "step": 18200
    },
    {
      "epoch": 2.1147161066048668,
      "grad_norm": 0.0023120564874261618,
      "learning_rate": 1.4754731556585556e-05,
      "loss": 0.0001,
      "step": 18250
    },
    {
      "epoch": 2.1205098493626884,
      "grad_norm": 0.00013968563871458173,
      "learning_rate": 1.465816917728853e-05,
      "loss": 0.0001,
      "step": 18300
    },
    {
      "epoch": 2.12630359212051,
      "grad_norm": 0.0011202110908925533,
      "learning_rate": 1.4561606797991503e-05,
      "loss": 0.0,
      "step": 18350
    },
    {
      "epoch": 2.132097334878331,
      "grad_norm": 0.004068365786224604,
      "learning_rate": 1.4465044418694476e-05,
      "loss": 0.0001,
      "step": 18400
    },
    {
      "epoch": 2.132097334878331,
      "eval_loss": 0.0007755039841867983,
      "eval_runtime": 31.2518,
      "eval_samples_per_second": 267.153,
      "eval_steps_per_second": 33.406,
      "step": 18400
    },
    {
      "epoch": 2.137891077636153,
      "grad_norm": 0.005082250572741032,
      "learning_rate": 1.4368482039397451e-05,
      "loss": 0.0006,
      "step": 18450
    },
    {
      "epoch": 2.1436848203939745,
      "grad_norm": 0.016715029254555702,
      "learning_rate": 1.4271919660100424e-05,
      "loss": 0.0006,
      "step": 18500
    },
    {
      "epoch": 2.149478563151796,
      "grad_norm": 0.0007998873479664326,
      "learning_rate": 1.41753572808034e-05,
      "loss": 0.0004,
      "step": 18550
    },
    {
      "epoch": 2.1552723059096177,
      "grad_norm": 0.03267785161733627,
      "learning_rate": 1.4078794901506373e-05,
      "loss": 0.0005,
      "step": 18600
    },
    {
      "epoch": 2.1610660486674393,
      "grad_norm": 0.1534203737974167,
      "learning_rate": 1.3982232522209348e-05,
      "loss": 0.0001,
      "step": 18650
    },
    {
      "epoch": 2.1668597914252605,
      "grad_norm": 0.00559222511947155,
      "learning_rate": 1.3885670142912322e-05,
      "loss": 0.0002,
      "step": 18700
    },
    {
      "epoch": 2.172653534183082,
      "grad_norm": 0.004951936658471823,
      "learning_rate": 1.3789107763615297e-05,
      "loss": 0.0001,
      "step": 18750
    },
    {
      "epoch": 2.178447276940904,
      "grad_norm": 0.0014604373136535287,
      "learning_rate": 1.369254538431827e-05,
      "loss": 0.0001,
      "step": 18800
    },
    {
      "epoch": 2.1842410196987254,
      "grad_norm": 0.0016737534897401929,
      "learning_rate": 1.3595983005021245e-05,
      "loss": 0.0002,
      "step": 18850
    },
    {
      "epoch": 2.190034762456547,
      "grad_norm": 0.003469744697213173,
      "learning_rate": 1.3499420625724219e-05,
      "loss": 0.0002,
      "step": 18900
    },
    {
      "epoch": 2.1958285052143687,
      "grad_norm": 0.001602219301275909,
      "learning_rate": 1.340285824642719e-05,
      "loss": 0.0001,
      "step": 18950
    },
    {
      "epoch": 2.20162224797219,
      "grad_norm": 0.0018249324057251215,
      "learning_rate": 1.3306295867130167e-05,
      "loss": 0.0004,
      "step": 19000
    },
    {
      "epoch": 2.2074159907300115,
      "grad_norm": 0.031146984547376633,
      "learning_rate": 1.3209733487833139e-05,
      "loss": 0.0,
      "step": 19050
    },
    {
      "epoch": 2.213209733487833,
      "grad_norm": 0.0010944327805191278,
      "learning_rate": 1.3113171108536116e-05,
      "loss": 0.0001,
      "step": 19100
    },
    {
      "epoch": 2.2190034762456547,
      "grad_norm": 0.00272062374278903,
      "learning_rate": 1.3016608729239088e-05,
      "loss": 0.0004,
      "step": 19150
    },
    {
      "epoch": 2.2247972190034764,
      "grad_norm": 0.0004957120981998742,
      "learning_rate": 1.2920046349942064e-05,
      "loss": 0.0006,
      "step": 19200
    },
    {
      "epoch": 2.2247972190034764,
      "eval_loss": 0.001013388391584158,
      "eval_runtime": 30.3765,
      "eval_samples_per_second": 274.85,
      "eval_steps_per_second": 34.369,
      "step": 19200
    },
    {
      "epoch": 2.2305909617612976,
      "grad_norm": 0.8967400193214417,
      "learning_rate": 1.2823483970645036e-05,
      "loss": 0.0002,
      "step": 19250
    },
    {
      "epoch": 2.236384704519119,
      "grad_norm": 0.0071436744183301926,
      "learning_rate": 1.2726921591348013e-05,
      "loss": 0.0001,
      "step": 19300
    },
    {
      "epoch": 2.242178447276941,
      "grad_norm": 0.0004687173350248486,
      "learning_rate": 1.2630359212050985e-05,
      "loss": 0.0006,
      "step": 19350
    },
    {
      "epoch": 2.2479721900347625,
      "grad_norm": 0.009739736095070839,
      "learning_rate": 1.2533796832753962e-05,
      "loss": 0.0,
      "step": 19400
    },
    {
      "epoch": 2.253765932792584,
      "grad_norm": 0.003092058701440692,
      "learning_rate": 1.2437234453456933e-05,
      "loss": 0.0002,
      "step": 19450
    },
    {
      "epoch": 2.2595596755504057,
      "grad_norm": 0.0019254779908806086,
      "learning_rate": 1.2340672074159908e-05,
      "loss": 0.0001,
      "step": 19500
    },
    {
      "epoch": 2.2653534183082273,
      "grad_norm": 0.005676895380020142,
      "learning_rate": 1.2244109694862882e-05,
      "loss": 0.0005,
      "step": 19550
    },
    {
      "epoch": 2.2711471610660485,
      "grad_norm": 0.001589137245900929,
      "learning_rate": 1.2147547315565857e-05,
      "loss": 0.0004,
      "step": 19600
    },
    {
      "epoch": 2.27694090382387,
      "grad_norm": 0.001444030087441206,
      "learning_rate": 1.205098493626883e-05,
      "loss": 0.0,
      "step": 19650
    },
    {
      "epoch": 2.282734646581692,
      "grad_norm": 0.0016205149004235864,
      "learning_rate": 1.1954422556971804e-05,
      "loss": 0.0004,
      "step": 19700
    },
    {
      "epoch": 2.2885283893395134,
      "grad_norm": 0.06631281971931458,
      "learning_rate": 1.1857860177674779e-05,
      "loss": 0.0001,
      "step": 19750
    },
    {
      "epoch": 2.294322132097335,
      "grad_norm": 0.005763673689216375,
      "learning_rate": 1.1761297798377752e-05,
      "loss": 0.0003,
      "step": 19800
    },
    {
      "epoch": 2.3001158748551562,
      "grad_norm": 0.0009011710644699633,
      "learning_rate": 1.1664735419080727e-05,
      "loss": 0.0001,
      "step": 19850
    },
    {
      "epoch": 2.305909617612978,
      "grad_norm": 0.0004319766303524375,
      "learning_rate": 1.1568173039783701e-05,
      "loss": 0.0001,
      "step": 19900
    },
    {
      "epoch": 2.3117033603707995,
      "grad_norm": 0.002062014304101467,
      "learning_rate": 1.1471610660486674e-05,
      "loss": 0.0004,
      "step": 19950
    },
    {
      "epoch": 2.317497103128621,
      "grad_norm": 0.0021855721715837717,
      "learning_rate": 1.1375048281189648e-05,
      "loss": 0.0001,
      "step": 20000
    },
    {
      "epoch": 2.317497103128621,
      "eval_loss": 0.000757621368393302,
      "eval_runtime": 30.2047,
      "eval_samples_per_second": 276.414,
      "eval_steps_per_second": 34.564,
      "step": 20000
    },
    {
      "epoch": 2.3232908458864427,
      "grad_norm": 0.007041699718683958,
      "learning_rate": 1.1278485901892623e-05,
      "loss": 0.0001,
      "step": 20050
    },
    {
      "epoch": 2.3290845886442644,
      "grad_norm": 0.17505298554897308,
      "learning_rate": 1.1181923522595596e-05,
      "loss": 0.0,
      "step": 20100
    },
    {
      "epoch": 2.3348783314020856,
      "grad_norm": 0.0011805434478446841,
      "learning_rate": 1.1085361143298571e-05,
      "loss": 0.0001,
      "step": 20150
    },
    {
      "epoch": 2.340672074159907,
      "grad_norm": 0.00037740275729447603,
      "learning_rate": 1.0988798764001545e-05,
      "loss": 0.0001,
      "step": 20200
    },
    {
      "epoch": 2.346465816917729,
      "grad_norm": 0.002629161812365055,
      "learning_rate": 1.089223638470452e-05,
      "loss": 0.0001,
      "step": 20250
    },
    {
      "epoch": 2.3522595596755504,
      "grad_norm": 0.0005917682428844273,
      "learning_rate": 1.0795674005407493e-05,
      "loss": 0.0002,
      "step": 20300
    },
    {
      "epoch": 2.358053302433372,
      "grad_norm": 0.010435560718178749,
      "learning_rate": 1.0699111626110469e-05,
      "loss": 0.0,
      "step": 20350
    },
    {
      "epoch": 2.3638470451911937,
      "grad_norm": 0.0004240974085405469,
      "learning_rate": 1.0602549246813442e-05,
      "loss": 0.0,
      "step": 20400
    },
    {
      "epoch": 2.369640787949015,
      "grad_norm": 0.0007243255968205631,
      "learning_rate": 1.0505986867516417e-05,
      "loss": 0.0,
      "step": 20450
    },
    {
      "epoch": 2.3754345307068365,
      "grad_norm": 0.005339143797755241,
      "learning_rate": 1.040942448821939e-05,
      "loss": 0.0,
      "step": 20500
    },
    {
      "epoch": 2.381228273464658,
      "grad_norm": 0.4109269976615906,
      "learning_rate": 1.0312862108922364e-05,
      "loss": 0.0004,
      "step": 20550
    },
    {
      "epoch": 2.38702201622248,
      "grad_norm": 0.0003739968524314463,
      "learning_rate": 1.0216299729625337e-05,
      "loss": 0.0,
      "step": 20600
    },
    {
      "epoch": 2.3928157589803014,
      "grad_norm": 0.010890615172684193,
      "learning_rate": 1.0119737350328313e-05,
      "loss": 0.0002,
      "step": 20650
    },
    {
      "epoch": 2.3986095017381226,
      "grad_norm": 0.0007587980362586677,
      "learning_rate": 1.0023174971031286e-05,
      "loss": 0.0004,
      "step": 20700
    },
    {
      "epoch": 2.4044032444959442,
      "grad_norm": 0.0012664471287280321,
      "learning_rate": 9.926612591734261e-06,
      "loss": 0.0006,
      "step": 20750
    },
    {
      "epoch": 2.410196987253766,
      "grad_norm": 0.002996457740664482,
      "learning_rate": 9.830050212437235e-06,
      "loss": 0.0,
      "step": 20800
    },
    {
      "epoch": 2.410196987253766,
      "eval_loss": 0.0007645852165296674,
      "eval_runtime": 30.2385,
      "eval_samples_per_second": 276.105,
      "eval_steps_per_second": 34.525,
      "step": 20800
    },
    {
      "epoch": 2.4159907300115875,
      "grad_norm": 0.0002748631814029068,
      "learning_rate": 9.73348783314021e-06,
      "loss": 0.0001,
      "step": 20850
    },
    {
      "epoch": 2.421784472769409,
      "grad_norm": 0.003147851675748825,
      "learning_rate": 9.636925453843183e-06,
      "loss": 0.0001,
      "step": 20900
    },
    {
      "epoch": 2.4275782155272307,
      "grad_norm": 0.0015418860130012035,
      "learning_rate": 9.540363074546158e-06,
      "loss": 0.0,
      "step": 20950
    },
    {
      "epoch": 2.4333719582850524,
      "grad_norm": 0.00032687847851775587,
      "learning_rate": 9.443800695249132e-06,
      "loss": 0.0004,
      "step": 21000
    },
    {
      "epoch": 2.4391657010428736,
      "grad_norm": 0.000273428246146068,
      "learning_rate": 9.347238315952107e-06,
      "loss": 0.0001,
      "step": 21050
    },
    {
      "epoch": 2.444959443800695,
      "grad_norm": 0.01999325305223465,
      "learning_rate": 9.25067593665508e-06,
      "loss": 0.0003,
      "step": 21100
    },
    {
      "epoch": 2.450753186558517,
      "grad_norm": 0.011509126983582973,
      "learning_rate": 9.154113557358054e-06,
      "loss": 0.0,
      "step": 21150
    },
    {
      "epoch": 2.4565469293163384,
      "grad_norm": 0.000538008229341358,
      "learning_rate": 9.057551178061027e-06,
      "loss": 0.0,
      "step": 21200
    },
    {
      "epoch": 2.46234067207416,
      "grad_norm": 0.004172104876488447,
      "learning_rate": 8.960988798764002e-06,
      "loss": 0.0001,
      "step": 21250
    },
    {
      "epoch": 2.4681344148319813,
      "grad_norm": 0.0006721137324348092,
      "learning_rate": 8.864426419466976e-06,
      "loss": 0.0004,
      "step": 21300
    },
    {
      "epoch": 2.473928157589803,
      "grad_norm": 0.00047197320964187384,
      "learning_rate": 8.76786404016995e-06,
      "loss": 0.0002,
      "step": 21350
    },
    {
      "epoch": 2.4797219003476245,
      "grad_norm": 0.029244523495435715,
      "learning_rate": 8.671301660872924e-06,
      "loss": 0.0,
      "step": 21400
    },
    {
      "epoch": 2.485515643105446,
      "grad_norm": 0.009913750924170017,
      "learning_rate": 8.574739281575898e-06,
      "loss": 0.0001,
      "step": 21450
    },
    {
      "epoch": 2.4913093858632678,
      "grad_norm": 0.001958267530426383,
      "learning_rate": 8.478176902278873e-06,
      "loss": 0.0001,
      "step": 21500
    },
    {
      "epoch": 2.4971031286210894,
      "grad_norm": 0.0031183387618511915,
      "learning_rate": 8.381614522981846e-06,
      "loss": 0.0001,
      "step": 21550
    },
    {
      "epoch": 2.502896871378911,
      "grad_norm": 0.004082036670297384,
      "learning_rate": 8.285052143684821e-06,
      "loss": 0.0003,
      "step": 21600
    },
    {
      "epoch": 2.502896871378911,
      "eval_loss": 0.00079589948290959,
      "eval_runtime": 30.3713,
      "eval_samples_per_second": 274.897,
      "eval_steps_per_second": 34.375,
      "step": 21600
    },
    {
      "epoch": 2.5086906141367322,
      "grad_norm": 0.07986725121736526,
      "learning_rate": 8.188489764387795e-06,
      "loss": 0.0,
      "step": 21650
    },
    {
      "epoch": 2.514484356894554,
      "grad_norm": 0.03978518396615982,
      "learning_rate": 8.09192738509077e-06,
      "loss": 0.0001,
      "step": 21700
    },
    {
      "epoch": 2.5202780996523755,
      "grad_norm": 0.0007091883453540504,
      "learning_rate": 7.995365005793743e-06,
      "loss": 0.0,
      "step": 21750
    },
    {
      "epoch": 2.526071842410197,
      "grad_norm": 0.002572678728029132,
      "learning_rate": 7.898802626496717e-06,
      "loss": 0.0001,
      "step": 21800
    },
    {
      "epoch": 2.5318655851680187,
      "grad_norm": 0.0015695467591285706,
      "learning_rate": 7.80224024719969e-06,
      "loss": 0.0002,
      "step": 21850
    },
    {
      "epoch": 2.53765932792584,
      "grad_norm": 0.0004363188927527517,
      "learning_rate": 7.705677867902665e-06,
      "loss": 0.0003,
      "step": 21900
    },
    {
      "epoch": 2.5434530706836616,
      "grad_norm": 0.00026516144862398505,
      "learning_rate": 7.6091154886056396e-06,
      "loss": 0.0003,
      "step": 21950
    },
    {
      "epoch": 2.549246813441483,
      "grad_norm": 0.037572819739580154,
      "learning_rate": 7.512553109308614e-06,
      "loss": 0.0001,
      "step": 22000
    },
    {
      "epoch": 2.555040556199305,
      "grad_norm": 0.014267335645854473,
      "learning_rate": 7.415990730011588e-06,
      "loss": 0.0,
      "step": 22050
    },
    {
      "epoch": 2.5608342989571264,
      "grad_norm": 0.003424580441787839,
      "learning_rate": 7.3194283507145615e-06,
      "loss": 0.0,
      "step": 22100
    },
    {
      "epoch": 2.5666280417149476,
      "grad_norm": 0.000653447990771383,
      "learning_rate": 7.222865971417536e-06,
      "loss": 0.0,
      "step": 22150
    },
    {
      "epoch": 2.5724217844727693,
      "grad_norm": 0.0016002978663891554,
      "learning_rate": 7.12630359212051e-06,
      "loss": 0.0001,
      "step": 22200
    },
    {
      "epoch": 2.578215527230591,
      "grad_norm": 0.0007281755097210407,
      "learning_rate": 7.029741212823484e-06,
      "loss": 0.0001,
      "step": 22250
    },
    {
      "epoch": 2.5840092699884125,
      "grad_norm": 0.0008416727068834007,
      "learning_rate": 6.933178833526459e-06,
      "loss": 0.0001,
      "step": 22300
    },
    {
      "epoch": 2.589803012746234,
      "grad_norm": 0.027289528399705887,
      "learning_rate": 6.836616454229433e-06,
      "loss": 0.0005,
      "step": 22350
    },
    {
      "epoch": 2.5955967555040558,
      "grad_norm": 0.00045587035128846765,
      "learning_rate": 6.740054074932407e-06,
      "loss": 0.0002,
      "step": 22400
    },
    {
      "epoch": 2.5955967555040558,
      "eval_loss": 0.0007534531760029495,
      "eval_runtime": 31.2328,
      "eval_samples_per_second": 267.315,
      "eval_steps_per_second": 33.426,
      "step": 22400
    },
    {
      "epoch": 2.6013904982618774,
      "grad_norm": 0.30186671018600464,
      "learning_rate": 6.64349169563538e-06,
      "loss": 0.0001,
      "step": 22450
    },
    {
      "epoch": 2.6071842410196986,
      "grad_norm": 0.0015994986752048135,
      "learning_rate": 6.546929316338354e-06,
      "loss": 0.0005,
      "step": 22500
    },
    {
      "epoch": 2.61297798377752,
      "grad_norm": 0.014260406605899334,
      "learning_rate": 6.450366937041328e-06,
      "loss": 0.0001,
      "step": 22550
    },
    {
      "epoch": 2.618771726535342,
      "grad_norm": 0.00019810676167253405,
      "learning_rate": 6.353804557744303e-06,
      "loss": 0.0,
      "step": 22600
    },
    {
      "epoch": 2.6245654692931635,
      "grad_norm": 0.0002905895235016942,
      "learning_rate": 6.257242178447277e-06,
      "loss": 0.0001,
      "step": 22650
    },
    {
      "epoch": 2.630359212050985,
      "grad_norm": 0.0012568001402541995,
      "learning_rate": 6.160679799150251e-06,
      "loss": 0.0002,
      "step": 22700
    },
    {
      "epoch": 2.6361529548088063,
      "grad_norm": 0.00032106737489812076,
      "learning_rate": 6.0641174198532255e-06,
      "loss": 0.0001,
      "step": 22750
    },
    {
      "epoch": 2.641946697566628,
      "grad_norm": 0.00024541723541915417,
      "learning_rate": 5.9675550405562e-06,
      "loss": 0.0001,
      "step": 22800
    },
    {
      "epoch": 2.6477404403244496,
      "grad_norm": 0.08183453232049942,
      "learning_rate": 5.870992661259174e-06,
      "loss": 0.0,
      "step": 22850
    },
    {
      "epoch": 2.653534183082271,
      "grad_norm": 0.0004340902087278664,
      "learning_rate": 5.7744302819621475e-06,
      "loss": 0.0001,
      "step": 22900
    },
    {
      "epoch": 2.659327925840093,
      "grad_norm": 0.014637429267168045,
      "learning_rate": 5.677867902665122e-06,
      "loss": 0.0001,
      "step": 22950
    },
    {
      "epoch": 2.665121668597914,
      "grad_norm": 0.0006267741555348039,
      "learning_rate": 5.581305523368096e-06,
      "loss": 0.0,
      "step": 23000
    },
    {
      "epoch": 2.670915411355736,
      "grad_norm": 0.0025511423591524363,
      "learning_rate": 5.48474314407107e-06,
      "loss": 0.0001,
      "step": 23050
    },
    {
      "epoch": 2.6767091541135573,
      "grad_norm": 0.00027918536216020584,
      "learning_rate": 5.3881807647740446e-06,
      "loss": 0.0,
      "step": 23100
    },
    {
      "epoch": 2.682502896871379,
      "grad_norm": 0.003924323245882988,
      "learning_rate": 5.291618385477019e-06,
      "loss": 0.0,
      "step": 23150
    },
    {
      "epoch": 2.6882966396292005,
      "grad_norm": 0.0026420089416205883,
      "learning_rate": 5.195056006179993e-06,
      "loss": 0.0004,
      "step": 23200
    },
    {
      "epoch": 2.6882966396292005,
      "eval_loss": 0.0007014042348600924,
      "eval_runtime": 30.2546,
      "eval_samples_per_second": 275.958,
      "eval_steps_per_second": 34.507,
      "step": 23200
    },
    {
      "epoch": 2.694090382387022,
      "grad_norm": 0.00012271433661226183,
      "learning_rate": 5.0984936268829666e-06,
      "loss": 0.0,
      "step": 23250
    },
    {
      "epoch": 2.6998841251448438,
      "grad_norm": 0.00020361578208394349,
      "learning_rate": 5.001931247585941e-06,
      "loss": 0.0,
      "step": 23300
    },
    {
      "epoch": 2.705677867902665,
      "grad_norm": 0.001199338585138321,
      "learning_rate": 4.905368868288915e-06,
      "loss": 0.0,
      "step": 23350
    },
    {
      "epoch": 2.7114716106604866,
      "grad_norm": 0.00047008058754727244,
      "learning_rate": 4.808806488991889e-06,
      "loss": 0.0002,
      "step": 23400
    },
    {
      "epoch": 2.717265353418308,
      "grad_norm": 0.0024874338414520025,
      "learning_rate": 4.712244109694864e-06,
      "loss": 0.0001,
      "step": 23450
    },
    {
      "epoch": 2.72305909617613,
      "grad_norm": 0.016408521682024002,
      "learning_rate": 4.615681730397837e-06,
      "loss": 0.0003,
      "step": 23500
    },
    {
      "epoch": 2.7288528389339515,
      "grad_norm": 0.0003171738935634494,
      "learning_rate": 4.519119351100811e-06,
      "loss": 0.0001,
      "step": 23550
    },
    {
      "epoch": 2.7346465816917727,
      "grad_norm": 0.007351107429713011,
      "learning_rate": 4.422556971803786e-06,
      "loss": 0.0001,
      "step": 23600
    },
    {
      "epoch": 2.7404403244495943,
      "grad_norm": 0.00014078954700380564,
      "learning_rate": 4.325994592506759e-06,
      "loss": 0.0001,
      "step": 23650
    },
    {
      "epoch": 2.746234067207416,
      "grad_norm": 0.001066316501237452,
      "learning_rate": 4.229432213209733e-06,
      "loss": 0.0,
      "step": 23700
    },
    {
      "epoch": 2.7520278099652375,
      "grad_norm": 0.0005460577667690814,
      "learning_rate": 4.132869833912708e-06,
      "loss": 0.0,
      "step": 23750
    },
    {
      "epoch": 2.757821552723059,
      "grad_norm": 0.000466977886389941,
      "learning_rate": 4.036307454615682e-06,
      "loss": 0.0,
      "step": 23800
    },
    {
      "epoch": 2.763615295480881,
      "grad_norm": 0.0003876008850056678,
      "learning_rate": 3.939745075318655e-06,
      "loss": 0.0001,
      "step": 23850
    },
    {
      "epoch": 2.7694090382387024,
      "grad_norm": 0.000510610465425998,
      "learning_rate": 3.84318269602163e-06,
      "loss": 0.0001,
      "step": 23900
    },
    {
      "epoch": 2.7752027809965236,
      "grad_norm": 0.00032643385929986835,
      "learning_rate": 3.7466203167246043e-06,
      "loss": 0.0001,
      "step": 23950
    },
    {
      "epoch": 2.7809965237543453,
      "grad_norm": 0.018342241644859314,
      "learning_rate": 3.650057937427578e-06,
      "loss": 0.0,
      "step": 24000
    },
    {
      "epoch": 2.7809965237543453,
      "eval_loss": 0.0006988160312175751,
      "eval_runtime": 30.292,
      "eval_samples_per_second": 275.617,
      "eval_steps_per_second": 34.465,
      "step": 24000
    },
    {
      "epoch": 2.786790266512167,
      "grad_norm": 0.0001341247552772984,
      "learning_rate": 3.5534955581305525e-06,
      "loss": 0.0,
      "step": 24050
    },
    {
      "epoch": 2.7925840092699885,
      "grad_norm": 0.018072232604026794,
      "learning_rate": 3.4569331788335268e-06,
      "loss": 0.0,
      "step": 24100
    },
    {
      "epoch": 2.79837775202781,
      "grad_norm": 0.002578428713604808,
      "learning_rate": 3.360370799536501e-06,
      "loss": 0.0004,
      "step": 24150
    },
    {
      "epoch": 2.8041714947856313,
      "grad_norm": 0.00036566174821928144,
      "learning_rate": 3.2638084202394745e-06,
      "loss": 0.0,
      "step": 24200
    },
    {
      "epoch": 2.809965237543453,
      "grad_norm": 0.0028984369710087776,
      "learning_rate": 3.1672460409424487e-06,
      "loss": 0.0,
      "step": 24250
    },
    {
      "epoch": 2.8157589803012746,
      "grad_norm": 0.00039804461994208395,
      "learning_rate": 3.070683661645423e-06,
      "loss": 0.0,
      "step": 24300
    },
    {
      "epoch": 2.821552723059096,
      "grad_norm": 0.001186605542898178,
      "learning_rate": 2.9741212823483973e-06,
      "loss": 0.0,
      "step": 24350
    },
    {
      "epoch": 2.827346465816918,
      "grad_norm": 0.0015923052560538054,
      "learning_rate": 2.877558903051371e-06,
      "loss": 0.0008,
      "step": 24400
    },
    {
      "epoch": 2.833140208574739,
      "grad_norm": 0.0006775084766559303,
      "learning_rate": 2.7809965237543454e-06,
      "loss": 0.0,
      "step": 24450
    },
    {
      "epoch": 2.838933951332561,
      "grad_norm": 5.8717832871479914e-05,
      "learning_rate": 2.6844341444573197e-06,
      "loss": 0.0,
      "step": 24500
    },
    {
      "epoch": 2.8447276940903823,
      "grad_norm": 0.000619556987658143,
      "learning_rate": 2.5878717651602936e-06,
      "loss": 0.0008,
      "step": 24550
    },
    {
      "epoch": 2.850521436848204,
      "grad_norm": 0.0012819045223295689,
      "learning_rate": 2.491309385863268e-06,
      "loss": 0.0002,
      "step": 24600
    },
    {
      "epoch": 2.8563151796060255,
      "grad_norm": 0.00016439591126982123,
      "learning_rate": 2.394747006566242e-06,
      "loss": 0.0,
      "step": 24650
    },
    {
      "epoch": 2.862108922363847,
      "grad_norm": 0.0030614142306149006,
      "learning_rate": 2.298184627269216e-06,
      "loss": 0.0001,
      "step": 24700
    },
    {
      "epoch": 2.867902665121669,
      "grad_norm": 0.004894044250249863,
      "learning_rate": 2.2016222479721903e-06,
      "loss": 0.0001,
      "step": 24750
    },
    {
      "epoch": 2.87369640787949,
      "grad_norm": 0.004257597960531712,
      "learning_rate": 2.105059868675164e-06,
      "loss": 0.0001,
      "step": 24800
    },
    {
      "epoch": 2.87369640787949,
      "eval_loss": 0.0007024454534985125,
      "eval_runtime": 30.2961,
      "eval_samples_per_second": 275.58,
      "eval_steps_per_second": 34.46,
      "step": 24800
    },
    {
      "epoch": 2.8794901506373116,
      "grad_norm": 0.004705564584583044,
      "learning_rate": 2.0084974893781384e-06,
      "loss": 0.0005,
      "step": 24850
    },
    {
      "epoch": 2.8852838933951332,
      "grad_norm": 0.0004618776438292116,
      "learning_rate": 1.9119351100811122e-06,
      "loss": 0.0001,
      "step": 24900
    },
    {
      "epoch": 2.891077636152955,
      "grad_norm": 0.00040867814095690846,
      "learning_rate": 1.8153727307840865e-06,
      "loss": 0.0003,
      "step": 24950
    },
    {
      "epoch": 2.8968713789107765,
      "grad_norm": 0.0029703218024224043,
      "learning_rate": 1.7188103514870608e-06,
      "loss": 0.0001,
      "step": 25000
    },
    {
      "epoch": 2.9026651216685977,
      "grad_norm": 0.004565117415040731,
      "learning_rate": 1.6222479721900347e-06,
      "loss": 0.0003,
      "step": 25050
    },
    {
      "epoch": 2.9084588644264193,
      "grad_norm": 0.0005856980569660664,
      "learning_rate": 1.525685592893009e-06,
      "loss": 0.0,
      "step": 25100
    },
    {
      "epoch": 2.914252607184241,
      "grad_norm": 0.004091979935765266,
      "learning_rate": 1.429123213595983e-06,
      "loss": 0.0002,
      "step": 25150
    },
    {
      "epoch": 2.9200463499420626,
      "grad_norm": 0.00762145733460784,
      "learning_rate": 1.3325608342989573e-06,
      "loss": 0.0,
      "step": 25200
    },
    {
      "epoch": 2.925840092699884,
      "grad_norm": 0.4288538694381714,
      "learning_rate": 1.2359984550019314e-06,
      "loss": 0.0004,
      "step": 25250
    },
    {
      "epoch": 2.931633835457706,
      "grad_norm": 0.004266073461622,
      "learning_rate": 1.1394360757049054e-06,
      "loss": 0.0002,
      "step": 25300
    },
    {
      "epoch": 2.9374275782155275,
      "grad_norm": 0.0037316223606467247,
      "learning_rate": 1.0428736964078795e-06,
      "loss": 0.0,
      "step": 25350
    },
    {
      "epoch": 2.9432213209733487,
      "grad_norm": 0.0005466780858114362,
      "learning_rate": 9.463113171108537e-07,
      "loss": 0.0,
      "step": 25400
    },
    {
      "epoch": 2.9490150637311703,
      "grad_norm": 0.0017374036833643913,
      "learning_rate": 8.497489378138278e-07,
      "loss": 0.0,
      "step": 25450
    },
    {
      "epoch": 2.954808806488992,
      "grad_norm": 0.0005588773055933416,
      "learning_rate": 7.531865585168019e-07,
      "loss": 0.0,
      "step": 25500
    },
    {
      "epoch": 2.9606025492468135,
      "grad_norm": 0.004197843838483095,
      "learning_rate": 6.566241792197761e-07,
      "loss": 0.0003,
      "step": 25550
    },
    {
      "epoch": 2.966396292004635,
      "grad_norm": 0.00024369361926801503,
      "learning_rate": 5.600617999227501e-07,
      "loss": 0.0001,
      "step": 25600
    },
    {
      "epoch": 2.966396292004635,
      "eval_loss": 0.000693491252604872,
      "eval_runtime": 31.3845,
      "eval_samples_per_second": 266.023,
      "eval_steps_per_second": 33.265,
      "step": 25600
    }
  ],
  "logging_steps": 50,
  "max_steps": 25890,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 800,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 4.0874505970176e+16,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
