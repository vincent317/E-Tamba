{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.9653441451877595,
  "eval_steps": 10000,
  "global_step": 10000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0,
      "grad_norm": 1.1831109523773193,
      "learning_rate": 0.00019903465585481225,
      "loss": 12.0293,
      "step": 50
    },
    {
      "epoch": 0.01,
      "grad_norm": 2.1252129077911377,
      "learning_rate": 0.0001980693117096245,
      "loss": 6.4526,
      "step": 100
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.8542820811271667,
      "learning_rate": 0.00019710396756443673,
      "loss": 5.8366,
      "step": 150
    },
    {
      "epoch": 0.02,
      "grad_norm": 1.4293636083602905,
      "learning_rate": 0.00019613862341924897,
      "loss": 5.5812,
      "step": 200
    },
    {
      "epoch": 0.02,
      "grad_norm": 1.1128816604614258,
      "learning_rate": 0.00019517327927406122,
      "loss": 5.39,
      "step": 250
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.9484511613845825,
      "learning_rate": 0.00019420793512887346,
      "loss": 5.2704,
      "step": 300
    },
    {
      "epoch": 0.03,
      "grad_norm": 1.0232495069503784,
      "learning_rate": 0.0001932425909836857,
      "loss": 5.1774,
      "step": 350
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.9939271211624146,
      "learning_rate": 0.0001922772468384979,
      "loss": 5.0812,
      "step": 400
    },
    {
      "epoch": 0.04,
      "grad_norm": 1.1946239471435547,
      "learning_rate": 0.00019131190269331015,
      "loss": 5.0281,
      "step": 450
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.9344195127487183,
      "learning_rate": 0.00019034655854812242,
      "loss": 4.9519,
      "step": 500
    },
    {
      "epoch": 0.05,
      "grad_norm": 1.0779428482055664,
      "learning_rate": 0.00018938121440293466,
      "loss": 4.909,
      "step": 550
    },
    {
      "epoch": 0.06,
      "grad_norm": 1.1772536039352417,
      "learning_rate": 0.0001884158702577469,
      "loss": 4.8818,
      "step": 600
    },
    {
      "epoch": 0.06,
      "grad_norm": 1.1766468286514282,
      "learning_rate": 0.00018745052611255912,
      "loss": 4.8285,
      "step": 650
    },
    {
      "epoch": 0.07,
      "grad_norm": 1.0086287260055542,
      "learning_rate": 0.00018648518196737136,
      "loss": 4.7737,
      "step": 700
    },
    {
      "epoch": 0.07,
      "grad_norm": 1.0564498901367188,
      "learning_rate": 0.0001855198378221836,
      "loss": 4.7323,
      "step": 750
    },
    {
      "epoch": 0.08,
      "grad_norm": 1.3032190799713135,
      "learning_rate": 0.00018455449367699587,
      "loss": 4.6956,
      "step": 800
    },
    {
      "epoch": 0.08,
      "grad_norm": 1.033011555671692,
      "learning_rate": 0.0001835891495318081,
      "loss": 4.6894,
      "step": 850
    },
    {
      "epoch": 0.09,
      "grad_norm": 1.1023571491241455,
      "learning_rate": 0.00018262380538662033,
      "loss": 4.6513,
      "step": 900
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.9695497751235962,
      "learning_rate": 0.00018165846124143257,
      "loss": 4.6291,
      "step": 950
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.9002431631088257,
      "learning_rate": 0.0001806931170962448,
      "loss": 4.6395,
      "step": 1000
    },
    {
      "epoch": 0.1,
      "grad_norm": 1.2878634929656982,
      "learning_rate": 0.00017972777295105705,
      "loss": 4.5899,
      "step": 1050
    },
    {
      "epoch": 0.11,
      "grad_norm": 1.0203977823257446,
      "learning_rate": 0.00017876242880586932,
      "loss": 4.5735,
      "step": 1100
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.9655368328094482,
      "learning_rate": 0.00017779708466068153,
      "loss": 4.5603,
      "step": 1150
    },
    {
      "epoch": 0.12,
      "grad_norm": 1.065623164176941,
      "learning_rate": 0.00017683174051549377,
      "loss": 4.5378,
      "step": 1200
    },
    {
      "epoch": 0.12,
      "grad_norm": 1.1114627122879028,
      "learning_rate": 0.00017586639637030602,
      "loss": 4.5017,
      "step": 1250
    },
    {
      "epoch": 0.13,
      "grad_norm": 1.1337567567825317,
      "learning_rate": 0.00017490105222511826,
      "loss": 4.5243,
      "step": 1300
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.9285839200019836,
      "learning_rate": 0.0001739357080799305,
      "loss": 4.5019,
      "step": 1350
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.8981044888496399,
      "learning_rate": 0.00017297036393474274,
      "loss": 4.4665,
      "step": 1400
    },
    {
      "epoch": 0.14,
      "grad_norm": 1.0722630023956299,
      "learning_rate": 0.00017200501978955498,
      "loss": 4.4539,
      "step": 1450
    },
    {
      "epoch": 0.14,
      "grad_norm": 1.1475744247436523,
      "learning_rate": 0.00017103967564436722,
      "loss": 4.4621,
      "step": 1500
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.9215633273124695,
      "learning_rate": 0.00017007433149917946,
      "loss": 4.4462,
      "step": 1550
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.9087814092636108,
      "learning_rate": 0.0001691089873539917,
      "loss": 4.4474,
      "step": 1600
    },
    {
      "epoch": 0.16,
      "grad_norm": 1.2054177522659302,
      "learning_rate": 0.00016814364320880395,
      "loss": 4.4256,
      "step": 1650
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.8464893698692322,
      "learning_rate": 0.0001671782990636162,
      "loss": 4.4077,
      "step": 1700
    },
    {
      "epoch": 0.17,
      "grad_norm": 1.018018126487732,
      "learning_rate": 0.00016621295491842843,
      "loss": 4.4107,
      "step": 1750
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.88913494348526,
      "learning_rate": 0.00016524761077324067,
      "loss": 4.39,
      "step": 1800
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.9876972436904907,
      "learning_rate": 0.0001642822666280529,
      "loss": 4.3839,
      "step": 1850
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.9479725360870361,
      "learning_rate": 0.00016331692248286515,
      "loss": 4.3947,
      "step": 1900
    },
    {
      "epoch": 0.19,
      "grad_norm": 1.1295076608657837,
      "learning_rate": 0.00016235157833767737,
      "loss": 4.3916,
      "step": 1950
    },
    {
      "epoch": 0.19,
      "grad_norm": 1.130225419998169,
      "learning_rate": 0.00016138623419248964,
      "loss": 4.3724,
      "step": 2000
    },
    {
      "epoch": 0.2,
      "grad_norm": 1.021152138710022,
      "learning_rate": 0.00016042089004730188,
      "loss": 4.374,
      "step": 2050
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.978830099105835,
      "learning_rate": 0.00015945554590211412,
      "loss": 4.346,
      "step": 2100
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.9898183345794678,
      "learning_rate": 0.00015849020175692636,
      "loss": 4.3529,
      "step": 2150
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.9028749465942383,
      "learning_rate": 0.00015752485761173857,
      "loss": 4.3281,
      "step": 2200
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.9500772356987,
      "learning_rate": 0.00015655951346655082,
      "loss": 4.3415,
      "step": 2250
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.8106299638748169,
      "learning_rate": 0.00015559416932136308,
      "loss": 4.3426,
      "step": 2300
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.8976991772651672,
      "learning_rate": 0.00015462882517617533,
      "loss": 4.3021,
      "step": 2350
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.8616029024124146,
      "learning_rate": 0.00015366348103098757,
      "loss": 4.3439,
      "step": 2400
    },
    {
      "epoch": 0.24,
      "grad_norm": 1.5985931158065796,
      "learning_rate": 0.00015269813688579978,
      "loss": 4.3276,
      "step": 2450
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.9222970604896545,
      "learning_rate": 0.00015173279274061202,
      "loss": 4.3205,
      "step": 2500
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.901764988899231,
      "learning_rate": 0.00015076744859542426,
      "loss": 4.2682,
      "step": 2550
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.8449400067329407,
      "learning_rate": 0.00014980210445023653,
      "loss": 4.296,
      "step": 2600
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.8904820084571838,
      "learning_rate": 0.00014883676030504877,
      "loss": 4.2949,
      "step": 2650
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.9016705751419067,
      "learning_rate": 0.000147871416159861,
      "loss": 4.2792,
      "step": 2700
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.9787415862083435,
      "learning_rate": 0.00014690607201467323,
      "loss": 4.299,
      "step": 2750
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.9014378786087036,
      "learning_rate": 0.00014594072786948547,
      "loss": 4.2628,
      "step": 2800
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.9620230197906494,
      "learning_rate": 0.0001449753837242977,
      "loss": 4.2787,
      "step": 2850
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.9389142990112305,
      "learning_rate": 0.00014401003957910998,
      "loss": 4.2602,
      "step": 2900
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.8291735649108887,
      "learning_rate": 0.0001430446954339222,
      "loss": 4.2542,
      "step": 2950
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.9001755714416504,
      "learning_rate": 0.00014207935128873444,
      "loss": 4.2819,
      "step": 3000
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.9112041592597961,
      "learning_rate": 0.00014111400714354668,
      "loss": 4.2286,
      "step": 3050
    },
    {
      "epoch": 0.3,
      "grad_norm": 1.0518839359283447,
      "learning_rate": 0.00014014866299835892,
      "loss": 4.2447,
      "step": 3100
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.8364813923835754,
      "learning_rate": 0.00013918331885317116,
      "loss": 4.2415,
      "step": 3150
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.9217178821563721,
      "learning_rate": 0.0001382179747079834,
      "loss": 4.2407,
      "step": 3200
    },
    {
      "epoch": 0.31,
      "grad_norm": 1.006066918373108,
      "learning_rate": 0.00013725263056279564,
      "loss": 4.2426,
      "step": 3250
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.8733242750167847,
      "learning_rate": 0.00013628728641760788,
      "loss": 4.2406,
      "step": 3300
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.829822838306427,
      "learning_rate": 0.00013532194227242013,
      "loss": 4.2026,
      "step": 3350
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.8899915814399719,
      "learning_rate": 0.00013435659812723237,
      "loss": 4.2133,
      "step": 3400
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.8136917352676392,
      "learning_rate": 0.0001333912539820446,
      "loss": 4.2213,
      "step": 3450
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.7769774794578552,
      "learning_rate": 0.00013242590983685685,
      "loss": 4.2032,
      "step": 3500
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.9257606863975525,
      "learning_rate": 0.0001314605656916691,
      "loss": 4.186,
      "step": 3550
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.9810475707054138,
      "learning_rate": 0.00013049522154648133,
      "loss": 4.1869,
      "step": 3600
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.8356710076332092,
      "learning_rate": 0.00012952987740129357,
      "loss": 4.2178,
      "step": 3650
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.8805652856826782,
      "learning_rate": 0.00012856453325610581,
      "loss": 4.2012,
      "step": 3700
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.8428524732589722,
      "learning_rate": 0.00012759918911091803,
      "loss": 4.2057,
      "step": 3750
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.8771306872367859,
      "learning_rate": 0.0001266338449657303,
      "loss": 4.2058,
      "step": 3800
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.7939105033874512,
      "learning_rate": 0.00012566850082054254,
      "loss": 4.1971,
      "step": 3850
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.9341532588005066,
      "learning_rate": 0.00012470315667535478,
      "loss": 4.1887,
      "step": 3900
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.8148544430732727,
      "learning_rate": 0.000123737812530167,
      "loss": 4.21,
      "step": 3950
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.8167626857757568,
      "learning_rate": 0.00012277246838497924,
      "loss": 4.1938,
      "step": 4000
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.9070426225662231,
      "learning_rate": 0.00012180712423979148,
      "loss": 4.187,
      "step": 4050
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.970813512802124,
      "learning_rate": 0.00012084178009460375,
      "loss": 4.1759,
      "step": 4100
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.8578963279724121,
      "learning_rate": 0.00011987643594941597,
      "loss": 4.1721,
      "step": 4150
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.8368277549743652,
      "learning_rate": 0.00011891109180422821,
      "loss": 4.1711,
      "step": 4200
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.7535359263420105,
      "learning_rate": 0.00011794574765904046,
      "loss": 4.1845,
      "step": 4250
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.8008574843406677,
      "learning_rate": 0.00011698040351385268,
      "loss": 4.186,
      "step": 4300
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.8865323662757874,
      "learning_rate": 0.00011601505936866492,
      "loss": 4.1901,
      "step": 4350
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.8139011263847351,
      "learning_rate": 0.00011504971522347718,
      "loss": 4.1634,
      "step": 4400
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.8177691102027893,
      "learning_rate": 0.00011408437107828942,
      "loss": 4.1658,
      "step": 4450
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.876196026802063,
      "learning_rate": 0.00011311902693310166,
      "loss": 4.1538,
      "step": 4500
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.8399475812911987,
      "learning_rate": 0.00011215368278791389,
      "loss": 4.1726,
      "step": 4550
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.8505564332008362,
      "learning_rate": 0.00011118833864272613,
      "loss": 4.1825,
      "step": 4600
    },
    {
      "epoch": 0.45,
      "grad_norm": 1.0946942567825317,
      "learning_rate": 0.00011022299449753837,
      "loss": 4.1533,
      "step": 4650
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.8010426759719849,
      "learning_rate": 0.00010925765035235063,
      "loss": 4.1494,
      "step": 4700
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.9217972755432129,
      "learning_rate": 0.00010829230620716287,
      "loss": 4.142,
      "step": 4750
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.7805877327919006,
      "learning_rate": 0.0001073269620619751,
      "loss": 4.1363,
      "step": 4800
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.7503125667572021,
      "learning_rate": 0.00010636161791678734,
      "loss": 4.1473,
      "step": 4850
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.7933399677276611,
      "learning_rate": 0.00010539627377159958,
      "loss": 4.1532,
      "step": 4900
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.4533488750457764,
      "learning_rate": 0.00010443092962641181,
      "loss": 4.1493,
      "step": 4950
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.7649533748626709,
      "learning_rate": 0.00010346558548122408,
      "loss": 4.1373,
      "step": 5000
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.8394296169281006,
      "learning_rate": 0.0001025002413360363,
      "loss": 4.1504,
      "step": 5050
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.9168701171875,
      "learning_rate": 0.00010153489719084855,
      "loss": 4.15,
      "step": 5100
    },
    {
      "epoch": 0.5,
      "grad_norm": 1.0212746858596802,
      "learning_rate": 0.00010056955304566079,
      "loss": 4.1508,
      "step": 5150
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.7445544004440308,
      "learning_rate": 9.960420890047303e-05,
      "loss": 4.1244,
      "step": 5200
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.7316919565200806,
      "learning_rate": 9.863886475528527e-05,
      "loss": 4.142,
      "step": 5250
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.9440210461616516,
      "learning_rate": 9.76735206100975e-05,
      "loss": 4.1369,
      "step": 5300
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.7979694604873657,
      "learning_rate": 9.670817646490975e-05,
      "loss": 4.134,
      "step": 5350
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.8512402772903442,
      "learning_rate": 9.574283231972199e-05,
      "loss": 4.1273,
      "step": 5400
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.7828729152679443,
      "learning_rate": 9.477748817453422e-05,
      "loss": 4.1428,
      "step": 5450
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.7703240513801575,
      "learning_rate": 9.381214402934648e-05,
      "loss": 4.1262,
      "step": 5500
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.8838983178138733,
      "learning_rate": 9.28467998841587e-05,
      "loss": 4.123,
      "step": 5550
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.8798351287841797,
      "learning_rate": 9.188145573897094e-05,
      "loss": 4.1236,
      "step": 5600
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.8104236721992493,
      "learning_rate": 9.091611159378319e-05,
      "loss": 4.1163,
      "step": 5650
    },
    {
      "epoch": 0.55,
      "grad_norm": 1.1629277467727661,
      "learning_rate": 8.995076744859543e-05,
      "loss": 4.1139,
      "step": 5700
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.8344479203224182,
      "learning_rate": 8.898542330340767e-05,
      "loss": 4.1298,
      "step": 5750
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.8348279595375061,
      "learning_rate": 8.802007915821991e-05,
      "loss": 4.1142,
      "step": 5800
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.8348570466041565,
      "learning_rate": 8.705473501303215e-05,
      "loss": 4.1121,
      "step": 5850
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.81160569190979,
      "learning_rate": 8.608939086784439e-05,
      "loss": 4.116,
      "step": 5900
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.8235256671905518,
      "learning_rate": 8.512404672265663e-05,
      "loss": 4.1165,
      "step": 5950
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.8537554144859314,
      "learning_rate": 8.415870257746888e-05,
      "loss": 4.1121,
      "step": 6000
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.7951446175575256,
      "learning_rate": 8.31933584322811e-05,
      "loss": 4.1054,
      "step": 6050
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.7870866060256958,
      "learning_rate": 8.222801428709336e-05,
      "loss": 4.1076,
      "step": 6100
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.7953885197639465,
      "learning_rate": 8.12626701419056e-05,
      "loss": 4.0918,
      "step": 6150
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.7668984532356262,
      "learning_rate": 8.029732599671783e-05,
      "loss": 4.1259,
      "step": 6200
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.8038023114204407,
      "learning_rate": 7.933198185153008e-05,
      "loss": 4.0943,
      "step": 6250
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.8485773801803589,
      "learning_rate": 7.836663770634231e-05,
      "loss": 4.0995,
      "step": 6300
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.788272500038147,
      "learning_rate": 7.740129356115455e-05,
      "loss": 4.1046,
      "step": 6350
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.845066487789154,
      "learning_rate": 7.64359494159668e-05,
      "loss": 4.0984,
      "step": 6400
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.7977762818336487,
      "learning_rate": 7.547060527077903e-05,
      "loss": 4.1179,
      "step": 6450
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.8691519498825073,
      "learning_rate": 7.450526112559128e-05,
      "loss": 4.0778,
      "step": 6500
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.7868472933769226,
      "learning_rate": 7.353991698040352e-05,
      "loss": 4.0906,
      "step": 6550
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.8411058187484741,
      "learning_rate": 7.257457283521576e-05,
      "loss": 4.1037,
      "step": 6600
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.8139075636863708,
      "learning_rate": 7.1609228690028e-05,
      "loss": 4.0857,
      "step": 6650
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.7905910015106201,
      "learning_rate": 7.064388454484024e-05,
      "loss": 4.1178,
      "step": 6700
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.7497928142547607,
      "learning_rate": 6.967854039965248e-05,
      "loss": 4.1009,
      "step": 6750
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.8128554821014404,
      "learning_rate": 6.871319625446472e-05,
      "loss": 4.0957,
      "step": 6800
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.7888936996459961,
      "learning_rate": 6.774785210927696e-05,
      "loss": 4.0983,
      "step": 6850
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.8160465955734253,
      "learning_rate": 6.67825079640892e-05,
      "loss": 4.1003,
      "step": 6900
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.7542181015014648,
      "learning_rate": 6.581716381890143e-05,
      "loss": 4.0995,
      "step": 6950
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.803841769695282,
      "learning_rate": 6.485181967371369e-05,
      "loss": 4.0998,
      "step": 7000
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.7917157411575317,
      "learning_rate": 6.388647552852593e-05,
      "loss": 4.0898,
      "step": 7050
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.8366890549659729,
      "learning_rate": 6.292113138333816e-05,
      "loss": 4.0992,
      "step": 7100
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.8626620173454285,
      "learning_rate": 6.195578723815041e-05,
      "loss": 4.0649,
      "step": 7150
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.9269588589668274,
      "learning_rate": 6.099044309296265e-05,
      "loss": 4.0656,
      "step": 7200
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.8664495348930359,
      "learning_rate": 6.002509894777488e-05,
      "loss": 4.0797,
      "step": 7250
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.7460818290710449,
      "learning_rate": 5.905975480258713e-05,
      "loss": 4.0637,
      "step": 7300
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.8001348376274109,
      "learning_rate": 5.8094410657399365e-05,
      "loss": 4.072,
      "step": 7350
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.8625226020812988,
      "learning_rate": 5.7129066512211606e-05,
      "loss": 4.076,
      "step": 7400
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.8108483552932739,
      "learning_rate": 5.6163722367023854e-05,
      "loss": 4.085,
      "step": 7450
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.7543138861656189,
      "learning_rate": 5.519837822183609e-05,
      "loss": 4.0595,
      "step": 7500
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.8009384274482727,
      "learning_rate": 5.4233034076648323e-05,
      "loss": 4.0652,
      "step": 7550
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.8281601667404175,
      "learning_rate": 5.326768993146057e-05,
      "loss": 4.0823,
      "step": 7600
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.8780572414398193,
      "learning_rate": 5.230234578627281e-05,
      "loss": 4.0716,
      "step": 7650
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.7585793137550354,
      "learning_rate": 5.133700164108505e-05,
      "loss": 4.0726,
      "step": 7700
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.799333393573761,
      "learning_rate": 5.0371657495897296e-05,
      "loss": 4.0839,
      "step": 7750
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.939466118812561,
      "learning_rate": 4.940631335070953e-05,
      "loss": 4.0707,
      "step": 7800
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.801547110080719,
      "learning_rate": 4.844096920552177e-05,
      "loss": 4.0618,
      "step": 7850
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.7751566171646118,
      "learning_rate": 4.747562506033401e-05,
      "loss": 4.0767,
      "step": 7900
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.8002744913101196,
      "learning_rate": 4.6510280915146254e-05,
      "loss": 4.0859,
      "step": 7950
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.7264780402183533,
      "learning_rate": 4.554493676995849e-05,
      "loss": 4.0523,
      "step": 8000
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.7637783288955688,
      "learning_rate": 4.457959262477073e-05,
      "loss": 4.0777,
      "step": 8050
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.8075039386749268,
      "learning_rate": 4.361424847958298e-05,
      "loss": 4.0539,
      "step": 8100
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.7646215558052063,
      "learning_rate": 4.264890433439521e-05,
      "loss": 4.0804,
      "step": 8150
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.7696529030799866,
      "learning_rate": 4.1683560189207454e-05,
      "loss": 4.0636,
      "step": 8200
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.780855655670166,
      "learning_rate": 4.0718216044019695e-05,
      "loss": 4.0708,
      "step": 8250
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.750584602355957,
      "learning_rate": 3.975287189883194e-05,
      "loss": 4.0541,
      "step": 8300
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.7928070425987244,
      "learning_rate": 3.878752775364418e-05,
      "loss": 4.0792,
      "step": 8350
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.7888878583908081,
      "learning_rate": 3.782218360845642e-05,
      "loss": 4.0757,
      "step": 8400
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.8757635354995728,
      "learning_rate": 3.6856839463268654e-05,
      "loss": 4.0668,
      "step": 8450
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.7734505534172058,
      "learning_rate": 3.5891495318080895e-05,
      "loss": 4.071,
      "step": 8500
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.7648115158081055,
      "learning_rate": 3.492615117289314e-05,
      "loss": 4.0511,
      "step": 8550
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.7599343657493591,
      "learning_rate": 3.396080702770538e-05,
      "loss": 4.0573,
      "step": 8600
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.7809708714485168,
      "learning_rate": 3.299546288251762e-05,
      "loss": 4.0573,
      "step": 8650
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.9333725571632385,
      "learning_rate": 3.203011873732986e-05,
      "loss": 4.0461,
      "step": 8700
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.7305577397346497,
      "learning_rate": 3.1064774592142095e-05,
      "loss": 4.0588,
      "step": 8750
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.7607168555259705,
      "learning_rate": 3.009943044695434e-05,
      "loss": 4.0736,
      "step": 8800
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.7994370460510254,
      "learning_rate": 2.9134086301766585e-05,
      "loss": 4.0638,
      "step": 8850
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.730217456817627,
      "learning_rate": 2.816874215657882e-05,
      "loss": 4.0667,
      "step": 8900
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.7758764624595642,
      "learning_rate": 2.7203398011391064e-05,
      "loss": 4.0564,
      "step": 8950
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.7568299770355225,
      "learning_rate": 2.6238053866203305e-05,
      "loss": 4.064,
      "step": 9000
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.8023002743721008,
      "learning_rate": 2.5272709721015543e-05,
      "loss": 4.0505,
      "step": 9050
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.8454918265342712,
      "learning_rate": 2.4307365575827785e-05,
      "loss": 4.0395,
      "step": 9100
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.8119435906410217,
      "learning_rate": 2.3342021430640023e-05,
      "loss": 4.0513,
      "step": 9150
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.77997225522995,
      "learning_rate": 2.2376677285452267e-05,
      "loss": 4.0633,
      "step": 9200
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.8070201277732849,
      "learning_rate": 2.1411333140264505e-05,
      "loss": 4.0619,
      "step": 9250
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.7569475769996643,
      "learning_rate": 2.0445988995076747e-05,
      "loss": 4.071,
      "step": 9300
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.892610490322113,
      "learning_rate": 1.9480644849888988e-05,
      "loss": 4.0446,
      "step": 9350
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.8263782858848572,
      "learning_rate": 1.8515300704701226e-05,
      "loss": 4.0387,
      "step": 9400
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.7218354940414429,
      "learning_rate": 1.7549956559513467e-05,
      "loss": 4.0482,
      "step": 9450
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.8567434549331665,
      "learning_rate": 1.658461241432571e-05,
      "loss": 4.0534,
      "step": 9500
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.8486940860748291,
      "learning_rate": 1.561926826913795e-05,
      "loss": 4.0602,
      "step": 9550
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.780633807182312,
      "learning_rate": 1.4653924123950188e-05,
      "loss": 4.0446,
      "step": 9600
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.7317347526550293,
      "learning_rate": 1.3688579978762431e-05,
      "loss": 4.0527,
      "step": 9650
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.7696024775505066,
      "learning_rate": 1.272323583357467e-05,
      "loss": 4.0475,
      "step": 9700
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.7494524717330933,
      "learning_rate": 1.175789168838691e-05,
      "loss": 4.0592,
      "step": 9750
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.7924948334693909,
      "learning_rate": 1.0792547543199152e-05,
      "loss": 4.0307,
      "step": 9800
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.7413445115089417,
      "learning_rate": 9.827203398011391e-06,
      "loss": 4.0252,
      "step": 9850
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.7417407035827637,
      "learning_rate": 8.861859252823631e-06,
      "loss": 4.0403,
      "step": 9900
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.7674304842948914,
      "learning_rate": 7.896515107635872e-06,
      "loss": 4.0239,
      "step": 9950
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.8087213039398193,
      "learning_rate": 6.931170962448114e-06,
      "loss": 4.0435,
      "step": 10000
    },
    {
      "epoch": 0.97,
      "eval_loss": 4.051451683044434,
      "eval_runtime": 750.1314,
      "eval_samples_per_second": 83.361,
      "eval_steps_per_second": 1.304,
      "step": 10000
    }
  ],
  "logging_steps": 50,
  "max_steps": 10359,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 10000,
  "total_flos": 8.141383139328e+16,
  "train_batch_size": 48,
  "trial_name": null,
  "trial_params": null
}
