{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.9867068658352748,
  "eval_steps": 900,
  "global_step": 1800,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.005481704810195971,
      "grad_norm": 3.151129961013794,
      "learning_rate": 0.0001,
      "loss": 5.5417,
      "step": 10
    },
    {
      "epoch": 0.010963409620391941,
      "grad_norm": 2.0958142280578613,
      "learning_rate": 0.0001,
      "loss": 4.3091,
      "step": 20
    },
    {
      "epoch": 0.016445114430587913,
      "grad_norm": 2.2808260917663574,
      "learning_rate": 0.0001,
      "loss": 4.0895,
      "step": 30
    },
    {
      "epoch": 0.021926819240783883,
      "grad_norm": 2.004617214202881,
      "learning_rate": 0.0001,
      "loss": 3.9383,
      "step": 40
    },
    {
      "epoch": 0.027408524050979856,
      "grad_norm": 1.780859351158142,
      "learning_rate": 0.0001,
      "loss": 3.9286,
      "step": 50
    },
    {
      "epoch": 0.032890228861175826,
      "grad_norm": 2.0659005641937256,
      "learning_rate": 0.0001,
      "loss": 3.9232,
      "step": 60
    },
    {
      "epoch": 0.038371933671371795,
      "grad_norm": 1.6403567790985107,
      "learning_rate": 0.0001,
      "loss": 3.8659,
      "step": 70
    },
    {
      "epoch": 0.043853638481567765,
      "grad_norm": 1.7690699100494385,
      "learning_rate": 0.0001,
      "loss": 3.9356,
      "step": 80
    },
    {
      "epoch": 0.04933534329176374,
      "grad_norm": 1.7851015329360962,
      "learning_rate": 0.0001,
      "loss": 3.8242,
      "step": 90
    },
    {
      "epoch": 0.05481704810195971,
      "grad_norm": 1.5641695261001587,
      "learning_rate": 0.0001,
      "loss": 3.7844,
      "step": 100
    },
    {
      "epoch": 0.06029875291215568,
      "grad_norm": 1.5278561115264893,
      "learning_rate": 0.0001,
      "loss": 3.7856,
      "step": 110
    },
    {
      "epoch": 0.06578045772235165,
      "grad_norm": 1.5756171941757202,
      "learning_rate": 0.0001,
      "loss": 3.7559,
      "step": 120
    },
    {
      "epoch": 0.07126216253254762,
      "grad_norm": 1.4340158700942993,
      "learning_rate": 0.0001,
      "loss": 3.7028,
      "step": 130
    },
    {
      "epoch": 0.07674386734274359,
      "grad_norm": 1.5940320491790771,
      "learning_rate": 0.0001,
      "loss": 3.7284,
      "step": 140
    },
    {
      "epoch": 0.08222557215293956,
      "grad_norm": 1.8554809093475342,
      "learning_rate": 0.0001,
      "loss": 3.7545,
      "step": 150
    },
    {
      "epoch": 0.08770727696313553,
      "grad_norm": 1.505895972251892,
      "learning_rate": 0.0001,
      "loss": 3.7788,
      "step": 160
    },
    {
      "epoch": 0.0931889817733315,
      "grad_norm": 1.6303902864456177,
      "learning_rate": 0.0001,
      "loss": 3.6499,
      "step": 170
    },
    {
      "epoch": 0.09867068658352748,
      "grad_norm": 1.4290934801101685,
      "learning_rate": 0.0001,
      "loss": 3.6894,
      "step": 180
    },
    {
      "epoch": 0.10415239139372345,
      "grad_norm": 1.473488211631775,
      "learning_rate": 0.0001,
      "loss": 3.7012,
      "step": 190
    },
    {
      "epoch": 0.10963409620391942,
      "grad_norm": 1.447486162185669,
      "learning_rate": 0.0001,
      "loss": 3.7298,
      "step": 200
    },
    {
      "epoch": 0.1151158010141154,
      "grad_norm": 1.558182954788208,
      "learning_rate": 0.0001,
      "loss": 3.6642,
      "step": 210
    },
    {
      "epoch": 0.12059750582431136,
      "grad_norm": 1.4898028373718262,
      "learning_rate": 0.0001,
      "loss": 3.6422,
      "step": 220
    },
    {
      "epoch": 0.12607921063450733,
      "grad_norm": 1.6011905670166016,
      "learning_rate": 0.0001,
      "loss": 3.6652,
      "step": 230
    },
    {
      "epoch": 0.1315609154447033,
      "grad_norm": 1.2855685949325562,
      "learning_rate": 0.0001,
      "loss": 3.644,
      "step": 240
    },
    {
      "epoch": 0.13704262025489927,
      "grad_norm": 1.503525972366333,
      "learning_rate": 0.0001,
      "loss": 3.6415,
      "step": 250
    },
    {
      "epoch": 0.14252432506509524,
      "grad_norm": 1.4367221593856812,
      "learning_rate": 0.0001,
      "loss": 3.6035,
      "step": 260
    },
    {
      "epoch": 0.1480060298752912,
      "grad_norm": 1.5203759670257568,
      "learning_rate": 0.0001,
      "loss": 3.626,
      "step": 270
    },
    {
      "epoch": 0.15348773468548718,
      "grad_norm": 1.3721895217895508,
      "learning_rate": 0.0001,
      "loss": 3.6528,
      "step": 280
    },
    {
      "epoch": 0.15896943949568315,
      "grad_norm": 1.295588493347168,
      "learning_rate": 0.0001,
      "loss": 3.6357,
      "step": 290
    },
    {
      "epoch": 0.16445114430587912,
      "grad_norm": 1.3383963108062744,
      "learning_rate": 0.0001,
      "loss": 3.61,
      "step": 300
    },
    {
      "epoch": 0.1699328491160751,
      "grad_norm": 1.284389615058899,
      "learning_rate": 0.0001,
      "loss": 3.6271,
      "step": 310
    },
    {
      "epoch": 0.17541455392627106,
      "grad_norm": 1.2792001962661743,
      "learning_rate": 0.0001,
      "loss": 3.6188,
      "step": 320
    },
    {
      "epoch": 0.18089625873646703,
      "grad_norm": 1.3618361949920654,
      "learning_rate": 0.0001,
      "loss": 3.6135,
      "step": 330
    },
    {
      "epoch": 0.186377963546663,
      "grad_norm": 1.4794087409973145,
      "learning_rate": 0.0001,
      "loss": 3.595,
      "step": 340
    },
    {
      "epoch": 0.19185966835685897,
      "grad_norm": 1.365308403968811,
      "learning_rate": 0.0001,
      "loss": 3.6226,
      "step": 350
    },
    {
      "epoch": 0.19734137316705497,
      "grad_norm": 1.3228063583374023,
      "learning_rate": 0.0001,
      "loss": 3.6137,
      "step": 360
    },
    {
      "epoch": 0.20282307797725094,
      "grad_norm": 1.367084264755249,
      "learning_rate": 0.0001,
      "loss": 3.5707,
      "step": 370
    },
    {
      "epoch": 0.2083047827874469,
      "grad_norm": 1.4091930389404297,
      "learning_rate": 0.0001,
      "loss": 3.5946,
      "step": 380
    },
    {
      "epoch": 0.21378648759764288,
      "grad_norm": 1.2843859195709229,
      "learning_rate": 0.0001,
      "loss": 3.557,
      "step": 390
    },
    {
      "epoch": 0.21926819240783885,
      "grad_norm": 1.2195395231246948,
      "learning_rate": 0.0001,
      "loss": 3.5607,
      "step": 400
    },
    {
      "epoch": 0.22474989721803482,
      "grad_norm": 1.6783794164657593,
      "learning_rate": 0.0001,
      "loss": 3.6374,
      "step": 410
    },
    {
      "epoch": 0.2302316020282308,
      "grad_norm": 1.573517918586731,
      "learning_rate": 0.0001,
      "loss": 3.5616,
      "step": 420
    },
    {
      "epoch": 0.23571330683842676,
      "grad_norm": 1.2869117259979248,
      "learning_rate": 0.0001,
      "loss": 3.5593,
      "step": 430
    },
    {
      "epoch": 0.24119501164862273,
      "grad_norm": 1.283294677734375,
      "learning_rate": 0.0001,
      "loss": 3.5885,
      "step": 440
    },
    {
      "epoch": 0.2466767164588187,
      "grad_norm": 1.3459075689315796,
      "learning_rate": 0.0001,
      "loss": 3.54,
      "step": 450
    },
    {
      "epoch": 0.25215842126901467,
      "grad_norm": 1.4596338272094727,
      "learning_rate": 0.0001,
      "loss": 3.58,
      "step": 460
    },
    {
      "epoch": 0.2576401260792106,
      "grad_norm": 1.380529522895813,
      "learning_rate": 0.0001,
      "loss": 3.5221,
      "step": 470
    },
    {
      "epoch": 0.2631218308894066,
      "grad_norm": 1.228606104850769,
      "learning_rate": 0.0001,
      "loss": 3.5581,
      "step": 480
    },
    {
      "epoch": 0.2686035356996026,
      "grad_norm": 1.4128233194351196,
      "learning_rate": 0.0001,
      "loss": 3.5426,
      "step": 490
    },
    {
      "epoch": 0.27408524050979854,
      "grad_norm": 1.237077236175537,
      "learning_rate": 0.0001,
      "loss": 3.5746,
      "step": 500
    },
    {
      "epoch": 0.27956694531999454,
      "grad_norm": 1.2780325412750244,
      "learning_rate": 0.0001,
      "loss": 3.5398,
      "step": 510
    },
    {
      "epoch": 0.2850486501301905,
      "grad_norm": 1.351839303970337,
      "learning_rate": 0.0001,
      "loss": 3.5553,
      "step": 520
    },
    {
      "epoch": 0.2905303549403865,
      "grad_norm": 1.3658422231674194,
      "learning_rate": 0.0001,
      "loss": 3.5743,
      "step": 530
    },
    {
      "epoch": 0.2960120597505824,
      "grad_norm": 1.2940647602081299,
      "learning_rate": 0.0001,
      "loss": 3.5701,
      "step": 540
    },
    {
      "epoch": 0.3014937645607784,
      "grad_norm": 1.5112437009811401,
      "learning_rate": 0.0001,
      "loss": 3.5467,
      "step": 550
    },
    {
      "epoch": 0.30697546937097436,
      "grad_norm": 1.291933536529541,
      "learning_rate": 0.0001,
      "loss": 3.5786,
      "step": 560
    },
    {
      "epoch": 0.31245717418117036,
      "grad_norm": 1.4475677013397217,
      "learning_rate": 0.0001,
      "loss": 3.5281,
      "step": 570
    },
    {
      "epoch": 0.3179388789913663,
      "grad_norm": 1.2873584032058716,
      "learning_rate": 0.0001,
      "loss": 3.5401,
      "step": 580
    },
    {
      "epoch": 0.3234205838015623,
      "grad_norm": 1.2832727432250977,
      "learning_rate": 0.0001,
      "loss": 3.5533,
      "step": 590
    },
    {
      "epoch": 0.32890228861175824,
      "grad_norm": 1.3076313734054565,
      "learning_rate": 0.0001,
      "loss": 3.5189,
      "step": 600
    },
    {
      "epoch": 0.33438399342195424,
      "grad_norm": 1.2533555030822754,
      "learning_rate": 0.0001,
      "loss": 3.5293,
      "step": 610
    },
    {
      "epoch": 0.3398656982321502,
      "grad_norm": 1.2464373111724854,
      "learning_rate": 0.0001,
      "loss": 3.5902,
      "step": 620
    },
    {
      "epoch": 0.3453474030423462,
      "grad_norm": 1.2522317171096802,
      "learning_rate": 0.0001,
      "loss": 3.5358,
      "step": 630
    },
    {
      "epoch": 0.3508291078525421,
      "grad_norm": 1.2176612615585327,
      "learning_rate": 0.0001,
      "loss": 3.5282,
      "step": 640
    },
    {
      "epoch": 0.3563108126627381,
      "grad_norm": 1.4101934432983398,
      "learning_rate": 0.0001,
      "loss": 3.5531,
      "step": 650
    },
    {
      "epoch": 0.36179251747293406,
      "grad_norm": 1.2589002847671509,
      "learning_rate": 0.0001,
      "loss": 3.5262,
      "step": 660
    },
    {
      "epoch": 0.36727422228313006,
      "grad_norm": 1.7628819942474365,
      "learning_rate": 0.0001,
      "loss": 3.509,
      "step": 670
    },
    {
      "epoch": 0.372755927093326,
      "grad_norm": 1.3755885362625122,
      "learning_rate": 0.0001,
      "loss": 3.5381,
      "step": 680
    },
    {
      "epoch": 0.378237631903522,
      "grad_norm": 1.2946668863296509,
      "learning_rate": 0.0001,
      "loss": 3.5242,
      "step": 690
    },
    {
      "epoch": 0.38371933671371794,
      "grad_norm": 1.3489432334899902,
      "learning_rate": 0.0001,
      "loss": 3.5156,
      "step": 700
    },
    {
      "epoch": 0.38920104152391394,
      "grad_norm": 1.3877547979354858,
      "learning_rate": 0.0001,
      "loss": 3.5058,
      "step": 710
    },
    {
      "epoch": 0.39468274633410994,
      "grad_norm": 1.2668349742889404,
      "learning_rate": 0.0001,
      "loss": 3.5047,
      "step": 720
    },
    {
      "epoch": 0.4001644511443059,
      "grad_norm": 1.279440999031067,
      "learning_rate": 0.0001,
      "loss": 3.5219,
      "step": 730
    },
    {
      "epoch": 0.4056461559545019,
      "grad_norm": 1.2282400131225586,
      "learning_rate": 0.0001,
      "loss": 3.5364,
      "step": 740
    },
    {
      "epoch": 0.4111278607646978,
      "grad_norm": 1.138603687286377,
      "learning_rate": 0.0001,
      "loss": 3.4562,
      "step": 750
    },
    {
      "epoch": 0.4166095655748938,
      "grad_norm": 1.272581696510315,
      "learning_rate": 0.0001,
      "loss": 3.5505,
      "step": 760
    },
    {
      "epoch": 0.42209127038508976,
      "grad_norm": 1.3695091009140015,
      "learning_rate": 0.0001,
      "loss": 3.5092,
      "step": 770
    },
    {
      "epoch": 0.42757297519528575,
      "grad_norm": 1.4207860231399536,
      "learning_rate": 0.0001,
      "loss": 3.4984,
      "step": 780
    },
    {
      "epoch": 0.4330546800054817,
      "grad_norm": 1.1543413400650024,
      "learning_rate": 0.0001,
      "loss": 3.4967,
      "step": 790
    },
    {
      "epoch": 0.4385363848156777,
      "grad_norm": 1.3192203044891357,
      "learning_rate": 0.0001,
      "loss": 3.5192,
      "step": 800
    },
    {
      "epoch": 0.44401808962587364,
      "grad_norm": 1.3008992671966553,
      "learning_rate": 0.0001,
      "loss": 3.4848,
      "step": 810
    },
    {
      "epoch": 0.44949979443606963,
      "grad_norm": 1.4705216884613037,
      "learning_rate": 0.0001,
      "loss": 3.5261,
      "step": 820
    },
    {
      "epoch": 0.4549814992462656,
      "grad_norm": 1.188541054725647,
      "learning_rate": 0.0001,
      "loss": 3.4943,
      "step": 830
    },
    {
      "epoch": 0.4604632040564616,
      "grad_norm": 1.2069517374038696,
      "learning_rate": 0.0001,
      "loss": 3.4868,
      "step": 840
    },
    {
      "epoch": 0.4659449088666575,
      "grad_norm": 1.1932071447372437,
      "learning_rate": 0.0001,
      "loss": 3.5307,
      "step": 850
    },
    {
      "epoch": 0.4714266136768535,
      "grad_norm": 1.463769793510437,
      "learning_rate": 0.0001,
      "loss": 3.517,
      "step": 860
    },
    {
      "epoch": 0.47690831848704945,
      "grad_norm": 1.1789461374282837,
      "learning_rate": 0.0001,
      "loss": 3.4901,
      "step": 870
    },
    {
      "epoch": 0.48239002329724545,
      "grad_norm": 1.2145986557006836,
      "learning_rate": 0.0001,
      "loss": 3.4543,
      "step": 880
    },
    {
      "epoch": 0.4878717281074414,
      "grad_norm": 1.174397587776184,
      "learning_rate": 0.0001,
      "loss": 3.5518,
      "step": 890
    },
    {
      "epoch": 0.4933534329176374,
      "grad_norm": 1.2485557794570923,
      "learning_rate": 0.0001,
      "loss": 3.5312,
      "step": 900
    },
    {
      "epoch": 0.4933534329176374,
      "eval_loss": 3.493290662765503,
      "eval_runtime": 245.3183,
      "eval_samples_per_second": 47.665,
      "eval_steps_per_second": 11.919,
      "step": 900
    },
    {
      "epoch": 0.49883513772783333,
      "grad_norm": 1.2047227621078491,
      "learning_rate": 0.0001,
      "loss": 3.4604,
      "step": 910
    },
    {
      "epoch": 0.5043168425380293,
      "grad_norm": 1.344939947128296,
      "learning_rate": 0.0001,
      "loss": 3.4907,
      "step": 920
    },
    {
      "epoch": 0.5097985473482253,
      "grad_norm": 1.3009854555130005,
      "learning_rate": 0.0001,
      "loss": 3.4863,
      "step": 930
    },
    {
      "epoch": 0.5152802521584212,
      "grad_norm": 1.1204755306243896,
      "learning_rate": 0.0001,
      "loss": 3.483,
      "step": 940
    },
    {
      "epoch": 0.5207619569686173,
      "grad_norm": 1.2325876951217651,
      "learning_rate": 0.0001,
      "loss": 3.4527,
      "step": 950
    },
    {
      "epoch": 0.5262436617788132,
      "grad_norm": 1.3107094764709473,
      "learning_rate": 0.0001,
      "loss": 3.4726,
      "step": 960
    },
    {
      "epoch": 0.5317253665890092,
      "grad_norm": 1.1350595951080322,
      "learning_rate": 0.0001,
      "loss": 3.4552,
      "step": 970
    },
    {
      "epoch": 0.5372070713992052,
      "grad_norm": 1.2184361219406128,
      "learning_rate": 0.0001,
      "loss": 3.5078,
      "step": 980
    },
    {
      "epoch": 0.5426887762094011,
      "grad_norm": 1.1969918012619019,
      "learning_rate": 0.0001,
      "loss": 3.4498,
      "step": 990
    },
    {
      "epoch": 0.5481704810195971,
      "grad_norm": 1.169530987739563,
      "learning_rate": 0.0001,
      "loss": 3.4823,
      "step": 1000
    },
    {
      "epoch": 0.553652185829793,
      "grad_norm": 1.2643978595733643,
      "learning_rate": 0.0001,
      "loss": 3.4813,
      "step": 1010
    },
    {
      "epoch": 0.5591338906399891,
      "grad_norm": 1.1304415464401245,
      "learning_rate": 0.0001,
      "loss": 3.4154,
      "step": 1020
    },
    {
      "epoch": 0.564615595450185,
      "grad_norm": 1.108981966972351,
      "learning_rate": 0.0001,
      "loss": 3.4712,
      "step": 1030
    },
    {
      "epoch": 0.570097300260381,
      "grad_norm": 1.2102316617965698,
      "learning_rate": 0.0001,
      "loss": 3.4683,
      "step": 1040
    },
    {
      "epoch": 0.5755790050705769,
      "grad_norm": 1.183030366897583,
      "learning_rate": 0.0001,
      "loss": 3.404,
      "step": 1050
    },
    {
      "epoch": 0.581060709880773,
      "grad_norm": 1.1429182291030884,
      "learning_rate": 0.0001,
      "loss": 3.4323,
      "step": 1060
    },
    {
      "epoch": 0.5865424146909689,
      "grad_norm": 1.0681359767913818,
      "learning_rate": 0.0001,
      "loss": 3.4194,
      "step": 1070
    },
    {
      "epoch": 0.5920241195011648,
      "grad_norm": 1.319586157798767,
      "learning_rate": 0.0001,
      "loss": 3.5009,
      "step": 1080
    },
    {
      "epoch": 0.5975058243113608,
      "grad_norm": 1.140541434288025,
      "learning_rate": 0.0001,
      "loss": 3.4615,
      "step": 1090
    },
    {
      "epoch": 0.6029875291215568,
      "grad_norm": 1.177136778831482,
      "learning_rate": 0.0001,
      "loss": 3.4945,
      "step": 1100
    },
    {
      "epoch": 0.6084692339317528,
      "grad_norm": 1.1744487285614014,
      "learning_rate": 0.0001,
      "loss": 3.477,
      "step": 1110
    },
    {
      "epoch": 0.6139509387419487,
      "grad_norm": 1.217124104499817,
      "learning_rate": 0.0001,
      "loss": 3.4604,
      "step": 1120
    },
    {
      "epoch": 0.6194326435521447,
      "grad_norm": 1.1675735712051392,
      "learning_rate": 0.0001,
      "loss": 3.5082,
      "step": 1130
    },
    {
      "epoch": 0.6249143483623407,
      "grad_norm": 1.271490216255188,
      "learning_rate": 0.0001,
      "loss": 3.4711,
      "step": 1140
    },
    {
      "epoch": 0.6303960531725367,
      "grad_norm": 1.0992385149002075,
      "learning_rate": 0.0001,
      "loss": 3.4743,
      "step": 1150
    },
    {
      "epoch": 0.6358777579827326,
      "grad_norm": 1.1264278888702393,
      "learning_rate": 0.0001,
      "loss": 3.5255,
      "step": 1160
    },
    {
      "epoch": 0.6413594627929285,
      "grad_norm": 1.068666696548462,
      "learning_rate": 0.0001,
      "loss": 3.4087,
      "step": 1170
    },
    {
      "epoch": 0.6468411676031246,
      "grad_norm": 1.1905677318572998,
      "learning_rate": 0.0001,
      "loss": 3.4183,
      "step": 1180
    },
    {
      "epoch": 0.6523228724133205,
      "grad_norm": 1.2062042951583862,
      "learning_rate": 0.0001,
      "loss": 3.4083,
      "step": 1190
    },
    {
      "epoch": 0.6578045772235165,
      "grad_norm": 1.2522950172424316,
      "learning_rate": 0.0001,
      "loss": 3.467,
      "step": 1200
    },
    {
      "epoch": 0.6632862820337125,
      "grad_norm": 1.242775559425354,
      "learning_rate": 0.0001,
      "loss": 3.4755,
      "step": 1210
    },
    {
      "epoch": 0.6687679868439085,
      "grad_norm": 1.2742310762405396,
      "learning_rate": 0.0001,
      "loss": 3.4719,
      "step": 1220
    },
    {
      "epoch": 0.6742496916541044,
      "grad_norm": 1.1215003728866577,
      "learning_rate": 0.0001,
      "loss": 3.4595,
      "step": 1230
    },
    {
      "epoch": 0.6797313964643004,
      "grad_norm": 1.421842336654663,
      "learning_rate": 0.0001,
      "loss": 3.476,
      "step": 1240
    },
    {
      "epoch": 0.6852131012744964,
      "grad_norm": 1.1756950616836548,
      "learning_rate": 0.0001,
      "loss": 3.3927,
      "step": 1250
    },
    {
      "epoch": 0.6906948060846924,
      "grad_norm": 1.3657124042510986,
      "learning_rate": 0.0001,
      "loss": 3.4234,
      "step": 1260
    },
    {
      "epoch": 0.6961765108948883,
      "grad_norm": 1.1451565027236938,
      "learning_rate": 0.0001,
      "loss": 3.4451,
      "step": 1270
    },
    {
      "epoch": 0.7016582157050842,
      "grad_norm": 1.34848153591156,
      "learning_rate": 0.0001,
      "loss": 3.4498,
      "step": 1280
    },
    {
      "epoch": 0.7071399205152803,
      "grad_norm": 1.280098795890808,
      "learning_rate": 0.0001,
      "loss": 3.4429,
      "step": 1290
    },
    {
      "epoch": 0.7126216253254762,
      "grad_norm": 1.1508235931396484,
      "learning_rate": 0.0001,
      "loss": 3.4615,
      "step": 1300
    },
    {
      "epoch": 0.7181033301356722,
      "grad_norm": 1.139003872871399,
      "learning_rate": 0.0001,
      "loss": 3.4413,
      "step": 1310
    },
    {
      "epoch": 0.7235850349458681,
      "grad_norm": 1.3129181861877441,
      "learning_rate": 0.0001,
      "loss": 3.4278,
      "step": 1320
    },
    {
      "epoch": 0.7290667397560642,
      "grad_norm": 1.3171603679656982,
      "learning_rate": 0.0001,
      "loss": 3.4058,
      "step": 1330
    },
    {
      "epoch": 0.7345484445662601,
      "grad_norm": 1.1495636701583862,
      "learning_rate": 0.0001,
      "loss": 3.4118,
      "step": 1340
    },
    {
      "epoch": 0.7400301493764561,
      "grad_norm": 1.0714820623397827,
      "learning_rate": 0.0001,
      "loss": 3.4157,
      "step": 1350
    },
    {
      "epoch": 0.745511854186652,
      "grad_norm": 1.1068886518478394,
      "learning_rate": 0.0001,
      "loss": 3.4171,
      "step": 1360
    },
    {
      "epoch": 0.750993558996848,
      "grad_norm": 1.3175805807113647,
      "learning_rate": 0.0001,
      "loss": 3.4111,
      "step": 1370
    },
    {
      "epoch": 0.756475263807044,
      "grad_norm": 1.252545952796936,
      "learning_rate": 0.0001,
      "loss": 3.4565,
      "step": 1380
    },
    {
      "epoch": 0.7619569686172399,
      "grad_norm": 1.244219422340393,
      "learning_rate": 0.0001,
      "loss": 3.4094,
      "step": 1390
    },
    {
      "epoch": 0.7674386734274359,
      "grad_norm": 1.8924318552017212,
      "learning_rate": 0.0001,
      "loss": 3.4432,
      "step": 1400
    },
    {
      "epoch": 0.7729203782376319,
      "grad_norm": 1.1624605655670166,
      "learning_rate": 0.0001,
      "loss": 3.4096,
      "step": 1410
    },
    {
      "epoch": 0.7784020830478279,
      "grad_norm": 1.1506041288375854,
      "learning_rate": 0.0001,
      "loss": 3.4052,
      "step": 1420
    },
    {
      "epoch": 0.7838837878580238,
      "grad_norm": 1.172170877456665,
      "learning_rate": 0.0001,
      "loss": 3.4611,
      "step": 1430
    },
    {
      "epoch": 0.7893654926682199,
      "grad_norm": 1.1062003374099731,
      "learning_rate": 0.0001,
      "loss": 3.3577,
      "step": 1440
    },
    {
      "epoch": 0.7948471974784158,
      "grad_norm": 1.1349952220916748,
      "learning_rate": 0.0001,
      "loss": 3.3878,
      "step": 1450
    },
    {
      "epoch": 0.8003289022886118,
      "grad_norm": 1.2545338869094849,
      "learning_rate": 0.0001,
      "loss": 3.4598,
      "step": 1460
    },
    {
      "epoch": 0.8058106070988077,
      "grad_norm": 1.216835618019104,
      "learning_rate": 0.0001,
      "loss": 3.3865,
      "step": 1470
    },
    {
      "epoch": 0.8112923119090037,
      "grad_norm": 1.2156288623809814,
      "learning_rate": 0.0001,
      "loss": 3.3796,
      "step": 1480
    },
    {
      "epoch": 0.8167740167191997,
      "grad_norm": 1.11119544506073,
      "learning_rate": 0.0001,
      "loss": 3.461,
      "step": 1490
    },
    {
      "epoch": 0.8222557215293956,
      "grad_norm": 1.225132942199707,
      "learning_rate": 0.0001,
      "loss": 3.3571,
      "step": 1500
    },
    {
      "epoch": 0.8277374263395916,
      "grad_norm": 1.2422053813934326,
      "learning_rate": 0.0001,
      "loss": 3.3975,
      "step": 1510
    },
    {
      "epoch": 0.8332191311497876,
      "grad_norm": 1.101026177406311,
      "learning_rate": 0.0001,
      "loss": 3.3717,
      "step": 1520
    },
    {
      "epoch": 0.8387008359599836,
      "grad_norm": 1.2868540287017822,
      "learning_rate": 0.0001,
      "loss": 3.3793,
      "step": 1530
    },
    {
      "epoch": 0.8441825407701795,
      "grad_norm": 1.187769889831543,
      "learning_rate": 0.0001,
      "loss": 3.4352,
      "step": 1540
    },
    {
      "epoch": 0.8496642455803755,
      "grad_norm": 1.2185710668563843,
      "learning_rate": 0.0001,
      "loss": 3.365,
      "step": 1550
    },
    {
      "epoch": 0.8551459503905715,
      "grad_norm": 1.1528267860412598,
      "learning_rate": 0.0001,
      "loss": 3.4256,
      "step": 1560
    },
    {
      "epoch": 0.8606276552007674,
      "grad_norm": 1.1413273811340332,
      "learning_rate": 0.0001,
      "loss": 3.4489,
      "step": 1570
    },
    {
      "epoch": 0.8661093600109634,
      "grad_norm": 1.1491827964782715,
      "learning_rate": 0.0001,
      "loss": 3.366,
      "step": 1580
    },
    {
      "epoch": 0.8715910648211593,
      "grad_norm": 1.3722851276397705,
      "learning_rate": 0.0001,
      "loss": 3.3823,
      "step": 1590
    },
    {
      "epoch": 0.8770727696313554,
      "grad_norm": 1.105493426322937,
      "learning_rate": 0.0001,
      "loss": 3.3599,
      "step": 1600
    },
    {
      "epoch": 0.8825544744415513,
      "grad_norm": 1.2124671936035156,
      "learning_rate": 0.0001,
      "loss": 3.3952,
      "step": 1610
    },
    {
      "epoch": 0.8880361792517473,
      "grad_norm": 1.1459720134735107,
      "learning_rate": 0.0001,
      "loss": 3.3929,
      "step": 1620
    },
    {
      "epoch": 0.8935178840619432,
      "grad_norm": 1.3859789371490479,
      "learning_rate": 0.0001,
      "loss": 3.4128,
      "step": 1630
    },
    {
      "epoch": 0.8989995888721393,
      "grad_norm": 1.0982780456542969,
      "learning_rate": 0.0001,
      "loss": 3.3658,
      "step": 1640
    },
    {
      "epoch": 0.9044812936823352,
      "grad_norm": 1.0865602493286133,
      "learning_rate": 0.0001,
      "loss": 3.34,
      "step": 1650
    },
    {
      "epoch": 0.9099629984925311,
      "grad_norm": 1.1911157369613647,
      "learning_rate": 0.0001,
      "loss": 3.4069,
      "step": 1660
    },
    {
      "epoch": 0.9154447033027272,
      "grad_norm": 1.1453582048416138,
      "learning_rate": 0.0001,
      "loss": 3.3577,
      "step": 1670
    },
    {
      "epoch": 0.9209264081129231,
      "grad_norm": 1.2897857427597046,
      "learning_rate": 0.0001,
      "loss": 3.3492,
      "step": 1680
    },
    {
      "epoch": 0.9264081129231191,
      "grad_norm": 1.0502692461013794,
      "learning_rate": 0.0001,
      "loss": 3.3967,
      "step": 1690
    },
    {
      "epoch": 0.931889817733315,
      "grad_norm": 1.1111788749694824,
      "learning_rate": 0.0001,
      "loss": 3.3865,
      "step": 1700
    },
    {
      "epoch": 0.9373715225435111,
      "grad_norm": 1.2114819288253784,
      "learning_rate": 0.0001,
      "loss": 3.3597,
      "step": 1710
    },
    {
      "epoch": 0.942853227353707,
      "grad_norm": 1.1332393884658813,
      "learning_rate": 0.0001,
      "loss": 3.3536,
      "step": 1720
    },
    {
      "epoch": 0.948334932163903,
      "grad_norm": 1.1305454969406128,
      "learning_rate": 0.0001,
      "loss": 3.3658,
      "step": 1730
    },
    {
      "epoch": 0.9538166369740989,
      "grad_norm": 1.2238168716430664,
      "learning_rate": 0.0001,
      "loss": 3.3749,
      "step": 1740
    },
    {
      "epoch": 0.959298341784295,
      "grad_norm": 1.312495231628418,
      "learning_rate": 0.0001,
      "loss": 3.3786,
      "step": 1750
    },
    {
      "epoch": 0.9647800465944909,
      "grad_norm": 1.2514418363571167,
      "learning_rate": 0.0001,
      "loss": 3.3602,
      "step": 1760
    },
    {
      "epoch": 0.9702617514046868,
      "grad_norm": 1.3355618715286255,
      "learning_rate": 0.0001,
      "loss": 3.3703,
      "step": 1770
    },
    {
      "epoch": 0.9757434562148828,
      "grad_norm": 1.2270326614379883,
      "learning_rate": 0.0001,
      "loss": 3.388,
      "step": 1780
    },
    {
      "epoch": 0.9812251610250788,
      "grad_norm": 1.1388421058654785,
      "learning_rate": 0.0001,
      "loss": 3.3703,
      "step": 1790
    },
    {
      "epoch": 0.9867068658352748,
      "grad_norm": 1.205701470375061,
      "learning_rate": 0.0001,
      "loss": 3.3785,
      "step": 1800
    },
    {
      "epoch": 0.9867068658352748,
      "eval_loss": 3.3572943210601807,
      "eval_runtime": 244.1271,
      "eval_samples_per_second": 47.897,
      "eval_steps_per_second": 11.977,
      "step": 1800
    }
  ],
  "logging_steps": 10,
  "max_steps": 1824,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 1800,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 5.854219248548413e+17,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
